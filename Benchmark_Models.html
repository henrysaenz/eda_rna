
<!DOCTYPE html>


<html lang="en" data-content_root="./" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Benchmark Models &#8212; My sample book</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="_static/pygments.css?v=03e43079" />
    <link rel="stylesheet" type="text/css" href="_static/styles/sphinx-book-theme.css?v=eba8b062" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css?v=be8a1c11" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-design.min.css?v=95c83b7e" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script src="_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="_static/doctools.js?v=9a2dae69"></script>
    <script src="_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="_static/copybutton.js?v=f281be69"></script>
    <script src="_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="_static/design-tabs.js?v=f930bc37"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'Benchmark_Models';</script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="prev" title="Principal Component Analysis - Dimensionality reduction" href="PCA.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="intro.html">
  
  
  
  
  
    
    
      
    
    
    <img src="_static/logo_uninorte.png" class="logo__image only-light" alt="My sample book - Home"/>
    <script>document.write(`<img src="_static/logo_uninorte.png" class="logo__image only-dark" alt="My sample book - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="intro.html">
                    Final Project - Deep Learning
                </a>
            </li>
        </ul>
        <ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="introduction.html">Introduction to Single-Cell RNA Sequencing</a></li>

<li class="toctree-l1"><a class="reference internal" href="EDA_metadata.html">Exploratory Data Analysis for Metadata</a></li>

<li class="toctree-l1"><a class="reference internal" href="EDA_sparse_matrix.html">Exploratory Data Analysis for the sparse matrix</a></li>
<li class="toctree-l1"><a class="reference internal" href="Datos_celulares_y_geneticos.html">Exploratory Data Analysis for Glioblastoma data</a></li>
<li class="toctree-l1"><a class="reference internal" href="Agrupaciones_y_clusters.html">Exploratory Data Analysis for clusterization and gene expressions</a></li>
<li class="toctree-l1"><a class="reference internal" href="EDA_test.html">Exploratory Data Analysis for test data</a></li>

<li class="toctree-l1"><a class="reference internal" href="preprocessing.html">Preprocessing of Raw Data</a></li>
<li class="toctree-l1"><a class="reference internal" href="PCA.html">Principal Component Analysis - Dimensionality reduction</a></li>

<li class="toctree-l1 current active"><a class="current reference internal" href="#">Benchmark Models</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/henrysaenz/eda_rna" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/henrysaenz/eda_rna/issues/new?title=Issue%20on%20page%20%2FBenchmark_Models.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="_sources/Benchmark_Models.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm pst-navbar-icon search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Benchmark Models</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#model-vae">Model VAE</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#decoder-gene-expression-reconstruction">3. Decoder – Gene Expression Reconstruction</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#loss-functions">Loss Functions</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#clusterization-for-vae">Clusterization for VAE</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#hyperparametrization-of-vae">Hyperparametrization of VAE</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#performance-loss-functions">Performance loss functions</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#clusters-of-vae">Clusters of VAE</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#evaluation-metrics">Evaluation Metrics</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#differential-expression-for-vae">Differential Expression for VAE</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#volcano-plot-for-differential-expression">Volcano PLot for Differential Expression</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#vae-attention">VAE + Attention</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#hyperparametrization-of-the-model-vae-attention">Hyperparametrization of the model VAE + Attention</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#cluster-for-vae-attention">Cluster for VAE + Attention</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#differential-expression-for-vae-attention">Differential Expression for VAE + Attention</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#cluster-interpretation-based-on-marker-ranking-plots">Cluster Interpretation Based on Marker Ranking Plots</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#vae-gat">VAE + GAT</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#hyperparametrization-of-vae-gat">Hyperparametrization of VAE + GAT</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#model-defined-vae-gat">Model Defined VAE + GAT</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#differential-expression-for-vae-gat">Differential Expression for VAE + GAT</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#cluster-summary-with-biological-interpretation">Cluster Summary with Biological Interpretation</a></li>
</ul>
</li>
</ul>
</li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="benchmark-models">
<h1>Benchmark Models<a class="headerlink" href="#benchmark-models" title="Link to this heading">#</a></h1>
<p>In this analysis, we will perform a benchmark to compare the performance of various dimensionality reduction techniques applied to single-cell RNA sequencing (scRNA-seq) data. These techniques help reduce the complexity of the data by projecting it into a lower-dimensional space, which is essential for tasks like clustering, visualization, and downstream analyses.</p>
<p>The benchmark focuses on evaluating methods specifically designed to handle the sparsity and noise typical of scRNA-seq count matrices. The comparison includes methods such as:</p>
<ul class="simple">
<li><p>Principal Component Analysis (<strong>PCA</strong>)</p></li>
<li><p>Variational Autoencoders (<strong>VAE</strong>)</p></li>
<li><p>Variational Autoencoders + Attention Network (<strong>VAE + Attention</strong>)</p></li>
<li><p>Variational Autoencoders + Graph Attention Network (<strong>VAE + GAT</strong>)</p></li>
<li><p>Spatial Correlation (<strong>SPACO</strong>)</p></li>
</ul>
<p>We will assess each method using standard performance metrics, such as:</p>
<ul class="simple">
<li><p>Silhouette Score – for cluster quality</p></li>
<li><p>Calinski-Harabasz Index – for cluster separation</p></li>
<li><p>Number of clusters</p></li>
<li><p>Biological interpretability via differential expression analysis (DEA)</p></li>
</ul>
<section id="model-vae">
<h2>Model VAE<a class="headerlink" href="#model-vae" title="Link to this heading">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.image</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">mpimg</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">image_path</span> <span class="o">=</span> <span class="s1">&#39;C:/Users/henry/Documents/jbook/eda_rna/img/vae.png&#39;</span>

<span class="c1"># Load and display the image</span>
<span class="n">img</span> <span class="o">=</span> <span class="n">mpimg</span><span class="o">.</span><span class="n">imread</span><span class="p">(</span><span class="n">image_path</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">img</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s1">&#39;off&#39;</span><span class="p">)</span>  
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Image Preview&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/66ff2cc7c56dda815c6a51620ef1f4b9bd8043647fe1d04f4baa14593db2a269.png" src="_images/66ff2cc7c56dda815c6a51620ef1f4b9bd8043647fe1d04f4baa14593db2a269.png" />
</div>
</div>
<p>The modelo learns a latent representation of each cell and reconstructs gene expression using a probabilistic decoder designed for count data.</p>
<ol class="arabic simple">
<li><p><code class="docutils literal notranslate"><span class="pre">Input:</span> <span class="pre">Gene</span> <span class="pre">Expression</span> <span class="pre">Matrix</span></code></p></li>
</ol>
<p>The input is a matrix ( \mathbf{X} \in \mathbb{R}^{n \times m} ), where each row represents a <strong>cell</strong> and each column corresponds to a <strong>gene</strong>. Each input vector ( \mathbf{x}_i ) is high-dimensional and sparse.</p>
<ol class="arabic simple" start="2">
<li><p>Encoder – Latent Representation Inference</p></li>
</ol>
<p>The encoder maps the high-dimensional input into a lower-dimensional <strong>latent space</strong> ( \mathbf{z} ).</p>
<ul class="simple">
<li><p><strong>Layer 1:</strong> <code class="docutils literal notranslate"><span class="pre">fc_enc1</span></code> → Reduces dimensionality with an <strong>ELU</strong> activation.</p></li>
<li><p><strong>Layer 2:</strong> <code class="docutils literal notranslate"><span class="pre">fc_enc2</span></code> → Further non-linear transformation.</p></li>
<li><p><strong>Outputs:</strong></p>
<ul>
<li><p>( \boldsymbol{\mu} ): Mean of the latent Gaussian.</p></li>
<li><p>( \log \boldsymbol{\sigma}^2 ): Log-variance of the latent Gaussian.</p></li>
</ul>
</li>
</ul>
<p>The latent variable ( \mathbf{z} ) is sampled using the <strong>reparameterization trick</strong>:</p>
<div class="math notranslate nohighlight">
\[
\mathbf{z} = \boldsymbol{\mu} + \boldsymbol{\epsilon} \cdot \boldsymbol{\sigma}, \quad \boldsymbol{\epsilon} \sim \mathcal{N}(0, I)
\]</div>
</section>
<section id="decoder-gene-expression-reconstruction">
<h2>3. Decoder – Gene Expression Reconstruction<a class="headerlink" href="#decoder-gene-expression-reconstruction" title="Link to this heading">#</a></h2>
<p>The decoder takes ( \mathbf{z} ) and reconstructs the original gene expression ( \mathbf{x}_i ).</p>
<ul class="simple">
<li><p><strong>Layers <code class="docutils literal notranslate"><span class="pre">fc_dec1</span></code> to <code class="docutils literal notranslate"><span class="pre">fc_dec3</span></code>:</strong> Gradually expand the latent vector back to the original input size.</p></li>
<li><p><strong>Output:</strong> The reconstructed gene expression ( \tilde{\mathbf{x}} ).</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span><span class="w"> </span><span class="nc">VAE</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_dim</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">,</span> <span class="n">latent_dim</span><span class="p">,</span> <span class="n">dropout_rate</span><span class="o">=</span><span class="mf">0.1</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">VAE</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="c1">#Encoder</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc_enc1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">input_dim</span><span class="p">,</span> <span class="n">hidden_dim</span> <span class="o">*</span> <span class="mi">2</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc_enc2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_dim</span> <span class="o">*</span> <span class="mi">2</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc_mu</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_dim</span><span class="p">,</span> <span class="n">latent_dim</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc_var</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_dim</span><span class="p">,</span> <span class="n">latent_dim</span><span class="p">)</span>
        
        <span class="c1"># Decoder</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc_dec1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">latent_dim</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc_dec2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_dim</span><span class="p">,</span> <span class="n">hidden_dim</span> <span class="o">*</span> <span class="mi">2</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc_dec3</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_dim</span> <span class="o">*</span> <span class="mi">2</span><span class="p">,</span> <span class="n">input_dim</span><span class="p">)</span>

        <span class="c1">#dropout layer</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">dropout_rate</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">encode</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">h</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">elu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">fc_enc1</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
        <span class="n">h</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">h</span><span class="p">)</span>
        <span class="n">h</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">elu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">fc_enc2</span><span class="p">(</span><span class="n">h</span><span class="p">))</span>
        <span class="n">h</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">h</span><span class="p">)</span>
        <span class="n">mu</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc_mu</span><span class="p">(</span><span class="n">h</span><span class="p">)</span>
        <span class="n">log_var</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc_var</span><span class="p">(</span><span class="n">h</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">mu</span><span class="p">,</span> <span class="n">log_var</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">reparameterize</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">mu</span><span class="p">,</span> <span class="n">log_var</span><span class="p">):</span>
        <span class="n">std</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="mf">0.5</span> <span class="o">*</span> <span class="n">log_var</span><span class="p">)</span>
        <span class="n">eps</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn_like</span><span class="p">(</span><span class="n">std</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">mu</span> <span class="o">+</span> <span class="n">eps</span> <span class="o">*</span> <span class="n">std</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">decode</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">z</span><span class="p">):</span>
        <span class="n">h</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">elu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">fc_dec1</span><span class="p">(</span><span class="n">z</span><span class="p">))</span>
        <span class="n">h</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">h</span><span class="p">)</span>
        <span class="n">h</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">elu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">fc_dec2</span><span class="p">(</span><span class="n">h</span><span class="p">))</span>
        <span class="n">h</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">h</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc_dec3</span><span class="p">(</span><span class="n">h</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">mu</span><span class="p">,</span> <span class="n">log_var</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">z</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">reparameterize</span><span class="p">(</span><span class="n">mu</span><span class="p">,</span> <span class="n">log_var</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="n">z</span><span class="p">),</span> <span class="n">mu</span><span class="p">,</span> <span class="n">log_var</span>
</pre></div>
</div>
</div>
</div>
<section id="loss-functions">
<h3>Loss Functions<a class="headerlink" href="#loss-functions" title="Link to this heading">#</a></h3>
<p><strong>Custom Loss Function:</strong> <code class="docutils literal notranslate"><span class="pre">zinb_loss</span></code></p>
<p>This model uses a <strong>Zero-Inflated Negative Binomial (ZINB)</strong> loss tailored to count data with overdispersion and excess zeros, typical of scRNA-seq. It includes:</p>
<p>• Negative Binomial (NB) Loss</p>
<p>The NB likelihood models overdispersed count data. Given mean (<span class="math notranslate nohighlight">\(\mu\)</span>), dispersion (<span class="math notranslate nohighlight">\(\theta\)</span>), and count (<span class="math notranslate nohighlight">\(x\)</span>):</p>
<div class="math notranslate nohighlight">
\[
\mathcal{L}_{NB}(x; \mu, \theta) = \log \Gamma(x + \theta) - \log \Gamma(x + 1) - \log \Gamma(\theta) + \theta \log \left( \frac{\theta}{\theta + \mu} \right) + x \log \left( \frac{\mu}{\theta + \mu} \right)
\]</div>
<p>This is typically <strong>negated</strong> to turn it into a loss.</p>
<p>• Bernoulli Loss (BL) — Optional for Zero-Inflation</p>
<p>If zero-inflation probabilities (<span class="math notranslate nohighlight">\(p_0\)</span>) are modeled, a Bernoulli component is added:</p>
<div class="math notranslate nohighlight">
\[
\mathcal{L}_{BL}(x; p_0) = -x \cdot \log(1 - p_0) - (1 - x) \cdot \log(p_0)
\]</div>
<p>Only applied when modeling dropout/excess zeros explicitly.</p>
<p>• KL Divergence (Latent Regularization)</p>
<p>The KL divergence ensures that the latent space stays close to a standard Gaussian prior:</p>
<div class="math notranslate nohighlight">
\[
\mathcal{L}_{KL} = -\frac{1}{2} \sum \left(1 + \log \sigma^2 - \mu^2 - \sigma^2 \right)
\]</div>
<p>• Total Loss</p>
<p>The final loss combines all components, with a tunable (<span class="math notranslate nohighlight">\(\beta\)</span>) coefficient:</p>
<div class="math notranslate nohighlight">
\[
\mathcal{L}_{\text{total}} = \mathcal{L}_{NB} + \mathcal{L}_{BL} + \beta \cdot \mathcal{L}_{KL}
\]</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">zinb_loss</span><span class="p">(</span><span class="n">recon_x</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">mu</span><span class="p">,</span> <span class="n">log_var</span><span class="p">,</span> <span class="n">p0</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">beta</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">theta</span><span class="o">=</span><span class="mf">1.0</span><span class="p">):</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">x</span><span class="o">.</span><span class="n">is_sparse</span><span class="p">:</span>
            <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">to_dense</span><span class="p">()</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>

    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">recon_x</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">recon_x</span><span class="o">.</span><span class="n">is_sparse</span><span class="p">:</span>
            <span class="n">recon_x</span> <span class="o">=</span> <span class="n">recon_x</span><span class="o">.</span><span class="n">to_dense</span><span class="p">()</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">recon_x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">recon_x</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>

    <span class="n">theta_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">theta</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">x</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">x</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
    <span class="n">theta_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">clamp</span><span class="p">(</span><span class="n">theta_tensor</span><span class="p">,</span> <span class="nb">min</span><span class="o">=</span><span class="mf">1e-6</span><span class="p">,</span> <span class="nb">max</span><span class="o">=</span><span class="mf">1e3</span><span class="p">)</span>

    <span class="n">nb_loss</span> <span class="o">=</span> <span class="o">-</span><span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">lgamma</span><span class="p">(</span><span class="n">x</span> <span class="o">+</span> <span class="n">theta_tensor</span><span class="p">)</span>
        <span class="o">-</span> <span class="n">torch</span><span class="o">.</span><span class="n">lgamma</span><span class="p">(</span><span class="n">x</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
        <span class="o">-</span> <span class="n">torch</span><span class="o">.</span><span class="n">lgamma</span><span class="p">(</span><span class="n">theta_tensor</span><span class="p">)</span>
        <span class="o">+</span> <span class="n">x</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">clamp</span><span class="p">(</span><span class="n">recon_x</span><span class="p">,</span> <span class="nb">min</span><span class="o">=</span><span class="mf">1e-8</span><span class="p">))</span>
        <span class="o">+</span> <span class="n">theta_tensor</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">theta_tensor</span> <span class="o">/</span> <span class="n">torch</span><span class="o">.</span><span class="n">clamp</span><span class="p">(</span><span class="n">recon_x</span><span class="p">,</span> <span class="nb">min</span><span class="o">=</span><span class="mf">1e-8</span><span class="p">))</span>
    <span class="p">)</span>

    <span class="c1"># if p0 do not provide we assume bernulli</span>
    <span class="k">if</span> <span class="n">p0</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">bernoulli_loss</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">x</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">p0</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">clamp</span><span class="p">(</span><span class="n">p0</span><span class="p">,</span> <span class="nb">min</span><span class="o">=</span><span class="mf">1e-5</span><span class="p">,</span> <span class="nb">max</span><span class="o">=</span><span class="mi">1</span> <span class="o">-</span> <span class="mf">1e-5</span><span class="p">)</span>
        <span class="n">bernoulli_loss</span> <span class="o">=</span> <span class="o">-</span><span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">x</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">p0</span> <span class="o">+</span> <span class="mf">1e-8</span><span class="p">)</span> <span class="o">+</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">x</span><span class="p">)</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">p0</span> <span class="o">+</span> <span class="mf">1e-8</span><span class="p">))</span>

    <span class="n">mu</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">clamp</span><span class="p">(</span><span class="n">mu</span><span class="p">,</span> <span class="nb">min</span><span class="o">=-</span><span class="mi">10</span><span class="p">,</span> <span class="nb">max</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
    <span class="n">log_var</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">clamp</span><span class="p">(</span><span class="n">log_var</span><span class="p">,</span> <span class="nb">min</span><span class="o">=-</span><span class="mi">10</span><span class="p">,</span> <span class="nb">max</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
    <span class="n">kl_loss</span> <span class="o">=</span> <span class="o">-</span><span class="mf">0.5</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">log_var</span> <span class="o">-</span> <span class="n">mu</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span> <span class="o">-</span> <span class="n">log_var</span><span class="o">.</span><span class="n">exp</span><span class="p">())</span>

    <span class="n">total_loss</span> <span class="o">=</span> <span class="n">nb_loss</span> <span class="o">+</span> <span class="n">bernoulli_loss</span> <span class="o">+</span> <span class="n">beta</span> <span class="o">*</span> <span class="n">kl_loss</span>

    <span class="k">return</span> <span class="n">total_loss</span><span class="p">,</span> <span class="n">nb_loss</span><span class="p">,</span> <span class="n">bernoulli_loss</span><span class="p">,</span> <span class="n">kl_loss</span>
</pre></div>
</div>
</div>
</div>
<p>Training of the model</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">train_model_vae</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">num_epochs</span><span class="o">=</span><span class="mi">200</span><span class="p">):</span>
    <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
    <span class="n">total_losses</span><span class="p">,</span> <span class="n">nb_losses</span><span class="p">,</span> <span class="n">bernoulli_losses</span><span class="p">,</span> <span class="n">kl_losses</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[],</span> <span class="p">[],</span> <span class="p">[]</span>

    <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_epochs</span><span class="p">):</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
        <span class="n">recon</span><span class="p">,</span> <span class="n">mu</span><span class="p">,</span> <span class="n">log_var</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
        <span class="n">total_loss</span><span class="p">,</span> <span class="n">nb_loss</span><span class="p">,</span> <span class="n">bern_loss</span><span class="p">,</span> <span class="n">kl_loss</span> <span class="o">=</span> <span class="n">zinb_loss</span><span class="p">(</span><span class="n">recon</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">mu</span><span class="p">,</span> <span class="n">log_var</span><span class="p">)</span>
        <span class="n">total_loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

        <span class="n">total_losses</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">total_loss</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>
        <span class="n">nb_losses</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nb_loss</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>
        <span class="n">bernoulli_losses</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">bern_loss</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>
        <span class="n">kl_losses</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">kl_loss</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>

        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Epoch [</span><span class="si">{</span><span class="n">epoch</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="n">num_epochs</span><span class="si">}</span><span class="s2">] - Total: </span><span class="si">{</span><span class="n">total_loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">, NB: </span><span class="si">{</span><span class="n">nb_loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">, Bernoulli: </span><span class="si">{</span><span class="n">bern_loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">, KL: </span><span class="si">{</span><span class="n">kl_loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">total_losses</span><span class="p">,</span> <span class="n">nb_losses</span><span class="p">,</span> <span class="n">bernoulli_losses</span><span class="p">,</span> <span class="n">kl_losses</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="clusterization-for-vae">
<h3>Clusterization for VAE<a class="headerlink" href="#clusterization-for-vae" title="Link to this heading">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">clustering_and_metrics</span><span class="p">(</span><span class="n">mu</span><span class="p">,</span> <span class="n">X_data</span><span class="p">):</span>
    <span class="c1"># Latent representation (mu)</span>
    <span class="n">adata_latent</span> <span class="o">=</span> <span class="n">sc</span><span class="o">.</span><span class="n">AnnData</span><span class="p">(</span><span class="n">X</span><span class="o">=</span><span class="n">mu</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>
    <span class="c1"># Preprocessing UMAP</span>
    <span class="n">sc</span><span class="o">.</span><span class="n">pp</span><span class="o">.</span><span class="n">neighbors</span><span class="p">(</span><span class="n">adata_latent</span><span class="p">,</span> <span class="n">n_neighbors</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">use_rep</span><span class="o">=</span><span class="s1">&#39;X&#39;</span><span class="p">)</span>
    <span class="n">sc</span><span class="o">.</span><span class="n">tl</span><span class="o">.</span><span class="n">umap</span><span class="p">(</span><span class="n">adata_latent</span><span class="p">)</span>
    
    <span class="c1"># clustering resolutions</span>
    <span class="n">resolutions</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.4</span><span class="p">,</span> <span class="mf">0.6</span><span class="p">,</span> <span class="mf">0.8</span><span class="p">]</span>
    <span class="n">methods</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;leiden&#39;</span><span class="p">,</span> <span class="s1">&#39;louvain&#39;</span><span class="p">]</span>
    <span class="n">clustering_results</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="n">fig</span><span class="p">,</span> <span class="n">axs</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">18</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>
    <span class="n">axs</span> <span class="o">=</span> <span class="n">axs</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>
    <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="k">for</span> <span class="n">method</span> <span class="ow">in</span> <span class="n">methods</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">res</span> <span class="ow">in</span> <span class="n">resolutions</span><span class="p">:</span>
            <span class="n">key</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">method</span><span class="si">}</span><span class="s2">_r&quot;</span>
            
            <span class="c1">#Leiden o Louvain</span>
            <span class="k">if</span> <span class="n">method</span> <span class="o">==</span> <span class="s1">&#39;leiden&#39;</span><span class="p">:</span>
                <span class="n">sc</span><span class="o">.</span><span class="n">tl</span><span class="o">.</span><span class="n">leiden</span><span class="p">(</span><span class="n">adata_latent</span><span class="p">,</span> <span class="n">resolution</span><span class="o">=</span><span class="n">res</span><span class="p">,</span> <span class="n">key_added</span><span class="o">=</span><span class="n">key</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">sc</span><span class="o">.</span><span class="n">tl</span><span class="o">.</span><span class="n">louvain</span><span class="p">(</span><span class="n">adata_latent</span><span class="p">,</span> <span class="n">resolution</span><span class="o">=</span><span class="n">res</span><span class="p">,</span> <span class="n">key_added</span><span class="o">=</span><span class="n">key</span><span class="p">)</span>
            <span class="c1"># clusters lablels</span>
            <span class="n">labels</span> <span class="o">=</span> <span class="n">adata_latent</span><span class="o">.</span><span class="n">obs</span><span class="p">[</span><span class="n">key</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span><span class="o">.</span><span class="n">values</span>
            <span class="n">n_clusters</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">labels</span><span class="p">))</span>
            <span class="n">silh</span> <span class="o">=</span> <span class="n">silhouette_score</span><span class="p">(</span><span class="n">adata_latent</span><span class="o">.</span><span class="n">obsm</span><span class="p">[</span><span class="s1">&#39;X_umap&#39;</span><span class="p">],</span> <span class="n">labels</span><span class="p">)</span> <span class="k">if</span> <span class="n">n_clusters</span> <span class="o">&gt;</span> <span class="mi">1</span> <span class="k">else</span> <span class="o">-</span><span class="mi">1</span>
            <span class="n">ch</span> <span class="o">=</span> <span class="n">calinski_harabasz_score</span><span class="p">(</span><span class="n">adata_latent</span><span class="o">.</span><span class="n">obsm</span><span class="p">[</span><span class="s1">&#39;X_umap&#39;</span><span class="p">],</span> <span class="n">labels</span><span class="p">)</span> <span class="k">if</span> <span class="n">n_clusters</span> <span class="o">&gt;</span> <span class="mi">1</span> <span class="k">else</span> <span class="o">-</span><span class="mi">1</span>
            
            <span class="n">clustering_results</span><span class="o">.</span><span class="n">append</span><span class="p">({</span>
                <span class="s1">&#39;method&#39;</span><span class="p">:</span> <span class="n">method</span><span class="p">,</span>
                <span class="s1">&#39;resolution&#39;</span><span class="p">:</span> <span class="n">res</span><span class="p">,</span>
                <span class="s1">&#39;n_clusters&#39;</span><span class="p">:</span> <span class="n">n_clusters</span><span class="p">,</span>
                <span class="s1">&#39;silhouette&#39;</span><span class="p">:</span> <span class="n">silh</span><span class="p">,</span>
                <span class="s1">&#39;calinski_harabasz&#39;</span><span class="p">:</span> <span class="n">ch</span>
            <span class="p">})</span>

            <span class="n">axs</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">adata_latent</span><span class="o">.</span><span class="n">obsm</span><span class="p">[</span><span class="s1">&#39;X_umap&#39;</span><span class="p">][:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">adata_latent</span><span class="o">.</span><span class="n">obsm</span><span class="p">[</span><span class="s1">&#39;X_umap&#39;</span><span class="p">][:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="n">labels</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;tab20&#39;</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.7</span><span class="p">)</span>
            <span class="n">axs</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">method</span><span class="o">.</span><span class="n">title</span><span class="p">()</span><span class="si">}</span><span class="s2"> (res=</span><span class="si">{</span><span class="n">res</span><span class="si">}</span><span class="s2">)</span><span class="se">\n</span><span class="s2">Silh=</span><span class="si">{</span><span class="n">silh</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">  CH=</span><span class="si">{</span><span class="n">ch</span><span class="si">:</span><span class="s2">.1f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="n">axs</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">&quot;UMAP1&quot;</span><span class="p">)</span>
            <span class="n">axs</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">&quot;UMAP2&quot;</span><span class="p">)</span>
            <span class="n">i</span> <span class="o">+=</span> <span class="mi">1</span>

    <span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

    <span class="k">return</span> <span class="n">clustering_results</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="hyperparametrization-of-vae">
<h3>Hyperparametrization of VAE<a class="headerlink" href="#hyperparametrization-of-vae" title="Link to this heading">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># GridSEARCH</span>
<span class="k">def</span><span class="w"> </span><span class="nf">hyperparameter_search</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">input_dim</span><span class="p">,</span> <span class="n">num_epochs</span><span class="p">):</span>
    <span class="n">param_grid</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s1">&#39;hidden_dim&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">64</span><span class="p">,</span> <span class="mi">128</span><span class="p">,</span> <span class="mi">256</span><span class="p">],</span>
        <span class="s1">&#39;latent_dim&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">32</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="mi">128</span><span class="p">],</span>
        <span class="s1">&#39;dropout_rate&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">],</span>
        <span class="s1">&#39;learning_rate&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mf">1e-3</span><span class="p">,</span> <span class="mf">1e-4</span><span class="p">,</span> <span class="mf">1e-5</span><span class="p">]</span>
    <span class="p">}</span>

    <span class="n">best_score</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="s1">&#39;inf&#39;</span><span class="p">)</span>
    <span class="n">best_params</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="n">best_model</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="k">for</span> <span class="n">params</span> <span class="ow">in</span> <span class="n">ParameterGrid</span><span class="p">(</span><span class="n">param_grid</span><span class="p">):</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Training with parameters: </span><span class="si">{</span><span class="n">params</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="n">model</span> <span class="o">=</span> <span class="n">VAE</span><span class="p">(</span><span class="n">input_dim</span><span class="p">,</span> <span class="n">params</span><span class="p">[</span><span class="s1">&#39;hidden_dim&#39;</span><span class="p">],</span> <span class="n">params</span><span class="p">[</span><span class="s1">&#39;latent_dim&#39;</span><span class="p">],</span> <span class="n">dropout_rate</span><span class="o">=</span><span class="n">params</span><span class="p">[</span><span class="s1">&#39;dropout_rate&#39;</span><span class="p">])</span>
        <span class="n">optimizer</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">params</span><span class="p">[</span><span class="s1">&#39;learning_rate&#39;</span><span class="p">])</span>
        <span class="n">losses</span><span class="p">,</span> <span class="n">nb_losses</span><span class="p">,</span> <span class="n">bernoulli_losses</span><span class="p">,</span> <span class="n">kl_losses</span> <span class="o">=</span> <span class="n">train_model_vae</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">num_epochs</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        
        <span class="c1"># Evaluar métricas</span>
        <span class="n">final_loss</span> <span class="o">=</span> <span class="n">losses</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
        <span class="k">if</span> <span class="n">final_loss</span> <span class="o">&lt;</span> <span class="n">best_score</span><span class="p">:</span>
            <span class="n">best_score</span> <span class="o">=</span> <span class="n">final_loss</span>
            <span class="n">best_params</span> <span class="o">=</span> <span class="n">params</span>
            <span class="n">best_model</span> <span class="o">=</span> <span class="n">model</span>

    <span class="k">return</span> <span class="n">best_model</span><span class="p">,</span> <span class="n">best_params</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">input_dim</span> <span class="o">=</span> <span class="n">adata_filtered</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
<span class="n">X_data</span> <span class="o">=</span> <span class="n">adata_filtered</span><span class="o">.</span><span class="n">X</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span><span class="p">(</span><span class="n">X_data</span><span class="p">)</span>
<span class="n">num_epochs</span> <span class="o">=</span> <span class="mi">200</span>
<span class="n">best_model</span><span class="p">,</span> <span class="n">best_params</span> <span class="o">=</span> <span class="n">hyperparameter_search</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">input_dim</span><span class="p">,</span> <span class="n">num_epochs</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Best hyperparameters: </span><span class="si">{</span><span class="n">best_params</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Best hyperparameters: {&#39;dropout_rate&#39;: 0.1, &#39;hidden_dim&#39;: 256, &#39;latent_dim&#39;: 64, &#39;learning_rate&#39;: 0.001}
</pre></div>
</div>
</div>
</div>
<div class="admonition-what-does-the-parameters-of-the-model-mean admonition">
<p class="admonition-title">What does the parameters of the model mean?</p>
<ul class="simple">
<li><p>input_dim: 	The number of input features (genes). Defines the size of the input layer in the encoder and the output layer in the decoder.</p></li>
<li><p>dropout_rate:	Dropout probability used in hidden layers to reduce overfitting. A value of 0.1 means 10% of neurons are randomly dropped during training.</p></li>
<li><p>hidden_dim:	Number of neurons in hidden layers of both encoder and decoder. Controls model complexity.</p></li>
<li><p>latent_dim:	Dimensionality of the latent space (the compressed representation of each cell). Lower values enforce more compression.</p></li>
<li><p>learning_rate:	Step size used by the optimizer to adjust weights. Lower values lead to more stable convergence.</p></li>
</ul>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#Using the best parameters</span>
<span class="n">X_data</span> <span class="o">=</span> <span class="n">adata_filtered</span><span class="o">.</span><span class="n">X</span> 
<span class="n">dropout_rate</span> <span class="o">=</span> <span class="mf">0.1</span>
<span class="n">hidden_dim</span> <span class="o">=</span> <span class="mi">256</span>
<span class="n">latent_dim</span> <span class="o">=</span> <span class="mi">64</span>
<span class="n">learning_rate</span> <span class="o">=</span> <span class="mf">0.001</span>
<span class="n">num_epochs</span> <span class="o">=</span> <span class="mi">200</span>
<span class="n">input_dim</span> <span class="o">=</span> <span class="n">X_data</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Model</span>
<span class="n">vae_model</span> <span class="o">=</span> <span class="n">VAE</span><span class="p">(</span><span class="n">input_dim</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">,</span> <span class="n">latent_dim</span><span class="p">,</span> <span class="n">dropout_rate</span><span class="o">=</span><span class="n">dropout_rate</span><span class="p">)</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">vae_model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">learning_rate</span><span class="p">)</span>
<span class="n">X_data_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">X_data</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span> <span class="c1">#tensor</span>
<span class="n">total_losses</span><span class="p">,</span> <span class="n">nb_losses</span><span class="p">,</span> <span class="n">bernoulli_losses</span><span class="p">,</span> <span class="n">kl_losses</span> <span class="o">=</span> <span class="n">train_model_vae</span><span class="p">(</span><span class="n">vae_model</span><span class="p">,</span> <span class="n">X_data_tensor</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">num_epochs</span><span class="o">=</span><span class="mi">200</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch [1/200] - Loss: -35418488.0000, NB Loss: -37964192.0000, Bernoulli Loss: 2543674.2500, KL Loss: 2029.6763
Epoch [2/200] - Loss: -37713400.0000, NB Loss: -40230984.0000, Bernoulli Loss: 2515098.0000, KL Loss: 2486.4631
Epoch [3/200] - Loss: -39879964.0000, NB Loss: -42370092.0000, Bernoulli Loss: 2487028.5000, KL Loss: 3101.0100
Epoch [4/200] - Loss: -41845732.0000, NB Loss: -44310336.0000, Bernoulli Loss: 2460814.0000, KL Loss: 3789.5840
Epoch [5/200] - Loss: -43725440.0000, NB Loss: -46164072.0000, Bernoulli Loss: 2434234.5000, KL Loss: 4395.9697
Epoch [6/200] - Loss: -45640240.0000, NB Loss: -48051340.0000, Bernoulli Loss: 2405989.2500, KL Loss: 5110.0586
Epoch [7/200] - Loss: -47352604.0000, NB Loss: -49737672.0000, Bernoulli Loss: 2379326.5000, KL Loss: 5740.4888
Epoch [8/200] - Loss: -49136532.0000, NB Loss: -51492504.0000, Bernoulli Loss: 2349561.2500, KL Loss: 6410.7227
Epoch [9/200] - Loss: -50843952.0000, NB Loss: -53170100.0000, Bernoulli Loss: 2319000.5000, KL Loss: 7147.8730
Epoch [10/200] - Loss: -52603484.0000, NB Loss: -54895016.0000, Bernoulli Loss: 2283711.0000, KL Loss: 7819.7373
Epoch [11/200] - Loss: -54298668.0000, NB Loss: -56553260.0000, Bernoulli Loss: 2246018.5000, KL Loss: 8570.2188
Epoch [12/200] - Loss: -55671228.0000, NB Loss: -57891752.0000, Bernoulli Loss: 2211248.7500, KL Loss: 9277.6699
Epoch [13/200] - Loss: -57220660.0000, NB Loss: -59397172.0000, Bernoulli Loss: 2166474.5000, KL Loss: 10034.8496
Epoch [14/200] - Loss: -58441192.0000, NB Loss: -60578492.0000, Bernoulli Loss: 2126451.0000, KL Loss: 10847.8477
Epoch [15/200] - Loss: -59526912.0000, NB Loss: -61623160.0000, Bernoulli Loss: 2084566.2500, KL Loss: 11680.8594
Epoch [16/200] - Loss: -60536252.0000, NB Loss: -62586864.0000, Bernoulli Loss: 2038071.0000, KL Loss: 12539.7607
Epoch [17/200] - Loss: -61569544.0000, NB Loss: -63567940.0000, Bernoulli Loss: 1984796.8750, KL Loss: 13601.6855
Epoch [18/200] - Loss: -62198224.0000, NB Loss: -64155212.0000, Bernoulli Loss: 1942214.7500, KL Loss: 14772.9512
Epoch [19/200] - Loss: -62827472.0000, NB Loss: -64737600.0000, Bernoulli Loss: 1894053.8750, KL Loss: 16075.2158
Epoch [20/200] - Loss: -63477052.0000, NB Loss: -65338148.0000, Bernoulli Loss: 1843593.1250, KL Loss: 17502.8301
Epoch [21/200] - Loss: -63937788.0000, NB Loss: -65749024.0000, Bernoulli Loss: 1792145.8750, KL Loss: 19092.3184
Epoch [22/200] - Loss: -64276688.0000, NB Loss: -66043780.0000, Bernoulli Loss: 1746339.5000, KL Loss: 20753.8984
Epoch [23/200] - Loss: -64661732.0000, NB Loss: -66374812.0000, Bernoulli Loss: 1690490.2500, KL Loss: 22587.8945
Epoch [24/200] - Loss: -64912540.0000, NB Loss: -66576036.0000, Bernoulli Loss: 1639310.3750, KL Loss: 24183.5508
Epoch [25/200] - Loss: -65163848.0000, NB Loss: -66780248.0000, Bernoulli Loss: 1590196.0000, KL Loss: 26204.2090
Epoch [26/200] - Loss: -65316672.0000, NB Loss: -66894740.0000, Bernoulli Loss: 1549961.7500, KL Loss: 28106.6270
Epoch [27/200] - Loss: -65528100.0000, NB Loss: -67048444.0000, Bernoulli Loss: 1490216.2500, KL Loss: 30128.2500
Epoch [28/200] - Loss: -65631440.0000, NB Loss: -67112056.0000, Bernoulli Loss: 1448296.7500, KL Loss: 32318.5801
Epoch [29/200] - Loss: -65776608.0000, NB Loss: -67210344.0000, Bernoulli Loss: 1399237.1250, KL Loss: 34499.3906
Epoch [30/200] - Loss: -65903604.0000, NB Loss: -67275032.0000, Bernoulli Loss: 1334792.3750, KL Loss: 36636.6562
Epoch [31/200] - Loss: -65982488.0000, NB Loss: -67322176.0000, Bernoulli Loss: 1300650.0000, KL Loss: 39041.7266
Epoch [32/200] - Loss: -66072020.0000, NB Loss: -67370456.0000, Bernoulli Loss: 1257282.1250, KL Loss: 41152.2617
Epoch [33/200] - Loss: -66156676.0000, NB Loss: -67407160.0000, Bernoulli Loss: 1207393.0000, KL Loss: 43091.6680
Epoch [34/200] - Loss: -66232900.0000, NB Loss: -67436736.0000, Bernoulli Loss: 1158677.2500, KL Loss: 45161.7109
Epoch [35/200] - Loss: -66294364.0000, NB Loss: -67460144.0000, Bernoulli Loss: 1118034.1250, KL Loss: 47743.0352
Epoch [36/200] - Loss: -66367836.0000, NB Loss: -67489984.0000, Bernoulli Loss: 1072515.5000, KL Loss: 49631.9570
Epoch [37/200] - Loss: -66448880.0000, NB Loss: -67517472.0000, Bernoulli Loss: 1016653.9375, KL Loss: 51940.1094
Epoch [38/200] - Loss: -66470696.0000, NB Loss: -67507360.0000, Bernoulli Loss: 982596.8750, KL Loss: 54068.7266
Epoch [39/200] - Loss: -66536016.0000, NB Loss: -67534288.0000, Bernoulli Loss: 941850.2500, KL Loss: 56421.9062
Epoch [40/200] - Loss: -66577308.0000, NB Loss: -67533720.0000, Bernoulli Loss: 898091.0625, KL Loss: 58321.2969
Epoch [41/200] - Loss: -66647788.0000, NB Loss: -67563192.0000, Bernoulli Loss: 854993.3750, KL Loss: 60412.4766
Epoch [42/200] - Loss: -66695396.0000, NB Loss: -67569032.0000, Bernoulli Loss: 810382.0000, KL Loss: 63253.9844
Epoch [43/200] - Loss: -66725436.0000, NB Loss: -67573672.0000, Bernoulli Loss: 782705.4375, KL Loss: 65533.2773
Epoch [44/200] - Loss: -66768132.0000, NB Loss: -67576352.0000, Bernoulli Loss: 740471.6250, KL Loss: 67747.7969
Epoch [45/200] - Loss: -66806288.0000, NB Loss: -67586168.0000, Bernoulli Loss: 709258.9375, KL Loss: 70620.0859
Epoch [46/200] - Loss: -66841680.0000, NB Loss: -67586696.0000, Bernoulli Loss: 672733.1250, KL Loss: 72282.3984
Epoch [47/200] - Loss: -66888152.0000, NB Loss: -67595104.0000, Bernoulli Loss: 631762.8750, KL Loss: 75189.0234
Epoch [48/200] - Loss: -66928536.0000, NB Loss: -67602016.0000, Bernoulli Loss: 595700.7500, KL Loss: 77780.2344
Epoch [49/200] - Loss: -66951092.0000, NB Loss: -67598744.0000, Bernoulli Loss: 567896.3125, KL Loss: 79754.0234
Epoch [50/200] - Loss: -66993756.0000, NB Loss: -67607224.0000, Bernoulli Loss: 530688.0000, KL Loss: 82780.2812
Epoch [51/200] - Loss: -67003404.0000, NB Loss: -67588504.0000, Bernoulli Loss: 499786.6250, KL Loss: 85313.9609
Epoch [52/200] - Loss: -67060504.0000, NB Loss: -67617448.0000, Bernoulli Loss: 469167.6875, KL Loss: 87777.5312
Epoch [53/200] - Loss: -67097212.0000, NB Loss: -67622416.0000, Bernoulli Loss: 434574.4688, KL Loss: 90628.0938
Epoch [54/200] - Loss: -67132048.0000, NB Loss: -67622080.0000, Bernoulli Loss: 396360.3125, KL Loss: 93669.3359
Epoch [55/200] - Loss: -67146320.0000, NB Loss: -67618720.0000, Bernoulli Loss: 376504.5312, KL Loss: 95896.8125
Epoch [56/200] - Loss: -67175792.0000, NB Loss: -67622160.0000, Bernoulli Loss: 347528.0000, KL Loss: 98839.9844
Epoch [57/200] - Loss: -67200256.0000, NB Loss: -67624272.0000, Bernoulli Loss: 322213.7188, KL Loss: 101801.2969
Epoch [58/200] - Loss: -67234640.0000, NB Loss: -67623056.0000, Bernoulli Loss: 282342.4688, KL Loss: 106074.5469
Epoch [59/200] - Loss: -67255688.0000, NB Loss: -67624272.0000, Bernoulli Loss: 259564.0000, KL Loss: 109014.1875
Epoch [60/200] - Loss: -67261648.0000, NB Loss: -67609296.0000, Bernoulli Loss: 236141.6094, KL Loss: 111503.3906
Epoch [61/200] - Loss: -67310696.0000, NB Loss: -67627936.0000, Bernoulli Loss: 202374.4375, KL Loss: 114862.9688
Epoch [62/200] - Loss: -67335416.0000, NB Loss: -67630520.0000, Bernoulli Loss: 177213.7188, KL Loss: 117890.0781
Epoch [63/200] - Loss: -67356088.0000, NB Loss: -67631040.0000, Bernoulli Loss: 154203.0781, KL Loss: 120750.2344
Epoch [64/200] - Loss: -67372968.0000, NB Loss: -67627792.0000, Bernoulli Loss: 130869.1250, KL Loss: 123951.5156
Epoch [65/200] - Loss: -67389072.0000, NB Loss: -67624128.0000, Bernoulli Loss: 108122.1172, KL Loss: 126938.1250
Epoch [66/200] - Loss: -67421224.0000, NB Loss: -67631288.0000, Bernoulli Loss: 79792.6406, KL Loss: 130275.5938
Epoch [67/200] - Loss: -67439248.0000, NB Loss: -67629464.0000, Bernoulli Loss: 56093.1172, KL Loss: 134119.1406
Epoch [68/200] - Loss: -67457688.0000, NB Loss: -67623904.0000, Bernoulli Loss: 28703.0898, KL Loss: 137514.7188
Epoch [69/200] - Loss: -67485224.0000, NB Loss: -67630688.0000, Bernoulli Loss: 4786.8438, KL Loss: 140677.3750
Epoch [70/200] - Loss: -67505640.0000, NB Loss: -67633200.0000, Bernoulli Loss: -15895.0527, KL Loss: 143459.5000
Epoch [71/200] - Loss: -67526624.0000, NB Loss: -67633720.0000, Bernoulli Loss: -40373.2188, KL Loss: 147473.3438
Epoch [72/200] - Loss: -67546872.0000, NB Loss: -67634488.0000, Bernoulli Loss: -62944.6719, KL Loss: 150560.2500
Epoch [73/200] - Loss: -67571968.0000, NB Loss: -67636104.0000, Bernoulli Loss: -90008.9844, KL Loss: 154146.9219
Epoch [74/200] - Loss: -67587512.0000, NB Loss: -67635976.0000, Bernoulli Loss: -109164.0234, KL Loss: 157635.6250
Epoch [75/200] - Loss: -67610744.0000, NB Loss: -67636360.0000, Bernoulli Loss: -135816.4844, KL Loss: 161435.1094
Epoch [76/200] - Loss: -67621440.0000, NB Loss: -67629992.0000, Bernoulli Loss: -156812.1250, KL Loss: 165366.5938
Epoch [77/200] - Loss: -67648232.0000, NB Loss: -67634920.0000, Bernoulli Loss: -181777.6094, KL Loss: 168466.2500
Epoch [78/200] - Loss: -67664680.0000, NB Loss: -67632112.0000, Bernoulli Loss: -205101.2344, KL Loss: 172532.1250
Epoch [79/200] - Loss: -67676224.0000, NB Loss: -67627968.0000, Bernoulli Loss: -224955.6562, KL Loss: 176696.1875
Epoch [80/200] - Loss: -67701512.0000, NB Loss: -67634168.0000, Bernoulli Loss: -247906.7500, KL Loss: 180559.0938
Epoch [81/200] - Loss: -67722976.0000, NB Loss: -67635360.0000, Bernoulli Loss: -272048.7500, KL Loss: 184434.6875
Epoch [82/200] - Loss: -67731288.0000, NB Loss: -67628320.0000, Bernoulli Loss: -292596.2188, KL Loss: 189633.8750
Epoch [83/200] - Loss: -67743064.0000, NB Loss: -67617640.0000, Bernoulli Loss: -319298.9688, KL Loss: 193871.0469
Epoch [84/200] - Loss: -67786848.0000, NB Loss: -67634344.0000, Bernoulli Loss: -352027.7500, KL Loss: 199519.5781
Epoch [85/200] - Loss: -67781200.0000, NB Loss: -67616576.0000, Bernoulli Loss: -367907.3750, KL Loss: 203276.7344
Epoch [86/200] - Loss: -67818040.0000, NB Loss: -67630720.0000, Bernoulli Loss: -396463.5312, KL Loss: 209144.1250
Epoch [87/200] - Loss: -67839176.0000, NB Loss: -67634960.0000, Bernoulli Loss: -417832.6250, KL Loss: 213613.7344
Epoch [88/200] - Loss: -67855912.0000, NB Loss: -67626928.0000, Bernoulli Loss: -447625.3125, KL Loss: 218640.3438
Epoch [89/200] - Loss: -67877280.0000, NB Loss: -67627120.0000, Bernoulli Loss: -472432.8750, KL Loss: 222271.4375
Epoch [90/200] - Loss: -67902936.0000, NB Loss: -67632496.0000, Bernoulli Loss: -499404.8750, KL Loss: 228964.3906
Epoch [91/200] - Loss: -67914600.0000, NB Loss: -67622984.0000, Bernoulli Loss: -527676.0000, KL Loss: 236056.7500
Epoch [92/200] - Loss: -67937576.0000, NB Loss: -67619488.0000, Bernoulli Loss: -558293.0000, KL Loss: 240211.9531
Epoch [93/200] - Loss: -67963056.0000, NB Loss: -67629344.0000, Bernoulli Loss: -579833.3125, KL Loss: 246121.3125
Epoch [94/200] - Loss: -67989704.0000, NB Loss: -67627376.0000, Bernoulli Loss: -614482.2500, KL Loss: 252149.2344
Epoch [95/200] - Loss: -68022864.0000, NB Loss: -67635192.0000, Bernoulli Loss: -647550.8125, KL Loss: 259881.3125
Epoch [96/200] - Loss: -68045768.0000, NB Loss: -67634736.0000, Bernoulli Loss: -675336.0625, KL Loss: 264303.2500
Epoch [97/200] - Loss: -68064152.0000, NB Loss: -67630320.0000, Bernoulli Loss: -705860.8750, KL Loss: 272029.4688
Epoch [98/200] - Loss: -68101072.0000, NB Loss: -67637568.0000, Bernoulli Loss: -742314.4375, KL Loss: 278810.3438
Epoch [99/200] - Loss: -68106008.0000, NB Loss: -67624256.0000, Bernoulli Loss: -767452.9375, KL Loss: 285707.5625
Epoch [100/200] - Loss: -68149712.0000, NB Loss: -67634160.0000, Bernoulli Loss: -808014.0000, KL Loss: 292466.4688
Epoch [101/200] - Loss: -68184736.0000, NB Loss: -67636328.0000, Bernoulli Loss: -851360.3750, KL Loss: 302950.8438
Epoch [102/200] - Loss: -68209576.0000, NB Loss: -67637936.0000, Bernoulli Loss: -881389.3750, KL Loss: 309749.6875
Epoch [103/200] - Loss: -68241976.0000, NB Loss: -67635376.0000, Bernoulli Loss: -925296.0000, KL Loss: 318696.7500
Epoch [104/200] - Loss: -68277008.0000, NB Loss: -67634776.0000, Bernoulli Loss: -971931.7500, KL Loss: 329698.6250
Epoch [105/200] - Loss: -68282856.0000, NB Loss: -67612784.0000, Bernoulli Loss: -1008791.3750, KL Loss: 338718.8125
Epoch [106/200] - Loss: -68333328.0000, NB Loss: -67634224.0000, Bernoulli Loss: -1048399.8750, KL Loss: 349292.0000
Epoch [107/200] - Loss: -68366144.0000, NB Loss: -67634448.0000, Bernoulli Loss: -1090386.1250, KL Loss: 358688.3438
Epoch [108/200] - Loss: -68394688.0000, NB Loss: -67627928.0000, Bernoulli Loss: -1137018.2500, KL Loss: 370258.7812
Epoch [109/200] - Loss: -68405848.0000, NB Loss: -67612976.0000, Bernoulli Loss: -1171127.2500, KL Loss: 378254.9688
Epoch [110/200] - Loss: -68462016.0000, NB Loss: -67634424.0000, Bernoulli Loss: -1216496.6250, KL Loss: 388900.0938
Epoch [111/200] - Loss: -68462696.0000, NB Loss: -67611944.0000, Bernoulli Loss: -1248750.7500, KL Loss: 397999.1562
Epoch [112/200] - Loss: -68510432.0000, NB Loss: -67626472.0000, Bernoulli Loss: -1293749.2500, KL Loss: 409789.2500
Epoch [113/200] - Loss: -68535744.0000, NB Loss: -67626128.0000, Bernoulli Loss: -1331610.8750, KL Loss: 421991.2812
Epoch [114/200] - Loss: -68565320.0000, NB Loss: -67632768.0000, Bernoulli Loss: -1361431.2500, KL Loss: 428876.4062
Epoch [115/200] - Loss: -68570488.0000, NB Loss: -67612520.0000, Bernoulli Loss: -1394830.8750, KL Loss: 436860.0938
Epoch [116/200] - Loss: -68605248.0000, NB Loss: -67628896.0000, Bernoulli Loss: -1422617.2500, KL Loss: 446266.6250
Epoch [117/200] - Loss: -68634792.0000, NB Loss: -67630216.0000, Bernoulli Loss: -1459405.5000, KL Loss: 454829.2500
Epoch [118/200] - Loss: -68653496.0000, NB Loss: -67629136.0000, Bernoulli Loss: -1488144.1250, KL Loss: 463785.7188
Epoch [119/200] - Loss: -68655880.0000, NB Loss: -67615376.0000, Bernoulli Loss: -1509923.5000, KL Loss: 469416.7188
Epoch [120/200] - Loss: -68657248.0000, NB Loss: -67604688.0000, Bernoulli Loss: -1529152.3750, KL Loss: 476590.3125
Epoch [121/200] - Loss: -68678280.0000, NB Loss: -67612168.0000, Bernoulli Loss: -1548635.0000, KL Loss: 482522.9375
Epoch [122/200] - Loss: -68696360.0000, NB Loss: -67609968.0000, Bernoulli Loss: -1575287.0000, KL Loss: 488898.0312
Epoch [123/200] - Loss: -68708680.0000, NB Loss: -67606272.0000, Bernoulli Loss: -1595087.5000, KL Loss: 492683.8438
Epoch [124/200] - Loss: -68717320.0000, NB Loss: -67591520.0000, Bernoulli Loss: -1625101.0000, KL Loss: 499305.2188
Epoch [125/200] - Loss: -68745184.0000, NB Loss: -67604216.0000, Bernoulli Loss: -1642790.3750, KL Loss: 501822.7812
Epoch [126/200] - Loss: -68762688.0000, NB Loss: -67602736.0000, Bernoulli Loss: -1667169.0000, KL Loss: 507214.1562
Epoch [127/200] - Loss: -68772440.0000, NB Loss: -67602608.0000, Bernoulli Loss: -1680038.2500, KL Loss: 510207.2500
Epoch [128/200] - Loss: -68771632.0000, NB Loss: -67590544.0000, Bernoulli Loss: -1693253.3750, KL Loss: 512169.1250
Epoch [129/200] - Loss: -68754672.0000, NB Loss: -67553336.0000, Bernoulli Loss: -1718390.3750, KL Loss: 517053.8125
Epoch [130/200] - Loss: -68692144.0000, NB Loss: -67480040.0000, Bernoulli Loss: -1730711.8750, KL Loss: 518605.0000
Epoch [131/200] - Loss: -68614552.0000, NB Loss: -67393048.0000, Bernoulli Loss: -1740153.0000, KL Loss: 518647.3125
Epoch [132/200] - Loss: -68667560.0000, NB Loss: -67434152.0000, Bernoulli Loss: -1741287.8750, KL Loss: 507876.0625
Epoch [133/200] - Loss: -68740472.0000, NB Loss: -67505824.0000, Bernoulli Loss: -1729842.3750, KL Loss: 495189.2188
Epoch [134/200] - Loss: -68778016.0000, NB Loss: -67558544.0000, Bernoulli Loss: -1706809.8750, KL Loss: 487337.1562
Epoch [135/200] - Loss: -68780488.0000, NB Loss: -67586344.0000, Bernoulli Loss: -1671507.5000, KL Loss: 477357.7500
Epoch [136/200] - Loss: -68747544.0000, NB Loss: -67586408.0000, Bernoulli Loss: -1635062.3750, KL Loss: 473928.1875
Epoch [137/200] - Loss: -68727056.0000, NB Loss: -67587784.0000, Bernoulli Loss: -1605956.7500, KL Loss: 466689.7500
Epoch [138/200] - Loss: -68708768.0000, NB Loss: -67584400.0000, Bernoulli Loss: -1587348.5000, KL Loss: 462982.0625
Epoch [139/200] - Loss: -68728520.0000, NB Loss: -67592312.0000, Bernoulli Loss: -1597222.2500, KL Loss: 461013.8750
Epoch [140/200] - Loss: -68734896.0000, NB Loss: -67591216.0000, Bernoulli Loss: -1602332.0000, KL Loss: 458655.4375
Epoch [141/200] - Loss: -68739616.0000, NB Loss: -67590704.0000, Bernoulli Loss: -1605742.1250, KL Loss: 456828.6250
Epoch [142/200] - Loss: -68770840.0000, NB Loss: -67592152.0000, Bernoulli Loss: -1637523.6250, KL Loss: 458828.6875
Epoch [143/200] - Loss: -68803184.0000, NB Loss: -67601440.0000, Bernoulli Loss: -1662847.2500, KL Loss: 461103.3125
Epoch [144/200] - Loss: -68806656.0000, NB Loss: -67579928.0000, Bernoulli Loss: -1691228.7500, KL Loss: 464504.4688
Epoch [145/200] - Loss: -68845656.0000, NB Loss: -67589800.0000, Bernoulli Loss: -1723042.5000, KL Loss: 467187.4375
Epoch [146/200] - Loss: -68888632.0000, NB Loss: -67598080.0000, Bernoulli Loss: -1759069.5000, KL Loss: 468521.5312
Epoch [147/200] - Loss: -68876328.0000, NB Loss: -67566160.0000, Bernoulli Loss: -1780410.0000, KL Loss: 470238.5938
Epoch [148/200] - Loss: -68870544.0000, NB Loss: -67537424.0000, Bernoulli Loss: -1806044.2500, KL Loss: 472924.5000
Epoch [149/200] - Loss: -68914664.0000, NB Loss: -67566744.0000, Bernoulli Loss: -1816257.5000, KL Loss: 468334.2812
Epoch [150/200] - Loss: -68939368.0000, NB Loss: -67568456.0000, Bernoulli Loss: -1840286.0000, KL Loss: 469379.2188
Epoch [151/200] - Loss: -68920984.0000, NB Loss: -67541760.0000, Bernoulli Loss: -1844694.3750, KL Loss: 465475.8438
Epoch [152/200] - Loss: -68933312.0000, NB Loss: -67534280.0000, Bernoulli Loss: -1859779.2500, KL Loss: 460744.6875
Epoch [153/200] - Loss: -68966888.0000, NB Loss: -67559128.0000, Bernoulli Loss: -1863314.6250, KL Loss: 455551.4375
Epoch [154/200] - Loss: -68993824.0000, NB Loss: -67572864.0000, Bernoulli Loss: -1870311.1250, KL Loss: 449348.3750
Epoch [155/200] - Loss: -69015152.0000, NB Loss: -67589112.0000, Bernoulli Loss: -1860160.8750, KL Loss: 434122.1250
Epoch [156/200] - Loss: -69030880.0000, NB Loss: -67603224.0000, Bernoulli Loss: -1853728.3750, KL Loss: 426071.1875
Epoch [157/200] - Loss: -69035256.0000, NB Loss: -67608272.0000, Bernoulli Loss: -1843363.1250, KL Loss: 416376.5312
Epoch [158/200] - Loss: -69033088.0000, NB Loss: -67608328.0000, Bernoulli Loss: -1832896.2500, KL Loss: 408132.7500
Epoch [159/200] - Loss: -69025352.0000, NB Loss: -67600536.0000, Bernoulli Loss: -1829244.5000, KL Loss: 404430.1250
Epoch [160/200] - Loss: -69029184.0000, NB Loss: -67603216.0000, Bernoulli Loss: -1827270.8750, KL Loss: 401304.4062
Epoch [161/200] - Loss: -69032496.0000, NB Loss: -67602832.0000, Bernoulli Loss: -1826780.0000, KL Loss: 397118.8125
Epoch [162/200] - Loss: -69041000.0000, NB Loss: -67604432.0000, Bernoulli Loss: -1830836.8750, KL Loss: 394275.0625
Epoch [163/200] - Loss: -69049184.0000, NB Loss: -67598904.0000, Bernoulli Loss: -1843922.8750, KL Loss: 393636.8750
Epoch [164/200] - Loss: -69079312.0000, NB Loss: -67602480.0000, Bernoulli Loss: -1869545.7500, KL Loss: 392712.3438
Epoch [165/200] - Loss: -69096280.0000, NB Loss: -67600360.0000, Bernoulli Loss: -1888226.2500, KL Loss: 392306.7188
Epoch [166/200] - Loss: -69110616.0000, NB Loss: -67602976.0000, Bernoulli Loss: -1902448.7500, KL Loss: 394811.6875
Epoch [167/200] - Loss: -69125600.0000, NB Loss: -67598984.0000, Bernoulli Loss: -1920486.7500, KL Loss: 393874.5625
Epoch [168/200] - Loss: -69131176.0000, NB Loss: -67588144.0000, Bernoulli Loss: -1941043.7500, KL Loss: 398009.9375
Epoch [169/200] - Loss: -69128064.0000, NB Loss: -67579224.0000, Bernoulli Loss: -1947137.3750, KL Loss: 398293.5000
Epoch [170/200] - Loss: -69135632.0000, NB Loss: -67569216.0000, Bernoulli Loss: -1969258.3750, KL Loss: 402843.6562
Epoch [171/200] - Loss: -69130376.0000, NB Loss: -67553784.0000, Bernoulli Loss: -1977770.0000, KL Loss: 401173.2188
Epoch [172/200] - Loss: -69137088.0000, NB Loss: -67555176.0000, Bernoulli Loss: -1983530.6250, KL Loss: 401612.3125
Epoch [173/200] - Loss: -69157344.0000, NB Loss: -67566864.0000, Bernoulli Loss: -1991232.2500, KL Loss: 400753.5938
Epoch [174/200] - Loss: -69194296.0000, NB Loss: -67601400.0000, Bernoulli Loss: -1988436.7500, KL Loss: 395546.0625
Epoch [175/200] - Loss: -69190344.0000, NB Loss: -67597568.0000, Bernoulli Loss: -1986990.2500, KL Loss: 394213.3750
Epoch [176/200] - Loss: -69199064.0000, NB Loss: -67594760.0000, Bernoulli Loss: -1991216.0000, KL Loss: 386908.2500
Epoch [177/200] - Loss: -69208536.0000, NB Loss: -67600952.0000, Bernoulli Loss: -1993878.1250, KL Loss: 386292.7812
Epoch [178/200] - Loss: -69210592.0000, NB Loss: -67598752.0000, Bernoulli Loss: -1994626.6250, KL Loss: 382786.0000
Epoch [179/200] - Loss: -69235920.0000, NB Loss: -67608192.0000, Bernoulli Loss: -2008804.5000, KL Loss: 381080.1250
Epoch [180/200] - Loss: -69237360.0000, NB Loss: -67604504.0000, Bernoulli Loss: -2010934.7500, KL Loss: 378076.1250
Epoch [181/200] - Loss: -69240144.0000, NB Loss: -67598184.0000, Bernoulli Loss: -2019355.5000, KL Loss: 377388.6250
Epoch [182/200] - Loss: -69244808.0000, NB Loss: -67599616.0000, Bernoulli Loss: -2019737.7500, KL Loss: 374542.1250
Epoch [183/200] - Loss: -69262904.0000, NB Loss: -67595960.0000, Bernoulli Loss: -2039270.2500, KL Loss: 372327.1562
Epoch [184/200] - Loss: -69273936.0000, NB Loss: -67601904.0000, Bernoulli Loss: -2042770.3750, KL Loss: 370734.7500
Epoch [185/200] - Loss: -69290304.0000, NB Loss: -67603200.0000, Bernoulli Loss: -2057632.2500, KL Loss: 370527.1875
Epoch [186/200] - Loss: -69300520.0000, NB Loss: -67603448.0000, Bernoulli Loss: -2066880.3750, KL Loss: 369810.8750
Epoch [187/200] - Loss: -69290472.0000, NB Loss: -67590248.0000, Bernoulli Loss: -2067750.7500, KL Loss: 367528.4688
Epoch [188/200] - Loss: -69300928.0000, NB Loss: -67603312.0000, Bernoulli Loss: -2060195.2500, KL Loss: 362573.7500
Epoch [189/200] - Loss: -69295720.0000, NB Loss: -67612048.0000, Bernoulli Loss: -2040853.0000, KL Loss: 357187.8438
Epoch [190/200] - Loss: -69281504.0000, NB Loss: -67606104.0000, Bernoulli Loss: -2029385.2500, KL Loss: 353982.1250
Epoch [191/200] - Loss: -69276832.0000, NB Loss: -67603584.0000, Bernoulli Loss: -2023345.8750, KL Loss: 350097.6875
Epoch [192/200] - Loss: -69260960.0000, NB Loss: -67602272.0000, Bernoulli Loss: -2005904.2500, KL Loss: 347213.1250
Epoch [193/200] - Loss: -69248296.0000, NB Loss: -67586512.0000, Bernoulli Loss: -2009056.0000, KL Loss: 347268.1250
Epoch [194/200] - Loss: -69229104.0000, NB Loss: -67572040.0000, Bernoulli Loss: -2004823.3750, KL Loss: 347756.1250
Epoch [195/200] - Loss: -69229032.0000, NB Loss: -67565784.0000, Bernoulli Loss: -2010788.2500, KL Loss: 347540.5312
Epoch [196/200] - Loss: -69240488.0000, NB Loss: -67564792.0000, Bernoulli Loss: -2026445.8750, KL Loss: 350755.7812
Epoch [197/200] - Loss: -69253456.0000, NB Loss: -67561248.0000, Bernoulli Loss: -2043710.8750, KL Loss: 351504.6875
Epoch [198/200] - Loss: -69254480.0000, NB Loss: -67566088.0000, Bernoulli Loss: -2039326.7500, KL Loss: 350936.8750
Epoch [199/200] - Loss: -69239288.0000, NB Loss: -67564704.0000, Bernoulli Loss: -2022128.6250, KL Loss: 347541.1875
Epoch [200/200] - Loss: -69240008.0000, NB Loss: -67565808.0000, Bernoulli Loss: -2021767.8750, KL Loss: 347568.6875
</pre></div>
</div>
</div>
</div>
<section id="performance-loss-functions">
<h4>Performance loss functions<a class="headerlink" href="#performance-loss-functions" title="Link to this heading">#</a></h4>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Function for the plots</span>
<span class="k">def</span><span class="w"> </span><span class="nf">plot_losses</span><span class="p">(</span><span class="n">total_losses</span><span class="p">,</span> <span class="n">nb_losses</span><span class="p">,</span><span class="n">bernoulli_losses</span><span class="p">,</span> <span class="n">kl_losses</span><span class="p">):</span>
    <span class="n">epochs</span> <span class="o">=</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">total_losses</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>

    <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">epochs</span><span class="p">,</span> <span class="n">total_losses</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Total Loss&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Epoch&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Loss&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Total Loss&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

    <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">epochs</span><span class="p">,</span> <span class="n">nb_losses</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Negative Binomial Loss&#39;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;orange&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Epoch&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Loss&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;NB Loss&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
    
    <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">epochs</span><span class="p">,</span> <span class="n">bernoulli_losses</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Bernoulli Loss&#39;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;orange&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Epoch&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Loss&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Bernoulli Loss&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

    <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">epochs</span><span class="p">,</span> <span class="n">kl_losses</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;KL Divergence Loss&#39;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;green&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Epoch&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Loss&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;KL Loss&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p>The VAE + GAT model for single-cell data uses a composite loss function made up of three components:</p>
<ol class="arabic simple">
<li><p><strong>Negative Binomial Loss (NB Loss)</strong><br />
This loss captures the reconstruction error assuming gene expression follows a negative binomial distribution. It effectively models the overdispersed count data typical of scRNA-seq.<br />
The loss decreases rapidly in the first 25 epochs and then stabilizes, as shown in the second plot.</p></li>
<li><p><strong>Bernoulli Loss (BL or Dropout Loss)</strong><br />
This component models dropout events (zeros due to technical effects rather than biology) using a Bernoulli likelihood.<br />
The plot shows a steady decrease in Bernoulli Loss, becoming negative due to log-likelihood scaling, indicating improved modeling of dropouts over time.</p></li>
<li><p><strong>KL Divergence Loss</strong><br />
This term regularizes the latent space by penalizing deviation from a standard normal prior.<br />
Initially low, it gradually increases as the model learns meaningful latent representations and then decreases after epoch ~150, indicating convergence in the latent distribution.</p></li>
</ol>
<p>The <strong>Total Loss</strong> combines all three components:<br />
<strong>Total Loss = NB Loss + BL + β × KL Divergence</strong>,<br />
where <code class="docutils literal notranslate"><span class="pre">β</span></code> is a weight parameter balancing the influence of KL divergence.</p>
<p>Each component contributes uniquely to training:</p>
<ul class="simple">
<li><p>NB Loss ensures accurate gene count modeling,</p></li>
<li><p>Bernoulli Loss adjusts for technical zeros,</p></li>
<li><p>KL Divergence enforces structure in the latent space.<br />
This multi-part objective leads to better generalization and clustering performance in the downstream cell-type analysis.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plot_losses</span><span class="p">(</span><span class="n">total_losses</span><span class="p">,</span> <span class="n">nb_losses</span><span class="p">,</span> <span class="n">bernoulli_losses</span><span class="p">,</span> <span class="n">kl_losses</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/658d059d60e2900fcf32f4a9aa9df7dab727f3b89603f802cd7334b2f2227a54.png" src="_images/658d059d60e2900fcf32f4a9aa9df7dab727f3b89603f802cd7334b2f2227a54.png" />
<img alt="_images/eda344f6a22f43fc4ba70d3042cf972881654f5a33643e553fa4e7c3495e9cae.png" src="_images/eda344f6a22f43fc4ba70d3042cf972881654f5a33643e553fa4e7c3495e9cae.png" />
<img alt="_images/ef48ca1f09ea12a543efb6817a0fad51b7702cbb4a95e9980c5f8e9a5561141b.png" src="_images/ef48ca1f09ea12a543efb6817a0fad51b7702cbb4a95e9980c5f8e9a5561141b.png" />
<img alt="_images/6f6981384600554a329ea32304a1e39d9ddccbb9e3330be696d430a3cb6c4b11.png" src="_images/6f6981384600554a329ea32304a1e39d9ddccbb9e3330be696d430a3cb6c4b11.png" />
</div>
</div>
</section>
<section id="clusters-of-vae">
<h4>Clusters of VAE<a class="headerlink" href="#clusters-of-vae" title="Link to this heading">#</a></h4>
<p>Leiden Clustering (Top Row)</p>
<ul class="simple">
<li><p><strong>Resolution 0.4</strong>:</p>
<ul>
<li><p>Clusters are relatively coarse (few, larger groups).</p></li>
<li><p>Silhouette: 0.20, CH: 510.8 (best CH score among all).</p></li>
<li><p>Indicates well-separated and compact clusters at this resolution.</p></li>
</ul>
</li>
<li><p><strong>Resolution 0.6</strong>:</p>
<ul>
<li><p>More refined clusters emerge, with a higher number of groups.</p></li>
<li><p>Silhouette: 0.17, CH: 443.5.</p></li>
<li><p>Slight drop in metrics, but more granularity in cell-type identification.</p></li>
</ul>
</li>
<li><p><strong>Resolution 0.8</strong>:</p>
<ul>
<li><p>Over-clustering is evident: many small groups with reduced compactness.</p></li>
<li><p>Silhouette: 0.08, CH: 229.0.</p></li>
<li><p>Lower scores suggest diminished quality in cluster separation.</p></li>
</ul>
</li>
</ul>
<p>Louvain Clustering (Bottom Row)</p>
<ul class="simple">
<li><p><strong>Resolution 0.4</strong>:</p>
<ul>
<li><p>Failed clustering: all cells assigned to a single cluster.</p></li>
<li><p>Silhouette: -1.00, CH: -1.0 — invalid values indicate no real clustering.</p></li>
</ul>
</li>
<li><p><strong>Resolution 0.6</strong>:</p>
<ul>
<li><p>Slight improvement; two major clusters are formed.</p></li>
<li><p>Silhouette: 0.11, CH: 206.1.</p></li>
<li><p>Performance still inferior to Leiden at the same resolution.</p></li>
</ul>
</li>
<li><p><strong>Resolution 0.8</strong>:</p>
<ul>
<li><p>More distinct clusters emerge, though still less well-defined than Leiden.</p></li>
<li><p>Silhouette: 0.06, CH: 230.6.</p></li>
<li><p>Moderate separation, but compactness is weaker.</p></li>
</ul>
</li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">X_data</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
    <span class="n">X_data</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">X_data</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>


<span class="n">device</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="n">vae_model</span><span class="o">.</span><span class="n">parameters</span><span class="p">())</span><span class="o">.</span><span class="n">device</span>
<span class="n">X_data</span> <span class="o">=</span> <span class="n">X_data</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

<span class="c1"># Latent representations</span>
<span class="n">mu</span><span class="p">,</span> <span class="n">log_var</span> <span class="o">=</span> <span class="n">vae_model</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">X_data</span><span class="p">)</span>
<span class="n">clustering_results</span> <span class="o">=</span> <span class="n">clustering_and_metrics</span><span class="p">(</span><span class="n">mu</span><span class="p">,</span> <span class="n">X_data</span><span class="p">)</span> <span class="c1">#clustering</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/d01ba5f34147bb5aec472032ab887bc9fbaa9382b3c36256fd749b199598da0d.png" src="_images/d01ba5f34147bb5aec472032ab887bc9fbaa9382b3c36256fd749b199598da0d.png" />
</div>
</div>
</section>
</section>
<section id="evaluation-metrics">
<h3>Evaluation Metrics<a class="headerlink" href="#evaluation-metrics" title="Link to this heading">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">evaluate_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">X_data</span><span class="p">):</span>
    <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
        <span class="n">recon</span><span class="p">,</span> <span class="n">mu</span><span class="p">,</span> <span class="n">log_var</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">X_data</span><span class="p">)</span>
    <span class="n">mu_np</span> <span class="o">=</span> <span class="n">mu</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
    <span class="n">X_np</span> <span class="o">=</span> <span class="n">X_data</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
    <span class="n">recon_np</span> <span class="o">=</span> <span class="n">recon</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>

    <span class="c1"># Reconstruction metrics</span>
    <span class="n">mse</span> <span class="o">=</span> <span class="n">mean_squared_error</span><span class="p">(</span><span class="n">X_np</span><span class="o">.</span><span class="n">flatten</span><span class="p">(),</span> <span class="n">recon_np</span><span class="o">.</span><span class="n">flatten</span><span class="p">())</span>
    <span class="n">pearson_corr</span> <span class="o">=</span> <span class="n">pearsonr</span><span class="p">(</span><span class="n">X_np</span><span class="o">.</span><span class="n">flatten</span><span class="p">(),</span> <span class="n">recon_np</span><span class="o">.</span><span class="n">flatten</span><span class="p">())[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">latent_normality_pval</span> <span class="o">=</span> <span class="n">normaltest</span><span class="p">(</span><span class="n">mu_np</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">pvalue</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>

    <span class="c1"># Cluster analysis</span>
    <span class="n">adata_latent</span> <span class="o">=</span> <span class="n">sc</span><span class="o">.</span><span class="n">AnnData</span><span class="p">(</span><span class="n">X</span><span class="o">=</span><span class="n">mu_np</span><span class="p">)</span>
    <span class="n">sc</span><span class="o">.</span><span class="n">pp</span><span class="o">.</span><span class="n">neighbors</span><span class="p">(</span><span class="n">adata_latent</span><span class="p">,</span> <span class="n">n_neighbors</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">use_rep</span><span class="o">=</span><span class="s2">&quot;X&quot;</span><span class="p">)</span>
    <span class="n">sc</span><span class="o">.</span><span class="n">tl</span><span class="o">.</span><span class="n">umap</span><span class="p">(</span><span class="n">adata_latent</span><span class="p">)</span>

    <span class="n">methods</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;leiden&quot;</span><span class="p">,</span> <span class="s2">&quot;louvain&quot;</span><span class="p">]</span>
    <span class="n">resolutions</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.4</span><span class="p">,</span> <span class="mf">0.6</span><span class="p">,</span> <span class="mf">0.8</span><span class="p">]</span>
    <span class="n">records</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="k">for</span> <span class="n">method</span> <span class="ow">in</span> <span class="n">methods</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">res</span> <span class="ow">in</span> <span class="n">resolutions</span><span class="p">:</span>
            <span class="n">key</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">method</span><span class="si">}</span><span class="s2">_r</span><span class="si">{</span><span class="n">res</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="k">if</span> <span class="n">method</span> <span class="o">==</span> <span class="s2">&quot;leiden&quot;</span><span class="p">:</span>
                <span class="n">sc</span><span class="o">.</span><span class="n">tl</span><span class="o">.</span><span class="n">leiden</span><span class="p">(</span><span class="n">adata_latent</span><span class="p">,</span> <span class="n">resolution</span><span class="o">=</span><span class="n">res</span><span class="p">,</span> <span class="n">key_added</span><span class="o">=</span><span class="n">key</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">sc</span><span class="o">.</span><span class="n">tl</span><span class="o">.</span><span class="n">louvain</span><span class="p">(</span><span class="n">adata_latent</span><span class="p">,</span> <span class="n">resolution</span><span class="o">=</span><span class="n">res</span><span class="p">,</span> <span class="n">key_added</span><span class="o">=</span><span class="n">key</span><span class="p">)</span>

            <span class="n">labels</span> <span class="o">=</span> <span class="n">adata_latent</span><span class="o">.</span><span class="n">obs</span><span class="p">[</span><span class="n">key</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span><span class="o">.</span><span class="n">values</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">labels</span><span class="p">))</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
                <span class="n">silh</span> <span class="o">=</span> <span class="n">silhouette_score</span><span class="p">(</span><span class="n">adata_latent</span><span class="o">.</span><span class="n">obsm</span><span class="p">[</span><span class="s2">&quot;X_umap&quot;</span><span class="p">],</span> <span class="n">labels</span><span class="p">)</span>
                <span class="n">ch</span> <span class="o">=</span> <span class="n">calinski_harabasz_score</span><span class="p">(</span><span class="n">adata_latent</span><span class="o">.</span><span class="n">obsm</span><span class="p">[</span><span class="s2">&quot;X_umap&quot;</span><span class="p">],</span> <span class="n">labels</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">silh</span><span class="p">,</span> <span class="n">ch</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span>

            <span class="n">records</span><span class="o">.</span><span class="n">append</span><span class="p">({</span>
                <span class="s2">&quot;Metric&quot;</span><span class="p">:</span> <span class="s2">&quot;Silhouette Score&quot;</span><span class="p">,</span>
                <span class="s2">&quot;VAE&quot;</span><span class="p">:</span> <span class="n">silh</span><span class="p">,</span>
                <span class="s2">&quot;Method&quot;</span><span class="p">:</span> <span class="n">method</span><span class="p">,</span>
                <span class="s2">&quot;Resolution&quot;</span><span class="p">:</span> <span class="n">res</span>
            <span class="p">})</span>
            <span class="n">records</span><span class="o">.</span><span class="n">append</span><span class="p">({</span>
                <span class="s2">&quot;Metric&quot;</span><span class="p">:</span> <span class="s2">&quot;Calinski-Harabasz Index&quot;</span><span class="p">,</span>
                <span class="s2">&quot;VAE&quot;</span><span class="p">:</span> <span class="n">ch</span><span class="p">,</span>
                <span class="s2">&quot;Method&quot;</span><span class="p">:</span> <span class="n">method</span><span class="p">,</span>
                <span class="s2">&quot;Resolution&quot;</span><span class="p">:</span> <span class="n">res</span>
            <span class="p">})</span>

    <span class="c1"># df</span>
    <span class="n">records</span><span class="o">.</span><span class="n">extend</span><span class="p">([</span>
        <span class="p">{</span><span class="s2">&quot;Metric&quot;</span><span class="p">:</span> <span class="s2">&quot;MSE&quot;</span><span class="p">,</span> <span class="s2">&quot;VAE&quot;</span><span class="p">:</span> <span class="n">mse</span><span class="p">,</span> <span class="s2">&quot;Method&quot;</span><span class="p">:</span> <span class="kc">None</span><span class="p">,</span> <span class="s2">&quot;Resolution&quot;</span><span class="p">:</span> <span class="kc">None</span><span class="p">},</span>
        <span class="p">{</span><span class="s2">&quot;Metric&quot;</span><span class="p">:</span> <span class="s2">&quot;Pearson Correlation&quot;</span><span class="p">,</span> <span class="s2">&quot;VAE&quot;</span><span class="p">:</span> <span class="n">pearson_corr</span><span class="p">,</span> <span class="s2">&quot;Method&quot;</span><span class="p">:</span> <span class="kc">None</span><span class="p">,</span> <span class="s2">&quot;Resolution&quot;</span><span class="p">:</span> <span class="kc">None</span><span class="p">},</span>
        <span class="p">{</span><span class="s2">&quot;Metric&quot;</span><span class="p">:</span> <span class="s2">&quot;Latent Space Normality (p-value)&quot;</span><span class="p">,</span> <span class="s2">&quot;VAE&quot;</span><span class="p">:</span> <span class="n">latent_normality_pval</span><span class="p">,</span> <span class="s2">&quot;Method&quot;</span><span class="p">:</span> <span class="kc">None</span><span class="p">,</span> <span class="s2">&quot;Resolution&quot;</span><span class="p">:</span> <span class="kc">None</span><span class="p">}</span>
    <span class="p">])</span>

    <span class="k">return</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">records</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">device</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="n">vae_model</span><span class="o">.</span><span class="n">parameters</span><span class="p">())</span><span class="o">.</span><span class="n">device</span>
<span class="n">X_data_tensor</span> <span class="o">=</span> <span class="n">X_data_tensor</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
<span class="n">metrics_df</span> <span class="o">=</span> <span class="n">evaluate_model</span><span class="p">(</span><span class="n">vae_model</span><span class="p">,</span> <span class="n">X_data_tensor</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="admonition-calinski-harabaz-index admonition">
<p class="admonition-title">Calinski-Harabaz Index</p>
<p>The Calinski-Harabasz Index, also known as the Variance Ratio Criterion, is a metric used to evaluate the quality of clustering results. It measures how well the clusters are separated and how compact they are. Specifically, it is the ratio of the sum of between-cluster dispersion to the sum of within-cluster dispersion. A higher Calinski-Harabasz score indicates better-defined clusters</p>
<p>The Calinski-Harabasz Index (CH) is defined as:</p>
<div class="math notranslate nohighlight">
\[
\text{CH} = \frac{ \text{Tr}(B_k) / (k - 1) }{ \text{Tr}(W_k) / (n - k) }
\]</div>
<p>Where:</p>
<ul class="simple">
<li><p>( \text{Tr}(B_k) ) is the trace of the between-cluster dispersion matrix</p></li>
<li><p>( \text{Tr}(W_k) ) is the trace of the within-cluster dispersion matrix</p></li>
<li><p>( k ) is the number of clusters</p></li>
<li><p>( n ) is the total number of data points</p></li>
</ul>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">pandas</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pd</span>

<span class="c1"># Datos originales</span>
<span class="n">data</span> <span class="o">=</span> <span class="p">[</span>
    <span class="p">[</span><span class="s2">&quot;Silhouette Score&quot;</span><span class="p">,</span> <span class="mf">0.195177</span><span class="p">,</span> <span class="s2">&quot;leiden&quot;</span><span class="p">,</span> <span class="mf">0.4</span><span class="p">],</span>
    <span class="p">[</span><span class="s2">&quot;Calinski-Harabasz Index&quot;</span><span class="p">,</span> <span class="mf">510.820769</span><span class="p">,</span> <span class="s2">&quot;leiden&quot;</span><span class="p">,</span> <span class="mf">0.4</span><span class="p">],</span>
    <span class="p">[</span><span class="s2">&quot;Silhouette Score&quot;</span><span class="p">,</span> <span class="mf">0.171419</span><span class="p">,</span> <span class="s2">&quot;leiden&quot;</span><span class="p">,</span> <span class="mf">0.6</span><span class="p">],</span>
    <span class="p">[</span><span class="s2">&quot;Calinski-Harabasz Index&quot;</span><span class="p">,</span> <span class="mf">443.458888</span><span class="p">,</span> <span class="s2">&quot;leiden&quot;</span><span class="p">,</span> <span class="mf">0.6</span><span class="p">],</span>
    <span class="p">[</span><span class="s2">&quot;Silhouette Score&quot;</span><span class="p">,</span> <span class="mf">0.076785</span><span class="p">,</span> <span class="s2">&quot;leiden&quot;</span><span class="p">,</span> <span class="mf">0.8</span><span class="p">],</span>
    <span class="p">[</span><span class="s2">&quot;Calinski-Harabasz Index&quot;</span><span class="p">,</span> <span class="mf">229.003893</span><span class="p">,</span> <span class="s2">&quot;leiden&quot;</span><span class="p">,</span> <span class="mf">0.8</span><span class="p">],</span>
    <span class="p">[</span><span class="s2">&quot;Silhouette Score&quot;</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.0</span><span class="p">,</span> <span class="s2">&quot;louvain&quot;</span><span class="p">,</span> <span class="mf">0.4</span><span class="p">],</span>
    <span class="p">[</span><span class="s2">&quot;Calinski-Harabasz Index&quot;</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.0</span><span class="p">,</span> <span class="s2">&quot;louvain&quot;</span><span class="p">,</span> <span class="mf">0.4</span><span class="p">],</span>
    <span class="p">[</span><span class="s2">&quot;Silhouette Score&quot;</span><span class="p">,</span> <span class="mf">0.106973</span><span class="p">,</span> <span class="s2">&quot;louvain&quot;</span><span class="p">,</span> <span class="mf">0.6</span><span class="p">],</span>
    <span class="p">[</span><span class="s2">&quot;Calinski-Harabasz Index&quot;</span><span class="p">,</span> <span class="mf">206.088366</span><span class="p">,</span> <span class="s2">&quot;louvain&quot;</span><span class="p">,</span> <span class="mf">0.6</span><span class="p">],</span>
    <span class="p">[</span><span class="s2">&quot;Silhouette Score&quot;</span><span class="p">,</span> <span class="mf">0.061618</span><span class="p">,</span> <span class="s2">&quot;louvain&quot;</span><span class="p">,</span> <span class="mf">0.8</span><span class="p">],</span>
    <span class="p">[</span><span class="s2">&quot;Calinski-Harabasz Index&quot;</span><span class="p">,</span> <span class="mf">230.627533</span><span class="p">,</span> <span class="s2">&quot;louvain&quot;</span><span class="p">,</span> <span class="mf">0.8</span><span class="p">],</span>
    <span class="p">[</span><span class="s2">&quot;MSE&quot;</span><span class="p">,</span> <span class="mf">0.794525</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">],</span>
    <span class="p">[</span><span class="s2">&quot;Pearson Correlation&quot;</span><span class="p">,</span> <span class="mf">0.000289</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">],</span>
    <span class="p">[</span><span class="s2">&quot;Latent Space Normality (p-value)&quot;</span><span class="p">,</span> <span class="mf">0.425853</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">]</span>
<span class="p">]</span>

<span class="c1"># Crear DataFrame</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;Metric&quot;</span><span class="p">,</span> <span class="s2">&quot;VAE&quot;</span><span class="p">,</span> <span class="s2">&quot;Method&quot;</span><span class="p">,</span> <span class="s2">&quot;Resolution&quot;</span><span class="p">])</span>

<span class="c1"># Reordenar columnas para que &#39;VAE&#39; esté al final</span>
<span class="n">column_order</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;Metric&quot;</span><span class="p">,</span> <span class="s2">&quot;Method&quot;</span><span class="p">,</span> <span class="s2">&quot;Resolution&quot;</span><span class="p">,</span> <span class="s2">&quot;VAE&quot;</span><span class="p">]</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">column_order</span><span class="p">]</span>

<span class="c1"># Mostrar la tabla final</span>
<span class="c1"># print(df)</span>
</pre></div>
</div>
</div>
</div>
<p>The clustering quality was assessed using the Silhouette Score and the Calinski-Harabasz (CH) Index for both Leiden and Louvain algorithms at different resolutions (0.4, 0.6, and 0.8). The best performance was achieved by Leiden at resolution 0.4, with a Silhouette Score of 0.195 and a CH index of 510.82, indicating well-separated and compact clusters. As the resolution increased to 0.6 and 0.8, both metrics declined (Silhouette Scores of 0.171 and 0.077, CH values of 443.46 and 229.00), suggesting over-clustering and reduced definition. Louvain performed significantly worse, particularly at resolution 0.4, where it failed to produce valid clusters (Silhouette and CH both at -1.0). At resolutions 0.6 and 0.8, Louvain showed slight improvement, with Silhouette Scores of 0.107 and 0.062, and CH values of 206.09 and 230.63, still underperforming compared to Leiden. Additionally, other metrics for the VAE model were included: a Mean Squared Error (MSE) of 0.7945, a near-zero Pearson correlation of 0.0003, and a latent space normality p-value of 0.426, indicating that the latent space does not deviate significantly from a normal distribution.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">metrics_df</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Metric</th>
      <th>Method</th>
      <th>Resolution</th>
      <th>VAE</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Silhouette Score</td>
      <td>leiden</td>
      <td>0.4</td>
      <td>0.195177</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Calinski-Harabasz Index</td>
      <td>leiden</td>
      <td>0.4</td>
      <td>510.820769</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Silhouette Score</td>
      <td>leiden</td>
      <td>0.6</td>
      <td>0.171419</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Calinski-Harabasz Index</td>
      <td>leiden</td>
      <td>0.6</td>
      <td>443.458888</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Silhouette Score</td>
      <td>leiden</td>
      <td>0.8</td>
      <td>0.076785</td>
    </tr>
    <tr>
      <th>5</th>
      <td>Calinski-Harabasz Index</td>
      <td>leiden</td>
      <td>0.8</td>
      <td>229.003893</td>
    </tr>
    <tr>
      <th>6</th>
      <td>Silhouette Score</td>
      <td>louvain</td>
      <td>0.4</td>
      <td>-1.000000</td>
    </tr>
    <tr>
      <th>7</th>
      <td>Calinski-Harabasz Index</td>
      <td>louvain</td>
      <td>0.4</td>
      <td>-1.000000</td>
    </tr>
    <tr>
      <th>8</th>
      <td>Silhouette Score</td>
      <td>louvain</td>
      <td>0.6</td>
      <td>0.106973</td>
    </tr>
    <tr>
      <th>9</th>
      <td>Calinski-Harabasz Index</td>
      <td>louvain</td>
      <td>0.6</td>
      <td>206.088366</td>
    </tr>
    <tr>
      <th>10</th>
      <td>Silhouette Score</td>
      <td>louvain</td>
      <td>0.8</td>
      <td>0.061618</td>
    </tr>
    <tr>
      <th>11</th>
      <td>Calinski-Harabasz Index</td>
      <td>louvain</td>
      <td>0.8</td>
      <td>230.627533</td>
    </tr>
    <tr>
      <th>12</th>
      <td>MSE</td>
      <td>None</td>
      <td>NaN</td>
      <td>0.794525</td>
    </tr>
    <tr>
      <th>13</th>
      <td>Pearson Correlation</td>
      <td>None</td>
      <td>NaN</td>
      <td>0.000289</td>
    </tr>
    <tr>
      <th>14</th>
      <td>Latent Space Normality (p-value)</td>
      <td>None</td>
      <td>NaN</td>
      <td>0.425853</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
</section>
<section id="differential-expression-for-vae">
<h3>Differential Expression for VAE<a class="headerlink" href="#differential-expression-for-vae" title="Link to this heading">#</a></h3>
<div class="admonition-boundaries-of-the-differential-expression-volcano-plot admonition">
<p class="admonition-title">Boundaries of the differential expression volcano plot</p>
<ul class="simple">
<li><p>The green vertical lines represent log fold change thresholds (typically at +1 and -1).</p></li>
<li><p>The blue horizontal line represents the p-value threshold (typically at p = 0.05, shown as -log10(0.05) on the y-axis).</p></li>
</ul>
<ol class="arabic simple">
<li><p>If a point (gene) is outside these lines, it means:</p></li>
</ol>
<ul class="simple">
<li><p>To the right of the green line (&gt; +1 logFC): The gene is strongly upregulated in the cluster compared to the others.</p></li>
<li><p>To the left of the green line (&lt; -1 logFC): The gene is strongly downregulated in the cluster compared to the others.</p></li>
</ul>
<ol class="arabic simple" start="2">
<li><p>Above the blue line: The gene is statistically significant, because its p-value is less than 0.05.</p></li>
</ol>
<p>So if a gene is:
Beyond the green lines and above the blue line, it’s considered both:</p>
<ul class="simple">
<li><p>Statistically significant</p></li>
<li><p>Biologically meaningful (large expression change)</p></li>
<li><p>These genes (points) are often colored red in the plot because they are the most relevant for biological interpretation.</p></li>
</ul>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">adata_filtered</span><span class="o">.</span><span class="n">obs</span><span class="o">.</span><span class="n">columns</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Index([&#39;disease_state&#39;, &#39;plate_id&#39;, &#39;tissue&#39;, &#39;patient_id&#39;, &#39;cell_type&#39;,
       &#39;neoplastic_state&#39;, &#39;diagnosis&#39;, &#39;n_genes_by_counts&#39;,
       &#39;log1p_n_genes_by_counts&#39;, &#39;total_counts&#39;, &#39;log1p_total_counts&#39;,
       &#39;pct_counts_in_top_50_genes&#39;, &#39;pct_counts_in_top_100_genes&#39;,
       &#39;pct_counts_in_top_200_genes&#39;, &#39;mito_UMI_counts&#39;, &#39;pct_mito&#39;,
       &#39;doublet_score&#39;, &#39;predicted_doublet&#39;],
      dtype=&#39;object&#39;)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">vae_model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
<span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
    <span class="n">x_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">adata_filtered</span><span class="o">.</span><span class="n">X</span><span class="o">.</span><span class="n">A</span> <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">adata_filtered</span><span class="o">.</span><span class="n">X</span><span class="p">,</span> <span class="s2">&quot;A&quot;</span><span class="p">)</span> <span class="k">else</span> <span class="n">adata_filtered</span><span class="o">.</span><span class="n">X</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
    <span class="n">mu</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">vae_model</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">x_tensor</span><span class="p">)</span>
    <span class="n">latent</span> <span class="o">=</span> <span class="n">mu</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Lattent embeddings for VAE</span>
<span class="n">adata_filtered</span><span class="o">.</span><span class="n">obsm</span><span class="p">[</span><span class="s2">&quot;X_latent&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">latent</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">adata_filtered</span><span class="o">.</span><span class="n">obsm</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>KeysView(AxisArrays with keys: X_pca, X_umap, X_harmony, X_latent)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">sc</span><span class="o">.</span><span class="n">pp</span><span class="o">.</span><span class="n">neighbors</span><span class="p">(</span><span class="n">adata_filtered</span><span class="p">,</span> <span class="n">use_rep</span><span class="o">=</span><span class="s2">&quot;X_latent&quot;</span><span class="p">,</span> <span class="n">n_neighbors</span><span class="o">=</span><span class="mi">15</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">sc</span><span class="o">.</span><span class="n">tl</span><span class="o">.</span><span class="n">leiden</span><span class="p">(</span><span class="n">adata_filtered</span><span class="p">,</span> <span class="n">resolution</span><span class="o">=</span><span class="mf">0.6</span><span class="p">,</span> <span class="n">key_added</span><span class="o">=</span><span class="s2">&quot;leiden_0.6&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">sc</span><span class="o">.</span><span class="n">tl</span><span class="o">.</span><span class="n">rank_genes_groups</span><span class="p">(</span>
    <span class="n">adata_filtered</span><span class="p">,</span>
    <span class="n">groupby</span><span class="o">=</span><span class="s2">&quot;leiden_0.6&quot;</span><span class="p">,</span>
    <span class="n">method</span><span class="o">=</span><span class="s2">&quot;wilcoxon&quot;</span><span class="p">,</span>
    <span class="n">use_raw</span><span class="o">=</span><span class="kc">False</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="pst-scrollable-table-container"><table class="table">
<thead>
<tr class="row-odd"><th class="head"><p>Cluster</p></th>
<th class="head"><p>Top Marker Genes</p></th>
<th class="head"><p>Probable Cell Type</p></th>
<th class="head"><p>Description</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>0</p></td>
<td><p>ZNF225, RERG, TGFBR3, WNT7B, PLA1A</p></td>
<td><p>Tumor cells / possibly epithelial-like</p></td>
<td><p>Genes related to growth signaling and differentiation. May correspond to tumor or modified progenitor cells.</p></td>
</tr>
<tr class="row-odd"><td><p>1</p></td>
<td><p>RNF227, RASGEF1B, CLEC2B, HLA-DRB5, CD74</p></td>
<td><p>Antigen-presenting cells (APCs)</p></td>
<td><p>High expression of HLA and CD74 genes indicates antigen-presenting cells such as dendritic cells or activated microglia.</p></td>
</tr>
<tr class="row-even"><td><p>2</p></td>
<td><p>RBX1, PCDHGA6, FCRLA, MS4A1, CD79B</p></td>
<td><p>B cells</p></td>
<td><p>Typical genes of B-cell receptors and immune signaling pathways.</p></td>
</tr>
<tr class="row-odd"><td><p>3</p></td>
<td><p>RMP, IGFBP2, CRABP1, HSPB1, TUBB2A</p></td>
<td><p>Tumor cells / glioma-like</p></td>
<td><p>IGFBP2 and other proliferation-related genes suggest a tumor cell identity.</p></td>
</tr>
<tr class="row-even"><td><p>4</p></td>
<td><p>TANC6, C2, SCIN, MOB1B, BCL2A1P4</p></td>
<td><p>Stromal / mesenchymal-like cells</p></td>
<td><p>Genes related to cytoskeleton, cell signaling, and survival; possibly stromal or mesenchymal cells in the tumor microenvironment.</p></td>
</tr>
<tr class="row-odd"><td><p>5</p></td>
<td><p>CCL13, DPH3, PDE3B, CCL2, TNF</p></td>
<td><p>Pro-inflammatory macrophages / Monocytes</p></td>
<td><p>High expression of chemokines and TNF suggests pro-inflammatory macrophages or infiltrating monocytes.</p></td>
</tr>
</tbody>
</table>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Map each differential Gene</span>
<span class="n">adata_filtered</span><span class="o">.</span><span class="n">var</span><span class="p">[</span><span class="s1">&#39;gene_symbols&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">adata_filtered</span><span class="o">.</span><span class="n">var</span><span class="p">[</span><span class="s1">&#39;Mapped_Gene&#39;</span><span class="p">]</span>
<span class="n">sc</span><span class="o">.</span><span class="n">pl</span><span class="o">.</span><span class="n">rank_genes_groups</span><span class="p">(</span><span class="n">adata_filtered</span><span class="p">,</span> <span class="n">n_genes</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">sharey</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">gene_symbols</span><span class="o">=</span><span class="s1">&#39;gene_symbols&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/644688c15ef5b52e742fcc0c205952a01cc44324dd62f6b46b3b0446a7059b65.png" src="_images/644688c15ef5b52e742fcc0c205952a01cc44324dd62f6b46b3b0446a7059b65.png" />
</div>
</div>
<section id="volcano-plot-for-differential-expression">
<h4>Volcano PLot for Differential Expression<a class="headerlink" href="#volcano-plot-for-differential-expression" title="Link to this heading">#</a></h4>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">groups</span> <span class="o">=</span> <span class="n">adata_filtered</span><span class="o">.</span><span class="n">uns</span><span class="p">[</span><span class="s1">&#39;rank_genes_groups&#39;</span><span class="p">][</span><span class="s1">&#39;names&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">dtype</span><span class="o">.</span><span class="n">names</span> <span class="c1">#Name of each cluster</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="n">axs</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">14</span><span class="p">,</span> <span class="mi">18</span><span class="p">))</span>
<span class="n">axs</span> <span class="o">=</span> <span class="n">axs</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>

<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">group</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">groups</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">i</span> <span class="o">&gt;=</span> <span class="nb">len</span><span class="p">(</span><span class="n">axs</span><span class="p">):</span> <span class="c1">#depends on the number of the cluster</span>
        <span class="k">break</span>

    <span class="n">names</span> <span class="o">=</span> <span class="n">adata_filtered</span><span class="o">.</span><span class="n">uns</span><span class="p">[</span><span class="s1">&#39;rank_genes_groups&#39;</span><span class="p">][</span><span class="s1">&#39;names&#39;</span><span class="p">][</span><span class="n">group</span><span class="p">]</span>
    <span class="n">logfc</span> <span class="o">=</span> <span class="n">adata_filtered</span><span class="o">.</span><span class="n">uns</span><span class="p">[</span><span class="s1">&#39;rank_genes_groups&#39;</span><span class="p">][</span><span class="s1">&#39;logfoldchanges&#39;</span><span class="p">][</span><span class="n">group</span><span class="p">]</span>
    <span class="n">pvals</span> <span class="o">=</span> <span class="n">adata_filtered</span><span class="o">.</span><span class="n">uns</span><span class="p">[</span><span class="s1">&#39;rank_genes_groups&#39;</span><span class="p">][</span><span class="s1">&#39;pvals&#39;</span><span class="p">][</span><span class="n">group</span><span class="p">]</span>

    <span class="c1"># Data for the volcano plot</span>
    <span class="n">volcano_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span>
        <span class="s1">&#39;gene&#39;</span><span class="p">:</span> <span class="n">names</span><span class="p">,</span>
        <span class="s1">&#39;logFC&#39;</span><span class="p">:</span> <span class="n">logfc</span><span class="p">,</span>
        <span class="s1">&#39;pval&#39;</span><span class="p">:</span> <span class="n">pvals</span>
    <span class="p">})</span>

    <span class="c1"># -log10(p-value)</span>
    <span class="n">volcano_df</span><span class="p">[</span><span class="s1">&#39;neg_log10_pval&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">log10</span><span class="p">(</span><span class="n">volcano_df</span><span class="p">[</span><span class="s1">&#39;pval&#39;</span><span class="p">])</span>

    <span class="c1"># Significative genes</span>
    <span class="n">volcano_df</span><span class="p">[</span><span class="s1">&#39;significant&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">volcano_df</span><span class="p">[</span><span class="s1">&#39;pval&#39;</span><span class="p">]</span> <span class="o">&lt;</span> <span class="mf">0.05</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="nb">abs</span><span class="p">(</span><span class="n">volcano_df</span><span class="p">[</span><span class="s1">&#39;logFC&#39;</span><span class="p">])</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">)</span>

    <span class="n">ax</span> <span class="o">=</span> <span class="n">axs</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">volcano_df</span><span class="p">[</span><span class="s1">&#39;logFC&#39;</span><span class="p">],</span> <span class="n">volcano_df</span><span class="p">[</span><span class="s1">&#39;neg_log10_pval&#39;</span><span class="p">],</span>
               <span class="n">c</span><span class="o">=</span><span class="n">volcano_df</span><span class="p">[</span><span class="s1">&#39;significant&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">({</span><span class="kc">True</span><span class="p">:</span> <span class="s1">&#39;red&#39;</span><span class="p">,</span> <span class="kc">False</span><span class="p">:</span> <span class="s1">&#39;gray&#39;</span><span class="p">}),</span>
               <span class="n">alpha</span><span class="o">=</span><span class="mf">0.7</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Volcano Plot: Cluster </span><span class="si">{</span><span class="n">group</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;Log Fold Change&#39;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;-log10(p-value)&#39;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">axhline</span><span class="p">(</span><span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">log10</span><span class="p">(</span><span class="mf">0.05</span><span class="p">),</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;blue&#39;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">axvline</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;green&#39;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">axvline</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;green&#39;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>

<span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">axs</span><span class="p">)):</span>
    <span class="n">fig</span><span class="o">.</span><span class="n">delaxes</span><span class="p">(</span><span class="n">axs</span><span class="p">[</span><span class="n">j</span><span class="p">])</span>

<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/15d6a3718e0b3dc66084df136c2d46641612a345cc757ab8a74791988c52ce0e.png" src="_images/15d6a3718e0b3dc66084df136c2d46641612a345cc757ab8a74791988c52ce0e.png" />
</div>
</div>
<p>Based on the volcano plots for Clusters 0 through 5, we can conclude that most genes in each cluster exhibit low statistical significance and minimal differential expression, as the majority of points are concentrated around the center (log fold change ≈ 0) and lie below the blue horizontal p-value threshold line. This suggests that for most clusters, the genes do not show strong up- or down-regulation, nor do they achieve statistical significance (p &gt; 0.05). Notably, only a few genes in each plot fall beyond the green vertical boundaries (logFC &gt; 1 or &lt; -1), and even fewer surpass the horizontal blue line, indicating that very few genes meet both criteria for being statistically significant and biologically meaningful. These few genes—if any—are the ones that stand out as potential key markers or drivers for each cluster and would warrant further biological interpretation and validation. Overall, the sparse presence of such genes suggests subtle transcriptional differences between clusters or a relatively homogeneous gene expression landscape.</p>
</section>
</section>
</section>
<section id="vae-attention">
<h2>VAE + Attention<a class="headerlink" href="#vae-attention" title="Link to this heading">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span><span class="w"> </span><span class="nc">Attention</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Attention</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">attention_layer</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">MultiheadAttention</span><span class="p">(</span><span class="n">embed_dim</span><span class="o">=</span><span class="n">hidden_dim</span><span class="p">,</span> <span class="n">num_heads</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">batch_first</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    
    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">attn_output</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">attention_layer</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">attn_output</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span><span class="w"> </span><span class="nc">VAEAttention</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_dim</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">,</span> <span class="n">latent_dim</span><span class="p">,</span> <span class="n">dropout_rate</span><span class="o">=</span><span class="mf">0.1</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">VAEAttention</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">hidden_dim</span> <span class="o">=</span> <span class="n">hidden_dim</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">latent_dim</span> <span class="o">=</span> <span class="n">latent_dim</span>
        
        <span class="bp">self</span><span class="o">.</span><span class="n">fc_enc1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">input_dim</span><span class="p">,</span> <span class="n">hidden_dim</span> <span class="o">*</span> <span class="mi">2</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc_enc2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_dim</span> <span class="o">*</span> <span class="mi">2</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc_mu</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_dim</span><span class="p">,</span> <span class="n">latent_dim</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc_var</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_dim</span><span class="p">,</span> <span class="n">latent_dim</span><span class="p">)</span>
        
        <span class="bp">self</span><span class="o">.</span><span class="n">attn</span> <span class="o">=</span> <span class="n">Attention</span><span class="p">(</span><span class="n">hidden_dim</span><span class="p">)</span>
        
        <span class="bp">self</span><span class="o">.</span><span class="n">fc_dec1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">latent_dim</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc_dec2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_dim</span><span class="p">,</span> <span class="n">hidden_dim</span> <span class="o">*</span> <span class="mi">2</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc_dec3</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_dim</span> <span class="o">*</span> <span class="mi">2</span><span class="p">,</span> <span class="n">input_dim</span><span class="p">)</span>
        
        <span class="bp">self</span><span class="o">.</span><span class="n">fc_p0</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">latent_dim</span><span class="p">,</span> <span class="n">input_dim</span><span class="p">)</span>
        
        <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">dropout_rate</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">encode</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">h</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">elu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">fc_enc1</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
        <span class="n">h</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">h</span><span class="p">)</span>
        <span class="n">h</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">elu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">fc_enc2</span><span class="p">(</span><span class="n">h</span><span class="p">))</span>
        <span class="n">h</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">h</span><span class="p">)</span>
        
        <span class="n">h</span> <span class="o">=</span> <span class="n">h</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">h</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">attn</span><span class="p">(</span><span class="n">h</span><span class="p">)</span>
        <span class="n">h</span> <span class="o">=</span> <span class="n">h</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
        
        <span class="n">mu</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc_mu</span><span class="p">(</span><span class="n">h</span><span class="p">)</span>
        <span class="n">log_var</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc_var</span><span class="p">(</span><span class="n">h</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">mu</span><span class="p">,</span> <span class="n">log_var</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">reparameterize</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">mu</span><span class="p">,</span> <span class="n">log_var</span><span class="p">):</span>
        <span class="n">std</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="mf">0.5</span> <span class="o">*</span> <span class="n">log_var</span><span class="p">)</span>
        <span class="n">eps</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn_like</span><span class="p">(</span><span class="n">std</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">mu</span> <span class="o">+</span> <span class="n">eps</span> <span class="o">*</span> <span class="n">std</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">decode</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">z</span><span class="p">):</span>
        <span class="n">h</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">elu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">fc_dec1</span><span class="p">(</span><span class="n">z</span><span class="p">))</span>
        <span class="n">h</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">h</span><span class="p">)</span>
        <span class="n">h</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">elu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">fc_dec2</span><span class="p">(</span><span class="n">h</span><span class="p">))</span>
        <span class="n">h</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">h</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc_dec3</span><span class="p">(</span><span class="n">h</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">mu</span><span class="p">,</span> <span class="n">log_var</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">z</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">reparameterize</span><span class="p">(</span><span class="n">mu</span><span class="p">,</span> <span class="n">log_var</span><span class="p">)</span>
        <span class="n">p0</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">fc_p0</span><span class="p">(</span><span class="n">mu</span><span class="p">))</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="n">z</span><span class="p">),</span> <span class="n">mu</span><span class="p">,</span> <span class="n">log_var</span><span class="p">,</span> <span class="n">p0</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#Loss functions </span>
<span class="k">def</span><span class="w"> </span><span class="nf">zinb_loss</span><span class="p">(</span><span class="n">recon_x</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">mu</span><span class="p">,</span> <span class="n">log_var</span><span class="p">,</span> <span class="n">p0</span><span class="p">,</span> <span class="n">beta</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">theta</span><span class="o">=</span><span class="mf">1.0</span><span class="p">):</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">x</span><span class="o">.</span><span class="n">is_sparse</span><span class="p">:</span>
            <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">to_dense</span><span class="p">()</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>

    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">recon_x</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">recon_x</span><span class="o">.</span><span class="n">is_sparse</span><span class="p">:</span>
            <span class="n">recon_x</span> <span class="o">=</span> <span class="n">recon_x</span><span class="o">.</span><span class="n">to_dense</span><span class="p">()</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">recon_x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">recon_x</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>

    <span class="n">theta_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">theta</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">x</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">x</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
    <span class="n">theta_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">clamp</span><span class="p">(</span><span class="n">theta_tensor</span><span class="p">,</span> <span class="nb">min</span><span class="o">=</span><span class="mf">1e-6</span><span class="p">,</span> <span class="nb">max</span><span class="o">=</span><span class="mf">1e3</span><span class="p">)</span>
    <span class="n">nb_loss</span> <span class="o">=</span> <span class="o">-</span><span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">lgamma</span><span class="p">(</span><span class="n">x</span> <span class="o">+</span> <span class="n">theta_tensor</span><span class="p">)</span> <span class="o">-</span> <span class="n">torch</span><span class="o">.</span><span class="n">lgamma</span><span class="p">(</span><span class="n">x</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">-</span> 
                         <span class="n">torch</span><span class="o">.</span><span class="n">lgamma</span><span class="p">(</span><span class="n">theta_tensor</span><span class="p">)</span> <span class="o">+</span> <span class="n">x</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">clamp</span><span class="p">(</span><span class="n">recon_x</span><span class="p">,</span> <span class="nb">min</span><span class="o">=</span><span class="mf">1e-8</span><span class="p">)</span> <span class="o">+</span> <span class="mf">1e-8</span><span class="p">)</span> <span class="o">+</span> 
                         <span class="n">theta_tensor</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">theta_tensor</span> <span class="o">/</span> <span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">clamp</span><span class="p">(</span><span class="n">recon_x</span><span class="p">,</span> <span class="nb">min</span><span class="o">=</span><span class="mf">1e-8</span><span class="p">)</span> <span class="o">+</span> <span class="mf">1e-8</span><span class="p">)))</span>

    <span class="n">p0</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">clamp</span><span class="p">(</span><span class="n">p0</span><span class="p">,</span> <span class="nb">min</span><span class="o">=</span><span class="mf">1e-5</span><span class="p">,</span> <span class="nb">max</span><span class="o">=</span><span class="mi">1</span><span class="o">-</span><span class="mf">1e-5</span><span class="p">)</span>
    <span class="n">bernoulli_loss</span> <span class="o">=</span> <span class="o">-</span><span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">x</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">p0</span> <span class="o">+</span> <span class="mf">1e-8</span><span class="p">)</span> <span class="o">+</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">x</span><span class="p">)</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">p0</span> <span class="o">+</span> <span class="mf">1e-8</span><span class="p">))</span>

    <span class="n">mu</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">clamp</span><span class="p">(</span><span class="n">mu</span><span class="p">,</span> <span class="nb">min</span><span class="o">=-</span><span class="mi">10</span><span class="p">,</span> <span class="nb">max</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
    <span class="n">log_var</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">clamp</span><span class="p">(</span><span class="n">log_var</span><span class="p">,</span> <span class="nb">min</span><span class="o">=-</span><span class="mi">10</span><span class="p">,</span> <span class="nb">max</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
    <span class="n">kl_loss</span> <span class="o">=</span> <span class="o">-</span><span class="mf">0.5</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">log_var</span> <span class="o">-</span> <span class="n">mu</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span> <span class="o">-</span> <span class="n">log_var</span><span class="o">.</span><span class="n">exp</span><span class="p">())</span>

    <span class="n">total_loss</span> <span class="o">=</span> <span class="n">nb_loss</span> <span class="o">+</span> <span class="n">bernoulli_loss</span> <span class="o">+</span> <span class="n">beta</span> <span class="o">*</span> <span class="n">kl_loss</span>
    <span class="k">return</span> <span class="n">total_loss</span><span class="p">,</span> <span class="n">nb_loss</span><span class="p">,</span> <span class="n">bernoulli_loss</span><span class="p">,</span> <span class="n">kl_loss</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#Function to train the model</span>
<span class="k">def</span><span class="w"> </span><span class="nf">train_model_vae_attention</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">num_epochs</span><span class="o">=</span><span class="mi">200</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
    <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
    <span class="n">losses</span><span class="p">,</span> <span class="n">nb_losses</span><span class="p">,</span> <span class="n">bernoulli_losses</span><span class="p">,</span> <span class="n">kl_losses</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[],</span> <span class="p">[],</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_epochs</span><span class="p">):</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
        <span class="n">recon_batch</span><span class="p">,</span> <span class="n">mu</span><span class="p">,</span> <span class="n">log_var</span><span class="p">,</span> <span class="n">p0</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
        <span class="n">loss</span><span class="p">,</span> <span class="n">nb_loss</span><span class="p">,</span> <span class="n">bernoulli_loss</span><span class="p">,</span> <span class="n">kl_loss</span> <span class="o">=</span> <span class="n">zinb_loss</span><span class="p">(</span><span class="n">recon_batch</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">mu</span><span class="p">,</span> <span class="n">log_var</span><span class="p">,</span> <span class="n">p0</span><span class="p">)</span>
        <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">clip_grad_norm_</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">max_norm</span><span class="o">=</span><span class="mf">1.0</span><span class="p">)</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

        <span class="n">losses</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>
        <span class="n">nb_losses</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nb_loss</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>
        <span class="n">bernoulli_losses</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">bernoulli_loss</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>
        <span class="n">kl_losses</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">kl_loss</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>

        <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Epoch [</span><span class="si">{</span><span class="n">epoch</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="n">num_epochs</span><span class="si">}</span><span class="s2">] - Loss: </span><span class="si">{</span><span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">, NB Loss: </span><span class="si">{</span><span class="n">nb_loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">, &quot;</span>
                  <span class="sa">f</span><span class="s2">&quot;Bernoulli Loss: </span><span class="si">{</span><span class="n">bernoulli_loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">, KL Loss: </span><span class="si">{</span><span class="n">kl_loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">losses</span><span class="p">,</span> <span class="n">nb_losses</span><span class="p">,</span> <span class="n">bernoulli_losses</span><span class="p">,</span> <span class="n">kl_losses</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Function to perform clustering and calculate metrics </span>
<span class="k">def</span><span class="w"> </span><span class="nf">clustering_and_metrics</span><span class="p">(</span><span class="n">X_data</span><span class="p">,</span> <span class="n">mu</span><span class="p">):</span>
    <span class="c1"># UMAP</span>
    <span class="n">adata_latent</span> <span class="o">=</span> <span class="n">sc</span><span class="o">.</span><span class="n">AnnData</span><span class="p">(</span><span class="n">X</span><span class="o">=</span><span class="n">mu</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>
    <span class="n">sc</span><span class="o">.</span><span class="n">pp</span><span class="o">.</span><span class="n">neighbors</span><span class="p">(</span><span class="n">adata_latent</span><span class="p">,</span> <span class="n">n_neighbors</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">use_rep</span><span class="o">=</span><span class="s1">&#39;X&#39;</span><span class="p">)</span>
    <span class="n">sc</span><span class="o">.</span><span class="n">tl</span><span class="o">.</span><span class="n">umap</span><span class="p">(</span><span class="n">adata_latent</span><span class="p">)</span>
    <span class="n">umap_coords</span> <span class="o">=</span> <span class="n">adata_latent</span><span class="o">.</span><span class="n">obsm</span><span class="p">[</span><span class="s1">&#39;X_umap&#39;</span><span class="p">]</span>

    <span class="n">resolutions</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.4</span><span class="p">,</span> <span class="mf">0.6</span><span class="p">,</span> <span class="mf">0.8</span><span class="p">]</span>
    <span class="n">methods</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;leiden&#39;</span><span class="p">,</span> <span class="s1">&#39;louvain&#39;</span><span class="p">]</span>
    <span class="n">clustering_results</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="n">fig</span><span class="p">,</span> <span class="n">axs</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">18</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>
    <span class="n">axs</span> <span class="o">=</span> <span class="n">axs</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>
    <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="k">for</span> <span class="n">method</span> <span class="ow">in</span> <span class="n">methods</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">res</span> <span class="ow">in</span> <span class="n">resolutions</span><span class="p">:</span>
            <span class="n">key</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">method</span><span class="si">}</span><span class="s2">_r&quot;</span>
            <span class="k">if</span> <span class="n">method</span> <span class="o">==</span> <span class="s1">&#39;leiden&#39;</span><span class="p">:</span>
                <span class="n">sc</span><span class="o">.</span><span class="n">tl</span><span class="o">.</span><span class="n">leiden</span><span class="p">(</span><span class="n">adata_latent</span><span class="p">,</span> <span class="n">resolution</span><span class="o">=</span><span class="n">res</span><span class="p">,</span> <span class="n">key_added</span><span class="o">=</span><span class="n">key</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">sc</span><span class="o">.</span><span class="n">tl</span><span class="o">.</span><span class="n">louvain</span><span class="p">(</span><span class="n">adata_latent</span><span class="p">,</span> <span class="n">resolution</span><span class="o">=</span><span class="n">res</span><span class="p">,</span> <span class="n">key_added</span><span class="o">=</span><span class="n">key</span><span class="p">)</span>

            <span class="n">labels</span> <span class="o">=</span> <span class="n">adata_latent</span><span class="o">.</span><span class="n">obs</span><span class="p">[</span><span class="n">key</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span><span class="o">.</span><span class="n">values</span>
            <span class="n">n_clusters</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">labels</span><span class="p">))</span>
            <span class="n">silh</span> <span class="o">=</span> <span class="n">silhouette_score</span><span class="p">(</span><span class="n">umap_coords</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span> <span class="k">if</span> <span class="n">n_clusters</span> <span class="o">&gt;</span> <span class="mi">1</span> <span class="k">else</span> <span class="o">-</span><span class="mi">1</span>
            <span class="n">ch</span> <span class="o">=</span> <span class="n">calinski_harabasz_score</span><span class="p">(</span><span class="n">umap_coords</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span> <span class="k">if</span> <span class="n">n_clusters</span> <span class="o">&gt;</span> <span class="mi">1</span> <span class="k">else</span> <span class="o">-</span><span class="mi">1</span>

            <span class="n">clustering_results</span><span class="o">.</span><span class="n">append</span><span class="p">({</span>
                <span class="s1">&#39;method&#39;</span><span class="p">:</span> <span class="n">method</span><span class="p">,</span>
                <span class="s1">&#39;resolution&#39;</span><span class="p">:</span> <span class="n">res</span><span class="p">,</span>
                <span class="s1">&#39;n_clusters&#39;</span><span class="p">:</span> <span class="n">n_clusters</span><span class="p">,</span>
                <span class="s1">&#39;silhouette&#39;</span><span class="p">:</span> <span class="n">silh</span><span class="p">,</span>
                <span class="s1">&#39;calinski_harabasz&#39;</span><span class="p">:</span> <span class="n">ch</span>
            <span class="p">})</span>

            <span class="n">axs</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">umap_coords</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">umap_coords</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="n">labels</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;tab20&#39;</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.7</span><span class="p">)</span>
            <span class="n">axs</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">method</span><span class="o">.</span><span class="n">title</span><span class="p">()</span><span class="si">}</span><span class="s2"> (res=</span><span class="si">{</span><span class="n">res</span><span class="si">}</span><span class="s2">)</span><span class="se">\n</span><span class="s2">Silh=</span><span class="si">{</span><span class="n">silh</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">  CH=</span><span class="si">{</span><span class="n">ch</span><span class="si">:</span><span class="s2">.1f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="n">axs</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">&quot;UMAP1&quot;</span><span class="p">)</span>
            <span class="n">axs</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">&quot;UMAP2&quot;</span><span class="p">)</span>
            <span class="n">i</span> <span class="o">+=</span> <span class="mi">1</span>

    <span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

    <span class="k">return</span> <span class="n">clustering_results</span>
</pre></div>
</div>
</div>
</div>
<section id="hyperparametrization-of-the-model-vae-attention">
<h3>Hyperparametrization of the model VAE + Attention<a class="headerlink" href="#hyperparametrization-of-the-model-vae-attention" title="Link to this heading">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">hyperparameter_tuning</span><span class="p">(</span><span class="n">X_data</span><span class="p">):</span>
    <span class="c1"># Hiyperparameters</span>
    <span class="n">param_grid</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s1">&#39;hidden_dim&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">64</span><span class="p">,</span> <span class="mi">128</span><span class="p">,</span> <span class="mi">256</span><span class="p">],</span>  
        <span class="s1">&#39;latent_dim&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">32</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="mi">128</span><span class="p">],</span>  
        <span class="s1">&#39;dropout_rate&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">],</span>  
        <span class="s1">&#39;learning_rate&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mf">1e-3</span><span class="p">,</span> <span class="mf">1e-4</span><span class="p">,</span> <span class="mf">1e-5</span><span class="p">]</span> 
    <span class="p">}</span>
    
    <span class="n">grid</span> <span class="o">=</span> <span class="n">ParameterGrid</span><span class="p">(</span><span class="n">param_grid</span><span class="p">)</span>
    
    <span class="n">best_metrics</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s1">&#39;best_loss&#39;</span><span class="p">:</span> <span class="nb">float</span><span class="p">(</span><span class="s1">&#39;inf&#39;</span><span class="p">),</span>
        <span class="s1">&#39;best_params&#39;</span><span class="p">:</span> <span class="kc">None</span><span class="p">,</span>
        <span class="s1">&#39;best_silhouette&#39;</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="s1">&#39;best_calinski&#39;</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="s1">&#39;best_pearson&#39;</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span>
    <span class="p">}</span>

    <span class="c1"># Searching for the best hyperparameters</span>
    <span class="k">for</span> <span class="n">params</span> <span class="ow">in</span> <span class="n">grid</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Training with params: </span><span class="si">{</span><span class="n">params</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        
        <span class="c1"># Model with hyperparameters</span>
        <span class="n">vae_model</span> <span class="o">=</span> <span class="n">VAEAttention</span><span class="p">(</span>
            <span class="n">input_dim</span><span class="o">=</span><span class="n">X_data</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span>
            <span class="n">hidden_dim</span><span class="o">=</span><span class="n">params</span><span class="p">[</span><span class="s1">&#39;hidden_dim&#39;</span><span class="p">],</span>
            <span class="n">latent_dim</span><span class="o">=</span><span class="n">params</span><span class="p">[</span><span class="s1">&#39;latent_dim&#39;</span><span class="p">],</span>
            <span class="n">dropout_rate</span><span class="o">=</span><span class="n">params</span><span class="p">[</span><span class="s1">&#39;dropout_rate&#39;</span><span class="p">]</span>
        <span class="p">)</span>
        <span class="n">optimizer</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">vae_model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">params</span><span class="p">[</span><span class="s1">&#39;learning_rate&#39;</span><span class="p">])</span>
        <span class="n">X_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">X_data</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
        <span class="n">num_epochs</span> <span class="o">=</span> <span class="mi">200</span>
        <span class="n">vae_losses</span><span class="p">,</span> <span class="n">vae_nb_losses</span><span class="p">,</span> <span class="n">vae_kl_losses</span> <span class="o">=</span> <span class="n">train_model_vae</span><span class="p">(</span><span class="n">vae_model</span><span class="p">,</span> <span class="n">X_tensor</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">num_epochs</span><span class="p">)</span>
        
        <span class="c1"># Latent representation</span>
        <span class="n">X_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">X_data</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span> 
        <span class="n">vae_embeddings_umap</span> <span class="o">=</span> <span class="n">vae_model</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">X_tensor</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
        
        <span class="c1"># Clustering con Louvain y Leiden</span>
        <span class="n">adata</span> <span class="o">=</span> <span class="n">sc</span><span class="o">.</span><span class="n">AnnData</span><span class="p">(</span><span class="n">vae_embeddings_umap</span><span class="p">)</span>
        <span class="n">sc</span><span class="o">.</span><span class="n">pp</span><span class="o">.</span><span class="n">neighbors</span><span class="p">(</span><span class="n">adata</span><span class="p">,</span> <span class="n">n_neighbors</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">use_rep</span><span class="o">=</span><span class="s1">&#39;X&#39;</span><span class="p">)</span>
        <span class="n">sc</span><span class="o">.</span><span class="n">tl</span><span class="o">.</span><span class="n">leiden</span><span class="p">(</span><span class="n">adata</span><span class="p">,</span> <span class="n">resolution</span><span class="o">=</span><span class="mf">0.6</span><span class="p">)</span>
        <span class="n">sc</span><span class="o">.</span><span class="n">tl</span><span class="o">.</span><span class="n">louvain</span><span class="p">(</span><span class="n">adata</span><span class="p">,</span> <span class="n">resolution</span><span class="o">=</span><span class="mf">0.6</span><span class="p">)</span>

        <span class="n">leiden_labels</span> <span class="o">=</span> <span class="n">adata</span><span class="o">.</span><span class="n">obs</span><span class="p">[</span><span class="s1">&#39;leiden&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span>
        <span class="n">louvain_labels</span> <span class="o">=</span> <span class="n">adata</span><span class="o">.</span><span class="n">obs</span><span class="p">[</span><span class="s1">&#39;louvain&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span>
        <span class="n">le</span> <span class="o">=</span> <span class="n">LabelEncoder</span><span class="p">()</span>
        <span class="n">leiden_labels</span> <span class="o">=</span> <span class="n">le</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">leiden_labels</span><span class="p">)</span>
        <span class="n">louvain_labels</span> <span class="o">=</span> <span class="n">le</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">louvain_labels</span><span class="p">)</span>
        
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">leiden_labels</span><span class="p">))</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">silhouette_leiden</span> <span class="o">=</span> <span class="n">silhouette_score</span><span class="p">(</span><span class="n">vae_embeddings_umap</span><span class="p">,</span> <span class="n">leiden_labels</span><span class="p">)</span>
            <span class="n">calinski_leiden</span> <span class="o">=</span> <span class="n">calinski_harabasz_score</span><span class="p">(</span><span class="n">vae_embeddings_umap</span><span class="p">,</span> <span class="n">leiden_labels</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">silhouette_leiden</span> <span class="o">=</span> <span class="kc">None</span>
            <span class="n">calinski_leiden</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">louvain_labels</span><span class="p">))</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">silhouette_louvain</span> <span class="o">=</span> <span class="n">silhouette_score</span><span class="p">(</span><span class="n">vae_embeddings_umap</span><span class="p">,</span> <span class="n">louvain_labels</span><span class="p">)</span>
            <span class="n">calinski_louvain</span> <span class="o">=</span> <span class="n">calinski_harabasz_score</span><span class="p">(</span><span class="n">vae_embeddings_umap</span><span class="p">,</span> <span class="n">louvain_labels</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">silhouette_louvain</span> <span class="o">=</span> <span class="kc">None</span>
            <span class="n">calinski_louvain</span> <span class="o">=</span> <span class="kc">None</span>
        
        <span class="c1"># Pearson Correlation</span>
        <span class="n">pearson_corr_leiden</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">corrcoef</span><span class="p">(</span><span class="n">vae_embeddings_umap</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">leiden_labels</span><span class="p">)[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
        <span class="n">pearson_corr_louvain</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">corrcoef</span><span class="p">(</span><span class="n">vae_embeddings_umap</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">louvain_labels</span><span class="p">)[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
        
        <span class="k">if</span> <span class="n">silhouette_leiden</span> <span class="o">&gt;</span> <span class="n">best_metrics</span><span class="p">[</span><span class="s1">&#39;best_silhouette&#39;</span><span class="p">]:</span>
            <span class="n">best_metrics</span><span class="p">[</span><span class="s1">&#39;best_silhouette&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">silhouette_leiden</span>
            <span class="n">best_metrics</span><span class="p">[</span><span class="s1">&#39;best_params&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">params</span>
        <span class="k">if</span> <span class="n">calinski_leiden</span> <span class="o">&gt;</span> <span class="n">best_metrics</span><span class="p">[</span><span class="s1">&#39;best_calinski&#39;</span><span class="p">]:</span>
            <span class="n">best_metrics</span><span class="p">[</span><span class="s1">&#39;best_calinski&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">calinski_leiden</span>
        <span class="k">if</span> <span class="n">pearson_corr_leiden</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">&gt;</span> <span class="n">best_metrics</span><span class="p">[</span><span class="s1">&#39;best_pearson&#39;</span><span class="p">]:</span>
            <span class="n">best_metrics</span><span class="p">[</span><span class="s1">&#39;best_pearson&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">pearson_corr_leiden</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    
    <span class="k">return</span> <span class="n">best_metrics</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X_data</span> <span class="o">=</span> <span class="n">adata_filtered</span><span class="o">.</span><span class="n">X</span>  
<span class="n">best_metrics</span> <span class="o">=</span> <span class="n">hyperparameter_tuning</span><span class="p">(</span><span class="n">X_data</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Best metrics: </span><span class="si">{</span><span class="n">best_metrics</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Best hyperparameters: {&#39;dropout_rate&#39;: 0.1, &#39;hidden_dim&#39;: 256, &#39;latent_dim&#39;: 64, &#39;learning_rate&#39;: 0.001}
</pre></div>
</div>
</div>
</div>
<p>Training the model with the best parameters</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">evaluate_model_attention_ordered</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">X_data</span><span class="p">):</span>
    <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
        <span class="n">recon</span><span class="p">,</span> <span class="n">mu</span><span class="p">,</span> <span class="n">log_var</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">X_data</span><span class="p">)</span>
    <span class="n">mu_np</span> <span class="o">=</span> <span class="n">mu</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
    <span class="n">X_np</span> <span class="o">=</span> <span class="n">X_data</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
    <span class="n">recon_np</span> <span class="o">=</span> <span class="n">recon</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>

    <span class="n">mse</span> <span class="o">=</span> <span class="n">mean_squared_error</span><span class="p">(</span><span class="n">X_np</span><span class="o">.</span><span class="n">flatten</span><span class="p">(),</span> <span class="n">recon_np</span><span class="o">.</span><span class="n">flatten</span><span class="p">())</span>
    <span class="n">pearson_corr</span> <span class="o">=</span> <span class="n">pearsonr</span><span class="p">(</span><span class="n">X_np</span><span class="o">.</span><span class="n">flatten</span><span class="p">(),</span> <span class="n">recon_np</span><span class="o">.</span><span class="n">flatten</span><span class="p">())[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">latent_normality_pval</span> <span class="o">=</span> <span class="n">normaltest</span><span class="p">(</span><span class="n">mu_np</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">pvalue</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>

    <span class="n">adata_latent</span> <span class="o">=</span> <span class="n">sc</span><span class="o">.</span><span class="n">AnnData</span><span class="p">(</span><span class="n">X</span><span class="o">=</span><span class="n">mu_np</span><span class="p">)</span>
    <span class="n">sc</span><span class="o">.</span><span class="n">pp</span><span class="o">.</span><span class="n">neighbors</span><span class="p">(</span><span class="n">adata_latent</span><span class="p">,</span> <span class="n">n_neighbors</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">use_rep</span><span class="o">=</span><span class="s2">&quot;X&quot;</span><span class="p">)</span>
    <span class="n">sc</span><span class="o">.</span><span class="n">tl</span><span class="o">.</span><span class="n">umap</span><span class="p">(</span><span class="n">adata_latent</span><span class="p">)</span>

    <span class="n">metrics</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">methods</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;leiden&#39;</span><span class="p">,</span> <span class="s1">&#39;louvain&#39;</span><span class="p">]</span>
    <span class="n">resolutions</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.4</span><span class="p">,</span> <span class="mf">0.6</span><span class="p">,</span> <span class="mf">0.8</span><span class="p">]</span>

    <span class="k">for</span> <span class="n">method</span> <span class="ow">in</span> <span class="n">methods</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">res</span> <span class="ow">in</span> <span class="n">resolutions</span><span class="p">:</span>
            <span class="n">key</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">method</span><span class="si">}</span><span class="s2">_r</span><span class="si">{</span><span class="n">res</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="k">if</span> <span class="n">method</span> <span class="o">==</span> <span class="s1">&#39;leiden&#39;</span><span class="p">:</span>
                <span class="n">sc</span><span class="o">.</span><span class="n">tl</span><span class="o">.</span><span class="n">leiden</span><span class="p">(</span><span class="n">adata_latent</span><span class="p">,</span> <span class="n">resolution</span><span class="o">=</span><span class="n">res</span><span class="p">,</span> <span class="n">key_added</span><span class="o">=</span><span class="n">key</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">sc</span><span class="o">.</span><span class="n">tl</span><span class="o">.</span><span class="n">louvain</span><span class="p">(</span><span class="n">adata_latent</span><span class="p">,</span> <span class="n">resolution</span><span class="o">=</span><span class="n">res</span><span class="p">,</span> <span class="n">key_added</span><span class="o">=</span><span class="n">key</span><span class="p">)</span>

            <span class="n">labels</span> <span class="o">=</span> <span class="n">adata_latent</span><span class="o">.</span><span class="n">obs</span><span class="p">[</span><span class="n">key</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span><span class="o">.</span><span class="n">values</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">labels</span><span class="p">))</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
                <span class="n">silh</span> <span class="o">=</span> <span class="n">silhouette_score</span><span class="p">(</span><span class="n">adata_latent</span><span class="o">.</span><span class="n">obsm</span><span class="p">[</span><span class="s1">&#39;X_umap&#39;</span><span class="p">],</span> <span class="n">labels</span><span class="p">)</span>
                <span class="n">ch</span> <span class="o">=</span> <span class="n">calinski_harabasz_score</span><span class="p">(</span><span class="n">adata_latent</span><span class="o">.</span><span class="n">obsm</span><span class="p">[</span><span class="s1">&#39;X_umap&#39;</span><span class="p">],</span> <span class="n">labels</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">silh</span><span class="p">,</span> <span class="n">ch</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span>

            <span class="n">metrics</span><span class="o">.</span><span class="n">append</span><span class="p">({</span><span class="s1">&#39;Metric&#39;</span><span class="p">:</span> <span class="s1">&#39;Silhouette Score&#39;</span><span class="p">,</span> <span class="s1">&#39;VAE+Attention&#39;</span><span class="p">:</span> <span class="n">silh</span><span class="p">,</span> <span class="s1">&#39;Method&#39;</span><span class="p">:</span> <span class="n">method</span><span class="p">,</span> <span class="s1">&#39;Resolution&#39;</span><span class="p">:</span> <span class="n">res</span><span class="p">})</span>
            <span class="n">metrics</span><span class="o">.</span><span class="n">append</span><span class="p">({</span><span class="s1">&#39;Metric&#39;</span><span class="p">:</span> <span class="s1">&#39;Calinski-Harabasz Index&#39;</span><span class="p">,</span> <span class="s1">&#39;VAE+Attention&#39;</span><span class="p">:</span> <span class="n">ch</span><span class="p">,</span> <span class="s1">&#39;Method&#39;</span><span class="p">:</span> <span class="n">method</span><span class="p">,</span> <span class="s1">&#39;Resolution&#39;</span><span class="p">:</span> <span class="n">res</span><span class="p">})</span>

    <span class="n">metrics</span><span class="o">.</span><span class="n">extend</span><span class="p">([</span>
        <span class="p">{</span><span class="s1">&#39;Metric&#39;</span><span class="p">:</span> <span class="s1">&#39;MSE&#39;</span><span class="p">,</span> <span class="s1">&#39;VAE+Attention&#39;</span><span class="p">:</span> <span class="n">mse</span><span class="p">,</span> <span class="s1">&#39;Method&#39;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">,</span> <span class="s1">&#39;Resolution&#39;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">},</span>
        <span class="p">{</span><span class="s1">&#39;Metric&#39;</span><span class="p">:</span> <span class="s1">&#39;Pearson Correlation&#39;</span><span class="p">,</span> <span class="s1">&#39;VAE+Attention&#39;</span><span class="p">:</span> <span class="n">pearson_corr</span><span class="p">,</span> <span class="s1">&#39;Method&#39;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">,</span> <span class="s1">&#39;Resolution&#39;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">},</span>
        <span class="p">{</span><span class="s1">&#39;Metric&#39;</span><span class="p">:</span> <span class="s1">&#39;Latent Space Normality (p-value)&#39;</span><span class="p">,</span> <span class="s1">&#39;VAE+Attention&#39;</span><span class="p">:</span> <span class="n">latent_normality_pval</span><span class="p">,</span> <span class="s1">&#39;Method&#39;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">,</span> <span class="s1">&#39;Resolution&#39;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">}</span>
    <span class="p">])</span>

    <span class="n">df_metrics</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">metrics</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">df_metrics</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">plot_losses</span><span class="p">(</span><span class="n">losses</span><span class="p">,</span> <span class="n">nb_losses</span><span class="p">,</span> <span class="n">bernoulli_losses</span><span class="p">,</span> <span class="n">kl_losses</span><span class="p">):</span>
    <span class="n">epochs</span> <span class="o">=</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">losses</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>

    <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">epochs</span><span class="p">,</span> <span class="n">losses</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Total Loss&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Epoch&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Loss&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Total Loss per Epoch&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

    <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">epochs</span><span class="p">,</span> <span class="n">nb_losses</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Negative Binomial Loss&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Epoch&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Loss&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Negative Binomial Loss per Epoch&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

    <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">epochs</span><span class="p">,</span> <span class="n">bernoulli_losses</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Bernoulli Loss&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Epoch&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Loss&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Bernoulli Loss per Epoch&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

    <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">epochs</span><span class="p">,</span> <span class="n">kl_losses</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;KL Divergence Loss&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Epoch&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Loss&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;KL Divergence Loss per Epoch&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">input_dim</span> <span class="o">=</span> <span class="n">X_data_tensor</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
<span class="n">best_params</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;dropout_rate&#39;</span><span class="p">:</span> <span class="mf">0.1</span><span class="p">,</span> <span class="s1">&#39;hidden_dim&#39;</span><span class="p">:</span> <span class="mi">256</span><span class="p">,</span> <span class="s1">&#39;latent_dim&#39;</span><span class="p">:</span> <span class="mi">32</span><span class="p">,</span> <span class="s1">&#39;learning_rate&#39;</span><span class="p">:</span> <span class="mf">0.001</span><span class="p">}</span>

<span class="n">model_attention</span> <span class="o">=</span> <span class="n">VAEAttention</span><span class="p">(</span>
    <span class="n">input_dim</span><span class="o">=</span><span class="n">input_dim</span><span class="p">,</span>
    <span class="n">hidden_dim</span><span class="o">=</span><span class="n">best_params</span><span class="p">[</span><span class="s1">&#39;hidden_dim&#39;</span><span class="p">],</span>
    <span class="n">latent_dim</span><span class="o">=</span><span class="n">best_params</span><span class="p">[</span><span class="s1">&#39;latent_dim&#39;</span><span class="p">],</span>
    <span class="n">dropout_rate</span><span class="o">=</span><span class="n">best_params</span><span class="p">[</span><span class="s1">&#39;dropout_rate&#39;</span><span class="p">]</span>
<span class="p">)</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">model_attention</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">best_params</span><span class="p">[</span><span class="s1">&#39;learning_rate&#39;</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Train</span>
<span class="n">num_epochs</span> <span class="o">=</span> <span class="mi">200</span>
<span class="n">losses</span><span class="p">,</span> <span class="n">nb_losses</span><span class="p">,</span> <span class="n">bernoulli_losses</span><span class="p">,</span> <span class="n">kl_losses</span> <span class="o">=</span> <span class="n">train_model_vae_attention</span><span class="p">(</span>
    <span class="n">model_attention</span><span class="p">,</span> <span class="n">X_data_tensor</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">num_epochs</span><span class="o">=</span><span class="n">num_epochs</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>C:\Users\henry\AppData\Local\Temp\ipykernel_31552\1573912572.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  x = torch.tensor(x, dtype=torch.float32)
C:\Users\henry\AppData\Local\Temp\ipykernel_31552\1573912572.py:13: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  recon_x = torch.tensor(recon_x, dtype=torch.float32)
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch [1/200] - Loss: -34626948.0000, NB Loss: -37153008.0000, Bernoulli Loss: 2525831.0000, KL Loss: 229.0655
Epoch [2/200] - Loss: -34635184.0000, NB Loss: -37148312.0000, Bernoulli Loss: 2512681.2500, KL Loss: 449.4211
Epoch [3/200] - Loss: -34545668.0000, NB Loss: -37044552.0000, Bernoulli Loss: 2497566.0000, KL Loss: 1316.4380
Epoch [4/200] - Loss: -34546528.0000, NB Loss: -37023540.0000, Bernoulli Loss: 2474118.5000, KL Loss: 2891.1189
Epoch [5/200] - Loss: -34457252.0000, NB Loss: -36899796.0000, Bernoulli Loss: 2435976.5000, KL Loss: 6566.5381
Epoch [6/200] - Loss: -34273352.0000, NB Loss: -36670332.0000, Bernoulli Loss: 2380245.2500, KL Loss: 16735.4004
Epoch [7/200] - Loss: -34060140.0000, NB Loss: -36416084.0000, Bernoulli Loss: 2320271.0000, KL Loss: 35671.7266
Epoch [8/200] - Loss: -33821952.0000, NB Loss: -36133544.0000, Bernoulli Loss: 2255565.5000, KL Loss: 56026.3047
Epoch [9/200] - Loss: -33917216.0000, NB Loss: -36164784.0000, Bernoulli Loss: 2190638.5000, KL Loss: 56928.1289
Epoch [10/200] - Loss: -33968752.0000, NB Loss: -36143296.0000, Bernoulli Loss: 2118434.7500, KL Loss: 56107.7031
Epoch [11/200] - Loss: -33978436.0000, NB Loss: -36091132.0000, Bernoulli Loss: 2055918.8750, KL Loss: 56775.2227
Epoch [12/200] - Loss: -34005172.0000, NB Loss: -36050048.0000, Bernoulli Loss: 1984012.0000, KL Loss: 60865.0469
Epoch [13/200] - Loss: -33912040.0000, NB Loss: -35876788.0000, Bernoulli Loss: 1883615.0000, KL Loss: 81131.7266
Epoch [14/200] - Loss: -33772428.0000, NB Loss: -35652368.0000, Bernoulli Loss: 1765113.7500, KL Loss: 114828.3906
Epoch [15/200] - Loss: -33724624.0000, NB Loss: -35520016.0000, Bernoulli Loss: 1653082.8750, KL Loss: 142307.2344
Epoch [16/200] - Loss: -33747396.0000, NB Loss: -35458712.0000, Bernoulli Loss: 1551147.8750, KL Loss: 160167.3750
Epoch [17/200] - Loss: -33821744.0000, NB Loss: -35442148.0000, Bernoulli Loss: 1446473.8750, KL Loss: 173933.5625
Epoch [18/200] - Loss: -33928068.0000, NB Loss: -35460016.0000, Bernoulli Loss: 1358473.8750, KL Loss: 173476.6875
Epoch [19/200] - Loss: -34046048.0000, NB Loss: -35494068.0000, Bernoulli Loss: 1272967.7500, KL Loss: 175053.7812
Epoch [20/200] - Loss: -34020788.0000, NB Loss: -35380380.0000, Bernoulli Loss: 1161081.7500, KL Loss: 198510.2188
Epoch [21/200] - Loss: -33968940.0000, NB Loss: -35239612.0000, Bernoulli Loss: 1037354.0625, KL Loss: 233315.7969
Epoch [22/200] - Loss: -33939028.0000, NB Loss: -35125300.0000, Bernoulli Loss: 927699.3750, KL Loss: 258570.4375
Epoch [23/200] - Loss: -33907240.0000, NB Loss: -35010224.0000, Bernoulli Loss: 814993.6250, KL Loss: 287990.9375
Epoch [24/200] - Loss: -33962792.0000, NB Loss: -34983988.0000, Bernoulli Loss: 715260.7500, KL Loss: 305936.7812
Epoch [25/200] - Loss: -34040480.0000, NB Loss: -34980680.0000, Bernoulli Loss: 640704.8750, KL Loss: 299495.5625
Epoch [26/200] - Loss: -34125836.0000, NB Loss: -34991220.0000, Bernoulli Loss: 555703.0625, KL Loss: 309678.2188
Epoch [27/200] - Loss: -34134744.0000, NB Loss: -34924828.0000, Bernoulli Loss: 453261.0625, KL Loss: 336825.8125
Epoch [28/200] - Loss: -34137644.0000, NB Loss: -34855680.0000, Bernoulli Loss: 351201.4375, KL Loss: 366837.2188
Epoch [29/200] - Loss: -34170216.0000, NB Loss: -34821712.0000, Bernoulli Loss: 257189.6562, KL Loss: 394309.3750
Epoch [30/200] - Loss: -34232928.0000, NB Loss: -34817112.0000, Bernoulli Loss: 179678.0938, KL Loss: 404505.8125
Epoch [31/200] - Loss: -34293760.0000, NB Loss: -34814984.0000, Bernoulli Loss: 119936.9922, KL Loss: 401287.8438
Epoch [32/200] - Loss: -34338968.0000, NB Loss: -34800816.0000, Bernoulli Loss: 53833.2109, KL Loss: 408014.1250
Epoch [33/200] - Loss: -34381908.0000, NB Loss: -34787472.0000, Bernoulli Loss: -40206.9375, KL Loss: 445773.1875
Epoch [34/200] - Loss: -34327472.0000, NB Loss: -34680348.0000, Bernoulli Loss: -100769.0469, KL Loss: 453642.0625
Epoch [35/200] - Loss: -34403052.0000, NB Loss: -34702260.0000, Bernoulli Loss: -179886.5625, KL Loss: 479094.5000
Epoch [36/200] - Loss: -34471848.0000, NB Loss: -34720316.0000, Bernoulli Loss: -213500.1719, KL Loss: 461966.6250
Epoch [37/200] - Loss: -34466460.0000, NB Loss: -34666364.0000, Bernoulli Loss: -270743.5625, KL Loss: 470648.6250
Epoch [38/200] - Loss: -34503920.0000, NB Loss: -34660316.0000, Bernoulli Loss: -356535.9688, KL Loss: 512932.7812
Epoch [39/200] - Loss: -34499596.0000, NB Loss: -34615328.0000, Bernoulli Loss: -379305.2812, KL Loss: 495037.8750
Epoch [40/200] - Loss: -34557768.0000, NB Loss: -34628660.0000, Bernoulli Loss: -443142.7812, KL Loss: 514035.5625
Epoch [41/200] - Loss: -34605592.0000, NB Loss: -34633576.0000, Bernoulli Loss: -483726.4375, KL Loss: 511710.1250
Epoch [42/200] - Loss: -34590616.0000, NB Loss: -34579920.0000, Bernoulli Loss: -552602.3750, KL Loss: 541907.4375
Epoch [43/200] - Loss: -34626784.0000, NB Loss: -34577448.0000, Bernoulli Loss: -599306.9375, KL Loss: 549970.3750
Epoch [44/200] - Loss: -34674448.0000, NB Loss: -34589652.0000, Bernoulli Loss: -603346.6875, KL Loss: 518552.1875
Epoch [45/200] - Loss: -34659152.0000, NB Loss: -34535924.0000, Bernoulli Loss: -705115.7500, KL Loss: 581888.2500
Epoch [46/200] - Loss: -34668040.0000, NB Loss: -34508392.0000, Bernoulli Loss: -734399.9375, KL Loss: 574751.1250
Epoch [47/200] - Loss: -34707716.0000, NB Loss: -34512136.0000, Bernoulli Loss: -772481.6250, KL Loss: 576898.3750
Epoch [48/200] - Loss: -34723704.0000, NB Loss: -34492680.0000, Bernoulli Loss: -820787.5000, KL Loss: 589762.5625
Epoch [49/200] - Loss: -34698064.0000, NB Loss: -34431640.0000, Bernoulli Loss: -907444.8750, KL Loss: 641020.7500
Epoch [50/200] - Loss: -34688736.0000, NB Loss: -34383360.0000, Bernoulli Loss: -907427.0000, KL Loss: 602051.2500
Epoch [51/200] - Loss: -34643640.0000, NB Loss: -34296064.0000, Bernoulli Loss: -991189.3125, KL Loss: 643611.7500
Epoch [52/200] - Loss: -34587268.0000, NB Loss: -34198824.0000, Bernoulli Loss: -1052602.0000, KL Loss: 664157.3750
Epoch [53/200] - Loss: -34591928.0000, NB Loss: -34169620.0000, Bernoulli Loss: -1043544.5000, KL Loss: 621237.6250
Epoch [54/200] - Loss: -34538392.0000, NB Loss: -34081692.0000, Bernoulli Loss: -1128262.8750, KL Loss: 671562.6875
Epoch [55/200] - Loss: -34495468.0000, NB Loss: -34003504.0000, Bernoulli Loss: -1159950.6250, KL Loss: 667987.5000
Epoch [56/200] - Loss: -34496964.0000, NB Loss: -33968400.0000, Bernoulli Loss: -1200349.2500, KL Loss: 671783.3750
Epoch [57/200] - Loss: -34556192.0000, NB Loss: -33987792.0000, Bernoulli Loss: -1234702.0000, KL Loss: 666305.3750
Epoch [58/200] - Loss: -34599116.0000, NB Loss: -33992248.0000, Bernoulli Loss: -1281647.1250, KL Loss: 674779.5000
Epoch [59/200] - Loss: -34576556.0000, NB Loss: -33933372.0000, Bernoulli Loss: -1331828.3750, KL Loss: 688643.1250
Epoch [60/200] - Loss: -34621608.0000, NB Loss: -33947520.0000, Bernoulli Loss: -1356958.5000, KL Loss: 682872.1875
Epoch [61/200] - Loss: -34607168.0000, NB Loss: -33898656.0000, Bernoulli Loss: -1386669.7500, KL Loss: 678156.4375
Epoch [62/200] - Loss: -34615392.0000, NB Loss: -33874768.0000, Bernoulli Loss: -1447725.8750, KL Loss: 707098.7500
Epoch [63/200] - Loss: -34710928.0000, NB Loss: -33934636.0000, Bernoulli Loss: -1435796.3750, KL Loss: 659502.3750
Epoch [64/200] - Loss: -34656072.0000, NB Loss: -33845408.0000, Bernoulli Loss: -1491631.1250, KL Loss: 680966.3750
Epoch [65/200] - Loss: -34667748.0000, NB Loss: -33823724.0000, Bernoulli Loss: -1544942.6250, KL Loss: 700921.1250
Epoch [66/200] - Loss: -34678432.0000, NB Loss: -33804924.0000, Bernoulli Loss: -1526377.0000, KL Loss: 652869.3750
Epoch [67/200] - Loss: -34690540.0000, NB Loss: -33782700.0000, Bernoulli Loss: -1583215.1250, KL Loss: 675377.1875
Epoch [68/200] - Loss: -34619344.0000, NB Loss: -33680876.0000, Bernoulli Loss: -1628133.2500, KL Loss: 689662.6250
Epoch [69/200] - Loss: -34645288.0000, NB Loss: -33681184.0000, Bernoulli Loss: -1607032.3750, KL Loss: 642928.1875
Epoch [70/200] - Loss: -34649432.0000, NB Loss: -33651720.0000, Bernoulli Loss: -1654278.5000, KL Loss: 656566.8750
Epoch [71/200] - Loss: -34631440.0000, NB Loss: -33609488.0000, Bernoulli Loss: -1712699.8750, KL Loss: 690746.1250
Epoch [72/200] - Loss: -34661760.0000, NB Loss: -33605392.0000, Bernoulli Loss: -1715614.2500, KL Loss: 659249.1250
Epoch [73/200] - Loss: -34703588.0000, NB Loss: -33624132.0000, Bernoulli Loss: -1712304.5000, KL Loss: 632847.2500
Epoch [74/200] - Loss: -34696908.0000, NB Loss: -33585188.0000, Bernoulli Loss: -1782570.5000, KL Loss: 670853.1250
Epoch [75/200] - Loss: -34701900.0000, NB Loss: -33562000.0000, Bernoulli Loss: -1800549.5000, KL Loss: 660648.8750
Epoch [76/200] - Loss: -34763896.0000, NB Loss: -33602224.0000, Bernoulli Loss: -1784487.8750, KL Loss: 622816.5000
Epoch [77/200] - Loss: -34732180.0000, NB Loss: -33539476.0000, Bernoulli Loss: -1835970.5000, KL Loss: 643266.6250
Epoch [78/200] - Loss: -34674540.0000, NB Loss: -33464612.0000, Bernoulli Loss: -1898791.3750, KL Loss: 688862.3125
Epoch [79/200] - Loss: -34698944.0000, NB Loss: -33462548.0000, Bernoulli Loss: -1901939.7500, KL Loss: 665543.1875
Epoch [80/200] - Loss: -34731100.0000, NB Loss: -33480738.0000, Bernoulli Loss: -1859329.3750, KL Loss: 608966.6250
Epoch [81/200] - Loss: -34738416.0000, NB Loss: -33460544.0000, Bernoulli Loss: -1881315.6250, KL Loss: 603443.7500
Epoch [82/200] - Loss: -34711508.0000, NB Loss: -33410912.0000, Bernoulli Loss: -1957085.8750, KL Loss: 656487.3750
Epoch [83/200] - Loss: -34714792.0000, NB Loss: -33393530.0000, Bernoulli Loss: -1982788.5000, KL Loss: 661527.8750
Epoch [84/200] - Loss: -34750008.0000, NB Loss: -33404974.0000, Bernoulli Loss: -1969005.5000, KL Loss: 623970.4375
Epoch [85/200] - Loss: -34769708.0000, NB Loss: -33402948.0000, Bernoulli Loss: -1995235.5000, KL Loss: 628474.5000
Epoch [86/200] - Loss: -34712784.0000, NB Loss: -33331922.0000, Bernoulli Loss: -2043538.0000, KL Loss: 662675.2500
Epoch [87/200] - Loss: -34736308.0000, NB Loss: -33334366.0000, Bernoulli Loss: -2056603.1250, KL Loss: 654659.2500
Epoch [88/200] - Loss: -34790456.0000, NB Loss: -33374380.0000, Bernoulli Loss: -2017148.0000, KL Loss: 601071.7500
Epoch [89/200] - Loss: -34786440.0000, NB Loss: -33352686.0000, Bernoulli Loss: -2034402.0000, KL Loss: 600647.7500
Epoch [90/200] - Loss: -34744000.0000, NB Loss: -33286834.0000, Bernoulli Loss: -2102069.5000, KL Loss: 644904.5000
Epoch [91/200] - Loss: -34747108.0000, NB Loss: -33272348.0000, Bernoulli Loss: -2117749.7500, KL Loss: 642988.6250
Epoch [92/200] - Loss: -34766604.0000, NB Loss: -33279176.0000, Bernoulli Loss: -2101008.2500, KL Loss: 613579.0000
Epoch [93/200] - Loss: -34773380.0000, NB Loss: -33263978.0000, Bernoulli Loss: -2121203.7500, KL Loss: 611799.5000
Epoch [94/200] - Loss: -34744388.0000, NB Loss: -33227774.0000, Bernoulli Loss: -2168256.5000, KL Loss: 651642.0625
Epoch [95/200] - Loss: -34743056.0000, NB Loss: -33208148.0000, Bernoulli Loss: -2181567.0000, KL Loss: 646661.5000
Epoch [96/200] - Loss: -34760880.0000, NB Loss: -33204268.0000, Bernoulli Loss: -2166216.2500, KL Loss: 609604.5000
Epoch [97/200] - Loss: -34782524.0000, NB Loss: -33211776.0000, Bernoulli Loss: -2174706.5000, KL Loss: 603959.1875
Epoch [98/200] - Loss: -34774352.0000, NB Loss: -33185976.0000, Bernoulli Loss: -2223890.0000, KL Loss: 635512.2500
Epoch [99/200] - Loss: -34755996.0000, NB Loss: -33150578.0000, Bernoulli Loss: -2232588.2500, KL Loss: 627170.9375
Epoch [100/200] - Loss: -34797216.0000, NB Loss: -33181356.0000, Bernoulli Loss: -2218640.7500, KL Loss: 602782.0000
Epoch [101/200] - Loss: -34813624.0000, NB Loss: -33180546.0000, Bernoulli Loss: -2231375.0000, KL Loss: 598294.6250
Epoch [102/200] - Loss: -34763016.0000, NB Loss: -33113732.0000, Bernoulli Loss: -2281335.0000, KL Loss: 632054.0000
Epoch [103/200] - Loss: -34766680.0000, NB Loss: -33102658.0000, Bernoulli Loss: -2294204.2500, KL Loss: 630182.7500
Epoch [104/200] - Loss: -34819196.0000, NB Loss: -33142900.0000, Bernoulli Loss: -2273223.7500, KL Loss: 596926.1250
Epoch [105/200] - Loss: -34773672.0000, NB Loss: -33081912.0000, Bernoulli Loss: -2291654.7500, KL Loss: 599898.0000
Epoch [106/200] - Loss: -34753824.0000, NB Loss: -33044082.0000, Bernoulli Loss: -2333194.0000, KL Loss: 623452.5000
Epoch [107/200] - Loss: -34739908.0000, NB Loss: -33017616.0000, Bernoulli Loss: -2338173.0000, KL Loss: 615878.3750
Epoch [108/200] - Loss: -34768504.0000, NB Loss: -33037402.0000, Bernoulli Loss: -2332898.7500, KL Loss: 601794.3750
Epoch [109/200] - Loss: -34775024.0000, NB Loss: -33027880.0000, Bernoulli Loss: -2338993.0000, KL Loss: 591846.6250
Epoch [110/200] - Loss: -34774692.0000, NB Loss: -33012004.0000, Bernoulli Loss: -2375477.0000, KL Loss: 612788.5000
Epoch [111/200] - Loss: -34715804.0000, NB Loss: -32946796.0000, Bernoulli Loss: -2398124.7500, KL Loss: 629115.6875
Epoch [112/200] - Loss: -34768420.0000, NB Loss: -32977270.0000, Bernoulli Loss: -2401585.5000, KL Loss: 610437.1875
Epoch [113/200] - Loss: -34745064.0000, NB Loss: -32976410.0000, Bernoulli Loss: -2349682.5000, KL Loss: 581029.7500
Epoch [114/200] - Loss: -34758536.0000, NB Loss: -32981672.0000, Bernoulli Loss: -2354869.7500, KL Loss: 578005.3750
Epoch [115/200] - Loss: -34782252.0000, NB Loss: -32960382.0000, Bernoulli Loss: -2414237.5000, KL Loss: 592367.5000
Epoch [116/200] - Loss: -34750992.0000, NB Loss: -32929598.0000, Bernoulli Loss: -2450657.2500, KL Loss: 629263.3750
Epoch [117/200] - Loss: -34719976.0000, NB Loss: -32887408.0000, Bernoulli Loss: -2464508.0000, KL Loss: 631939.7500
Epoch [118/200] - Loss: -34743268.0000, NB Loss: -32895146.0000, Bernoulli Loss: -2453584.5000, KL Loss: 605464.2500
Epoch [119/200] - Loss: -34793436.0000, NB Loss: -32926968.0000, Bernoulli Loss: -2453097.0000, KL Loss: 586628.6250
Epoch [120/200] - Loss: -34782200.0000, NB Loss: -32912908.0000, Bernoulli Loss: -2462561.5000, KL Loss: 593266.6250
Epoch [121/200] - Loss: -34755676.0000, NB Loss: -32868554.0000, Bernoulli Loss: -2489642.5000, KL Loss: 602521.8750
Epoch [122/200] - Loss: -34748084.0000, NB Loss: -32856246.0000, Bernoulli Loss: -2491499.0000, KL Loss: 599659.3750
Epoch [123/200] - Loss: -34736104.0000, NB Loss: -32829480.0000, Bernoulli Loss: -2504133.5000, KL Loss: 597509.1250
Epoch [124/200] - Loss: -34692728.0000, NB Loss: -32793976.0000, Bernoulli Loss: -2500870.0000, KL Loss: 602118.8750
Epoch [125/200] - Loss: -34726404.0000, NB Loss: -32818154.0000, Bernoulli Loss: -2508032.7500, KL Loss: 599785.5000
Epoch [126/200] - Loss: -34734824.0000, NB Loss: -32792468.0000, Bernoulli Loss: -2531510.5000, KL Loss: 589155.9375
Epoch [127/200] - Loss: -34731792.0000, NB Loss: -32788620.0000, Bernoulli Loss: -2546306.0000, KL Loss: 603135.3750
Epoch [128/200] - Loss: -34756020.0000, NB Loss: -32795658.0000, Bernoulli Loss: -2562490.2500, KL Loss: 602127.1250
Epoch [129/200] - Loss: -34718800.0000, NB Loss: -32753636.0000, Bernoulli Loss: -2547927.5000, KL Loss: 582763.0000
Epoch [130/200] - Loss: -34742172.0000, NB Loss: -32764556.0000, Bernoulli Loss: -2556969.2500, KL Loss: 579350.3750
Epoch [131/200] - Loss: -34747092.0000, NB Loss: -32758874.0000, Bernoulli Loss: -2586598.0000, KL Loss: 598381.1875
Epoch [132/200] - Loss: -34725168.0000, NB Loss: -32725618.0000, Bernoulli Loss: -2602932.5000, KL Loss: 603382.7500
Epoch [133/200] - Loss: -34753292.0000, NB Loss: -32739156.0000, Bernoulli Loss: -2596944.2500, KL Loss: 582806.2500
Epoch [134/200] - Loss: -34728456.0000, NB Loss: -32706464.0000, Bernoulli Loss: -2605731.5000, KL Loss: 583741.5000
Epoch [135/200] - Loss: -34748816.0000, NB Loss: -32717298.0000, Bernoulli Loss: -2633261.7500, KL Loss: 601743.1250
Epoch [136/200] - Loss: -34726936.0000, NB Loss: -32681596.0000, Bernoulli Loss: -2641242.2500, KL Loss: 595903.2500
Epoch [137/200] - Loss: -34711600.0000, NB Loss: -32668666.0000, Bernoulli Loss: -2619596.7500, KL Loss: 576665.8750
Epoch [138/200] - Loss: -34722796.0000, NB Loss: -32668998.0000, Bernoulli Loss: -2627883.7500, KL Loss: 574083.3750
Epoch [139/200] - Loss: -34718308.0000, NB Loss: -32646564.0000, Bernoulli Loss: -2665120.2500, KL Loss: 593375.4375
Epoch [140/200] - Loss: -34728000.0000, NB Loss: -32646610.0000, Bernoulli Loss: -2682532.2500, KL Loss: 601142.4375
Epoch [141/200] - Loss: -34710492.0000, NB Loss: -32621188.0000, Bernoulli Loss: -2676991.5000, KL Loss: 587687.8750
Epoch [142/200] - Loss: -34717564.0000, NB Loss: -32613560.0000, Bernoulli Loss: -2683346.7500, KL Loss: 579343.5000
Epoch [143/200] - Loss: -34742120.0000, NB Loss: -32628254.0000, Bernoulli Loss: -2704938.0000, KL Loss: 591070.2500
Epoch [144/200] - Loss: -34729540.0000, NB Loss: -32608718.0000, Bernoulli Loss: -2714764.7500, KL Loss: 593943.8750
Epoch [145/200] - Loss: -34717156.0000, NB Loss: -32580176.0000, Bernoulli Loss: -2719211.5000, KL Loss: 582230.6250
Epoch [146/200] - Loss: -34705252.0000, NB Loss: -32571844.0000, Bernoulli Loss: -2715475.7500, KL Loss: 582069.2500
Epoch [147/200] - Loss: -34698708.0000, NB Loss: -32553800.0000, Bernoulli Loss: -2729862.5000, KL Loss: 584956.1250
Epoch [148/200] - Loss: -34723980.0000, NB Loss: -32564766.0000, Bernoulli Loss: -2749360.0000, KL Loss: 590146.8750
Epoch [149/200] - Loss: -34712588.0000, NB Loss: -32541704.0000, Bernoulli Loss: -2759795.5000, KL Loss: 588910.2500
Epoch [150/200] - Loss: -34733028.0000, NB Loss: -32557464.0000, Bernoulli Loss: -2760265.7500, KL Loss: 584701.7500
Epoch [151/200] - Loss: -34723468.0000, NB Loss: -32534208.0000, Bernoulli Loss: -2769398.0000, KL Loss: 580141.5000
Epoch [152/200] - Loss: -34717980.0000, NB Loss: -32523388.0000, Bernoulli Loss: -2778444.5000, KL Loss: 583852.1250
Epoch [153/200] - Loss: -34700000.0000, NB Loss: -32497870.0000, Bernoulli Loss: -2791698.0000, KL Loss: 589566.6250
Epoch [154/200] - Loss: -34707292.0000, NB Loss: -32493374.0000, Bernoulli Loss: -2803556.7500, KL Loss: 589639.3125
Epoch [155/200] - Loss: -34727504.0000, NB Loss: -32503798.0000, Bernoulli Loss: -2804994.7500, KL Loss: 581289.8125
Epoch [156/200] - Loss: -34694232.0000, NB Loss: -32466866.0000, Bernoulli Loss: -2808064.2500, KL Loss: 580701.3125
Epoch [157/200] - Loss: -34741244.0000, NB Loss: -32500498.0000, Bernoulli Loss: -2827061.2500, KL Loss: 586314.5000
Epoch [158/200] - Loss: -34662092.0000, NB Loss: -32420458.0000, Bernoulli Loss: -2829048.7500, KL Loss: 587417.5625
Epoch [159/200] - Loss: -34711788.0000, NB Loss: -32459658.0000, Bernoulli Loss: -2833582.7500, KL Loss: 581451.3750
Epoch [160/200] - Loss: -34709984.0000, NB Loss: -32445790.0000, Bernoulli Loss: -2841864.0000, KL Loss: 577672.3125
Epoch [161/200] - Loss: -34693764.0000, NB Loss: -32423388.0000, Bernoulli Loss: -2854922.5000, KL Loss: 584549.3125
Epoch [162/200] - Loss: -34682976.0000, NB Loss: -32405302.0000, Bernoulli Loss: -2863955.0000, KL Loss: 586280.8750
Epoch [163/200] - Loss: -34692800.0000, NB Loss: -32404264.0000, Bernoulli Loss: -2870678.0000, KL Loss: 582142.8750
Epoch [164/200] - Loss: -34689588.0000, NB Loss: -32399894.0000, Bernoulli Loss: -2869575.2500, KL Loss: 579881.6250
Epoch [165/200] - Loss: -34660048.0000, NB Loss: -32361532.0000, Bernoulli Loss: -2882448.2500, KL Loss: 583930.1250
Epoch [166/200] - Loss: -34693944.0000, NB Loss: -32382972.0000, Bernoulli Loss: -2894261.5000, KL Loss: 583286.1875
Epoch [167/200] - Loss: -34683584.0000, NB Loss: -32367694.0000, Bernoulli Loss: -2895592.2500, KL Loss: 579704.2500
Epoch [168/200] - Loss: -34702804.0000, NB Loss: -32379548.0000, Bernoulli Loss: -2901369.7500, KL Loss: 578112.7500
Epoch [169/200] - Loss: -34672940.0000, NB Loss: -32339384.0000, Bernoulli Loss: -2914826.7500, KL Loss: 581270.5000
Epoch [170/200] - Loss: -34678624.0000, NB Loss: -32347268.0000, Bernoulli Loss: -2915022.2500, KL Loss: 583668.7500
Epoch [171/200] - Loss: -34650924.0000, NB Loss: -32310908.0000, Bernoulli Loss: -2922471.5000, KL Loss: 582457.8750
Epoch [172/200] - Loss: -34681320.0000, NB Loss: -32325232.0000, Bernoulli Loss: -2936652.2500, KL Loss: 580563.0000
Epoch [173/200] - Loss: -34679760.0000, NB Loss: -32314186.0000, Bernoulli Loss: -2945334.0000, KL Loss: 579760.8750
Epoch [174/200] - Loss: -34652164.0000, NB Loss: -32289408.0000, Bernoulli Loss: -2946841.2500, KL Loss: 584083.6250
Epoch [175/200] - Loss: -34667232.0000, NB Loss: -32297514.0000, Bernoulli Loss: -2956012.0000, KL Loss: 586296.8750
Epoch [176/200] - Loss: -34692220.0000, NB Loss: -32313006.0000, Bernoulli Loss: -2959619.0000, KL Loss: 580405.5000
Epoch [177/200] - Loss: -34671872.0000, NB Loss: -32284494.0000, Bernoulli Loss: -2967406.5000, KL Loss: 580029.0000
Epoch [178/200] - Loss: -34663972.0000, NB Loss: -32267418.0000, Bernoulli Loss: -2979900.5000, KL Loss: 583347.1250
Epoch [179/200] - Loss: -34677820.0000, NB Loss: -32272300.0000, Bernoulli Loss: -2989884.0000, KL Loss: 584365.5625
Epoch [180/200] - Loss: -34675500.0000, NB Loss: -32271450.0000, Bernoulli Loss: -2986737.0000, KL Loss: 582689.6875
Epoch [181/200] - Loss: -34672836.0000, NB Loss: -32261726.0000, Bernoulli Loss: -2992973.5000, KL Loss: 581864.0625
Epoch [182/200] - Loss: -34678828.0000, NB Loss: -32255176.0000, Bernoulli Loss: -3006436.2500, KL Loss: 582785.5000
Epoch [183/200] - Loss: -34680408.0000, NB Loss: -32249120.0000, Bernoulli Loss: -3015686.7500, KL Loss: 584399.2500
Epoch [184/200] - Loss: -34643604.0000, NB Loss: -32211258.0000, Bernoulli Loss: -3016945.0000, KL Loss: 584600.8750
Epoch [185/200] - Loss: -34669328.0000, NB Loss: -32227844.0000, Bernoulli Loss: -3022801.2500, KL Loss: 581317.8125
Epoch [186/200] - Loss: -34671868.0000, NB Loss: -32223724.0000, Bernoulli Loss: -3032513.5000, KL Loss: 584369.2500
Epoch [187/200] - Loss: -34646636.0000, NB Loss: -32191540.0000, Bernoulli Loss: -3040736.5000, KL Loss: 585640.5000
Epoch [188/200] - Loss: -34638580.0000, NB Loss: -32177542.0000, Bernoulli Loss: -3046874.5000, KL Loss: 585835.3125
Epoch [189/200] - Loss: -34647232.0000, NB Loss: -32179290.0000, Bernoulli Loss: -3047149.0000, KL Loss: 579209.1250
Epoch [190/200] - Loss: -34628832.0000, NB Loss: -32157428.0000, Bernoulli Loss: -3056199.2500, KL Loss: 584794.2500
Epoch [191/200] - Loss: -34632312.0000, NB Loss: -32150568.0000, Bernoulli Loss: -3066187.0000, KL Loss: 584443.8750
Epoch [192/200] - Loss: -34644204.0000, NB Loss: -32161276.0000, Bernoulli Loss: -3064136.7500, KL Loss: 581208.8750
Epoch [193/200] - Loss: -34664744.0000, NB Loss: -32175190.0000, Bernoulli Loss: -3070104.5000, KL Loss: 580552.1250
Epoch [194/200] - Loss: -34643408.0000, NB Loss: -32141378.0000, Bernoulli Loss: -3086700.5000, KL Loss: 584673.2500
Epoch [195/200] - Loss: -34617468.0000, NB Loss: -32112432.0000, Bernoulli Loss: -3093814.0000, KL Loss: 588779.0625
Epoch [196/200] - Loss: -34641000.0000, NB Loss: -32126812.0000, Bernoulli Loss: -3099746.2500, KL Loss: 585559.8750
Epoch [197/200] - Loss: -34649512.0000, NB Loss: -32130438.0000, Bernoulli Loss: -3099917.2500, KL Loss: 580844.5000
Epoch [198/200] - Loss: -34655780.0000, NB Loss: -32129498.0000, Bernoulli Loss: -3112106.7500, KL Loss: 585824.1250
Epoch [199/200] - Loss: -34640868.0000, NB Loss: -32108162.0000, Bernoulli Loss: -3117553.5000, KL Loss: 584847.9375
Epoch [200/200] - Loss: -34613364.0000, NB Loss: -32076000.0000, Bernoulli Loss: -3120197.0000, KL Loss: 582832.0000
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plot_losses</span><span class="p">(</span><span class="n">losses</span><span class="p">,</span> <span class="n">nb_losses</span><span class="p">,</span> <span class="n">bernoulli_losses</span><span class="p">,</span> <span class="n">kl_losses</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/053cbcccdd2b01681d31604d19c458bbd037cb40aab3f71192708dde27e2e4b5.png" src="_images/053cbcccdd2b01681d31604d19c458bbd037cb40aab3f71192708dde27e2e4b5.png" />
<img alt="_images/2aea2815e942e02b3d165605f2de2a91a8858bf7ba088ebc22e169961132ab4e.png" src="_images/2aea2815e942e02b3d165605f2de2a91a8858bf7ba088ebc22e169961132ab4e.png" />
<img alt="_images/8ca20be28ad62ebd63826b6e6392defdbc15e7e301f1d9fa9f8cb87c5f40e0bf.png" src="_images/8ca20be28ad62ebd63826b6e6392defdbc15e7e301f1d9fa9f8cb87c5f40e0bf.png" />
<img alt="_images/97953703a484b81aa2544aafa32d2a678f01625cf2ed411ac5744c5c61844c57.png" src="_images/97953703a484b81aa2544aafa32d2a678f01625cf2ed411ac5744c5c61844c57.png" />
</div>
</div>
<section id="cluster-for-vae-attention">
<h4>Cluster for VAE + Attention<a class="headerlink" href="#cluster-for-vae-attention" title="Link to this heading">#</a></h4>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">plot_clusters_vae_attention</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">X_data</span><span class="p">):</span>
    <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
        <span class="n">_</span><span class="p">,</span> <span class="n">mu</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">X_data</span><span class="p">)</span>
    <span class="n">mu_np</span> <span class="o">=</span> <span class="n">mu</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>

    <span class="n">adata_latent</span> <span class="o">=</span> <span class="n">sc</span><span class="o">.</span><span class="n">AnnData</span><span class="p">(</span><span class="n">X</span><span class="o">=</span><span class="n">mu_np</span><span class="p">)</span>
    <span class="n">sc</span><span class="o">.</span><span class="n">pp</span><span class="o">.</span><span class="n">neighbors</span><span class="p">(</span><span class="n">adata_latent</span><span class="p">,</span> <span class="n">n_neighbors</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">use_rep</span><span class="o">=</span><span class="s2">&quot;X&quot;</span><span class="p">)</span>
    <span class="n">sc</span><span class="o">.</span><span class="n">tl</span><span class="o">.</span><span class="n">umap</span><span class="p">(</span><span class="n">adata_latent</span><span class="p">)</span>
    <span class="n">umap_coords</span> <span class="o">=</span> <span class="n">adata_latent</span><span class="o">.</span><span class="n">obsm</span><span class="p">[</span><span class="s1">&#39;X_umap&#39;</span><span class="p">]</span>

    <span class="n">methods</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;leiden&#39;</span><span class="p">,</span> <span class="s1">&#39;louvain&#39;</span><span class="p">]</span>
    <span class="n">resolutions</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.4</span><span class="p">,</span> <span class="mf">0.6</span><span class="p">,</span> <span class="mf">0.8</span><span class="p">]</span>

    <span class="n">fig</span><span class="p">,</span> <span class="n">axs</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">methods</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="n">resolutions</span><span class="p">),</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">18</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">method</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">methods</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">j</span><span class="p">,</span> <span class="n">res</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">resolutions</span><span class="p">):</span>
            <span class="n">key</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">method</span><span class="si">}</span><span class="s2">_r</span><span class="si">{</span><span class="n">res</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="k">if</span> <span class="n">method</span> <span class="o">==</span> <span class="s1">&#39;leiden&#39;</span><span class="p">:</span>
                <span class="n">sc</span><span class="o">.</span><span class="n">tl</span><span class="o">.</span><span class="n">leiden</span><span class="p">(</span><span class="n">adata_latent</span><span class="p">,</span> <span class="n">resolution</span><span class="o">=</span><span class="n">res</span><span class="p">,</span> <span class="n">key_added</span><span class="o">=</span><span class="n">key</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">sc</span><span class="o">.</span><span class="n">tl</span><span class="o">.</span><span class="n">louvain</span><span class="p">(</span><span class="n">adata_latent</span><span class="p">,</span> <span class="n">resolution</span><span class="o">=</span><span class="n">res</span><span class="p">,</span> <span class="n">key_added</span><span class="o">=</span><span class="n">key</span><span class="p">)</span>

            <span class="n">labels</span> <span class="o">=</span> <span class="n">adata_latent</span><span class="o">.</span><span class="n">obs</span><span class="p">[</span><span class="n">key</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span><span class="o">.</span><span class="n">values</span>
            <span class="n">axs</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">umap_coords</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">umap_coords</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="n">labels</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;tab20&#39;</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.7</span><span class="p">)</span>
            <span class="n">axs</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">method</span><span class="o">.</span><span class="n">title</span><span class="p">()</span><span class="si">}</span><span class="s2"> (res=</span><span class="si">{</span><span class="n">res</span><span class="si">}</span><span class="s2">)&quot;</span><span class="p">)</span>
            <span class="n">axs</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">&quot;UMAP1&quot;</span><span class="p">)</span>
            <span class="n">axs</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">&quot;UMAP2&quot;</span><span class="p">)</span>

    <span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plot_clusters_vae_attention</span><span class="p">(</span><span class="n">model_attention</span><span class="p">,</span> <span class="n">X_data_tensor</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/adef58cccd6a92fa223093993e5a007881c172068fed84a52ee58b8153d3bd47.png" src="_images/adef58cccd6a92fa223093993e5a007881c172068fed84a52ee58b8153d3bd47.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">device</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="n">model_attention</span><span class="o">.</span><span class="n">parameters</span><span class="p">())</span><span class="o">.</span><span class="n">device</span>
<span class="n">X_data_tensor_device</span> <span class="o">=</span> <span class="n">X_data_tensor</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
<span class="n">metrics_attention_df</span> <span class="o">=</span> <span class="n">evaluate_model_attention_ordered</span><span class="p">(</span><span class="n">model_attention</span><span class="p">,</span> <span class="n">X_data_tensor_device</span><span class="p">)</span>
<span class="n">merged_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">merge</span><span class="p">(</span><span class="n">metrics_df</span><span class="p">,</span> <span class="n">metrics_attention_df</span><span class="p">,</span> <span class="n">on</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;Metric&quot;</span><span class="p">,</span> <span class="s2">&quot;Method&quot;</span><span class="p">,</span> <span class="s2">&quot;Resolution&quot;</span><span class="p">],</span> <span class="n">how</span><span class="o">=</span><span class="s2">&quot;outer&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">merged_df</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Metric</th>
      <th>Method</th>
      <th>Resolution</th>
      <th>VAE</th>
      <th>VAE+Attention</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Silhouette Score</td>
      <td>leiden</td>
      <td>0.4</td>
      <td>0.195177</td>
      <td>0.462208</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Calinski-Harabasz Index</td>
      <td>leiden</td>
      <td>0.4</td>
      <td>510.820769</td>
      <td>3348.233447</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Silhouette Score</td>
      <td>leiden</td>
      <td>0.6</td>
      <td>0.171419</td>
      <td>0.435036</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Calinski-Harabasz Index</td>
      <td>leiden</td>
      <td>0.6</td>
      <td>443.458888</td>
      <td>3652.384527</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Silhouette Score</td>
      <td>leiden</td>
      <td>0.8</td>
      <td>0.076785</td>
      <td>0.411317</td>
    </tr>
    <tr>
      <th>5</th>
      <td>Calinski-Harabasz Index</td>
      <td>leiden</td>
      <td>0.8</td>
      <td>229.003893</td>
      <td>3600.145376</td>
    </tr>
    <tr>
      <th>6</th>
      <td>Silhouette Score</td>
      <td>louvain</td>
      <td>0.4</td>
      <td>-1.000000</td>
      <td>0.408141</td>
    </tr>
    <tr>
      <th>7</th>
      <td>Calinski-Harabasz Index</td>
      <td>louvain</td>
      <td>0.4</td>
      <td>-1.000000</td>
      <td>2133.816489</td>
    </tr>
    <tr>
      <th>8</th>
      <td>Silhouette Score</td>
      <td>louvain</td>
      <td>0.6</td>
      <td>0.106973</td>
      <td>0.390661</td>
    </tr>
    <tr>
      <th>9</th>
      <td>Calinski-Harabasz Index</td>
      <td>louvain</td>
      <td>0.6</td>
      <td>206.088366</td>
      <td>1920.285863</td>
    </tr>
    <tr>
      <th>10</th>
      <td>Silhouette Score</td>
      <td>louvain</td>
      <td>0.8</td>
      <td>0.061618</td>
      <td>0.394807</td>
    </tr>
    <tr>
      <th>11</th>
      <td>Calinski-Harabasz Index</td>
      <td>louvain</td>
      <td>0.8</td>
      <td>230.627533</td>
      <td>1912.544419</td>
    </tr>
    <tr>
      <th>12</th>
      <td>MSE</td>
      <td>None</td>
      <td>NaN</td>
      <td>0.794525</td>
      <td>4.551389</td>
    </tr>
    <tr>
      <th>13</th>
      <td>Pearson Correlation</td>
      <td>None</td>
      <td>NaN</td>
      <td>0.000289</td>
      <td>-0.003726</td>
    </tr>
    <tr>
      <th>14</th>
      <td>Latent Space Normality (p-value)</td>
      <td>None</td>
      <td>NaN</td>
      <td>0.425853</td>
      <td>0.029407</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
</section>
</section>
<section id="differential-expression-for-vae-attention">
<h3>Differential Expression for VAE + Attention<a class="headerlink" href="#differential-expression-for-vae-attention" title="Link to this heading">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model_attention</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
<span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
    <span class="n">x_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">adata_filtered</span><span class="o">.</span><span class="n">X</span><span class="o">.</span><span class="n">A</span> <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">adata_filtered</span><span class="o">.</span><span class="n">X</span><span class="p">,</span> <span class="s2">&quot;A&quot;</span><span class="p">)</span> <span class="k">else</span> <span class="n">adata_filtered</span><span class="o">.</span><span class="n">X</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
    <span class="n">mu</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">model_attention</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">x_tensor</span><span class="p">)</span>
    <span class="n">latent</span> <span class="o">=</span> <span class="n">mu</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">adata_filtered</span><span class="o">.</span><span class="n">obsm</span><span class="p">[</span><span class="s2">&quot;X_latent_attn&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">latent</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">sc</span><span class="o">.</span><span class="n">pp</span><span class="o">.</span><span class="n">neighbors</span><span class="p">(</span><span class="n">adata_filtered</span><span class="p">,</span> <span class="n">use_rep</span><span class="o">=</span><span class="s2">&quot;X_latent_attn&quot;</span><span class="p">,</span> <span class="n">n_neighbors</span><span class="o">=</span><span class="mi">15</span><span class="p">)</span>
<span class="n">sc</span><span class="o">.</span><span class="n">tl</span><span class="o">.</span><span class="n">leiden</span><span class="p">(</span><span class="n">adata_filtered</span><span class="p">,</span> <span class="n">resolution</span><span class="o">=</span><span class="mf">0.6</span><span class="p">,</span> <span class="n">key_added</span><span class="o">=</span><span class="s2">&quot;leiden_attn_0.6&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">sc</span><span class="o">.</span><span class="n">tl</span><span class="o">.</span><span class="n">rank_genes_groups</span><span class="p">(</span>
    <span class="n">adata_filtered</span><span class="p">,</span>
    <span class="n">groupby</span><span class="o">=</span><span class="s2">&quot;leiden_attn_0.6&quot;</span><span class="p">,</span>
    <span class="n">method</span><span class="o">=</span><span class="s2">&quot;wilcoxon&quot;</span><span class="p">,</span>
    <span class="n">use_raw</span><span class="o">=</span><span class="kc">False</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="cluster-interpretation-based-on-marker-ranking-plots">
<h3>Cluster Interpretation Based on Marker Ranking Plots<a class="headerlink" href="#cluster-interpretation-based-on-marker-ranking-plots" title="Link to this heading">#</a></h3>
<div class="pst-scrollable-table-container"><table class="table">
<thead>
<tr class="row-odd"><th class="head"><p>Cluster</p></th>
<th class="head"><p>Top Marker Genes</p></th>
<th class="head"><p>Probable Cell Type</p></th>
<th class="head"><p>Description</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>0</p></td>
<td><p>HLA-DRA, HLA-DRB1, HLA-DPA1, CD74</p></td>
<td><p>Antigen-presenting cells (APCs)</p></td>
<td><p>MHC class II expression suggests activated microglia or dendritic cells presenting antigens to T cells. Common in glioblastoma immune responses.</p></td>
</tr>
<tr class="row-odd"><td><p>1</p></td>
<td><p>S100A9, LYZ, CST3, FCER1G</p></td>
<td><p>Classical monocytes / myeloid cells</p></td>
<td><p>High expression of lysosomal and inflammatory markers indicates innate immune cells like monocytes infiltrating the tumor.</p></td>
</tr>
<tr class="row-even"><td><p>2</p></td>
<td><p>CCL3, CCL4, GZMB, IFNG, NKG7</p></td>
<td><p>Activated cytotoxic T or NK-like cells</p></td>
<td><p>This cluster shows strong pro-inflammatory and cytotoxic profiles, typical of activated effector immune cells targeting tumor cells.</p></td>
</tr>
<tr class="row-odd"><td><p>3</p></td>
<td><p>GNLY, GZMB, PRF1, KLRD1</p></td>
<td><p>NK cells or cytotoxic T lymphocytes</p></td>
<td><p>Cytolytic gene profile suggests innate lymphoid cells capable of tumor cell killing.</p></td>
</tr>
<tr class="row-even"><td><p>4</p></td>
<td><p>IGHM, CD79A, MS4A1, MZB1</p></td>
<td><p>B cells / memory B cells</p></td>
<td><p>Expression of immunoglobulin and BCR-related genes suggests presence of adaptive humoral immune cells in the tumor niche.</p></td>
</tr>
<tr class="row-odd"><td><p>5</p></td>
<td><p>JCHAIN, IGHG1, IGKC</p></td>
<td><p>Plasma cells / antibody-secreting B cells</p></td>
<td><p>High levels of immunoglobulin components suggest these are terminally differentiated B cells involved in antibody production.</p></td>
</tr>
<tr class="row-even"><td><p>6</p></td>
<td><p>HBB, HBA2, AHSP, ALAS2</p></td>
<td><p>Erythroid lineage</p></td>
<td><p>Hemoglobin and erythrocyte genes indicate red blood cells or erythroid precursors, likely due to blood contamination or vascular proximity.</p></td>
</tr>
<tr class="row-odd"><td><p>7</p></td>
<td><p>HLA-DRA, CCL3, CCL4, CD74</p></td>
<td><p>APC-like / microglia</p></td>
<td><p>Similar to cluster 0, suggests a subpopulation of antigen-presenting microglia with inflammatory chemokine signaling.</p></td>
</tr>
<tr class="row-even"><td><p>8</p></td>
<td><p>PPBP, PF4, ITGA2B</p></td>
<td><p>Platelets / megakaryocyte-derived elements</p></td>
<td><p>Platelet markers reflect circulating cell fragments, possibly adhered to vasculature in the glioblastoma microenvironment.</p></td>
</tr>
<tr class="row-odd"><td><p>9</p></td>
<td><p>CD14, FCN1, LYZ</p></td>
<td><p>Classical monocytes / TAM precursors</p></td>
<td><p>Indicative of monocytes that may differentiate into tumor-associated macrophages (TAMs), influencing glioma progression.</p></td>
</tr>
<tr class="row-even"><td><p>10</p></td>
<td><p>GNLY, PRF1, GZMB, KLRD1</p></td>
<td><p>NK cells</p></td>
<td><p>Strong cytotoxic gene signature characteristic of natural killer cells. These are key in innate immune surveillance.</p></td>
</tr>
<tr class="row-odd"><td><p>11</p></td>
<td><p>ZNF683, TRAC, CCL5, GZMK</p></td>
<td><p>CD8+ T cells / tissue-resident memory T cells</p></td>
<td><p>Express cytotoxic and tissue-residency genes, suggesting long-term presence in glioma and adaptive immune memory potential.</p></td>
</tr>
</tbody>
</table>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">sc</span><span class="o">.</span><span class="n">pl</span><span class="o">.</span><span class="n">rank_genes_groups</span><span class="p">(</span><span class="n">adata_filtered</span><span class="p">,</span> <span class="n">n_genes</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">sharey</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">gene_symbols</span><span class="o">=</span><span class="s1">&#39;gene_symbols&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/9eaa8adfe0180c96a8b771ce78d04f4c0367024c49d17b01f32ad33e5dbc846e.png" src="_images/9eaa8adfe0180c96a8b771ce78d04f4c0367024c49d17b01f32ad33e5dbc846e.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">result</span> <span class="o">=</span> <span class="n">adata_filtered</span><span class="o">.</span><span class="n">uns</span><span class="p">[</span><span class="s1">&#39;rank_genes_groups&#39;</span><span class="p">]</span>
<span class="n">groups</span> <span class="o">=</span> <span class="n">result</span><span class="p">[</span><span class="s1">&#39;names&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">dtype</span><span class="o">.</span><span class="n">names</span>
</pre></div>
</div>
</div>
</div>
<p>The green vertical lines represent log fold change thresholds (typically at +1 and -1).</p>
<p>The blue horizontal line represents the p-value threshold (typically at p = 0.05, shown as -log10(0.05) on the y-axis).</p>
<p>If a point (gene) is outside these lines, it means:
To the right of the green line (&gt; +1 logFC):
The gene is strongly upregulated in the cluster compared to the others.</p>
<p>To the left of the green line (&lt; -1 logFC):
The gene is strongly downregulated in the cluster compared to the others.</p>
<p>Above the blue line:
The gene is statistically significant, because its p-value is less than 0.05.</p>
<p>So if a gene is:
Beyond the green lines and above the blue line, it’s considered both:</p>
<p>Statistically significant</p>
<p>Biologically meaningful (large expression change)</p>
<p>These genes (points) are often colored red in the plot because they are the most relevant for biological interpretation.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="n">axs</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">18</span><span class="p">,</span> <span class="mi">20</span><span class="p">))</span>
<span class="n">axs</span> <span class="o">=</span> <span class="n">axs</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>

<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">group</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">groups</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">i</span> <span class="o">&gt;=</span> <span class="nb">len</span><span class="p">(</span><span class="n">axs</span><span class="p">):</span>  
        <span class="k">break</span>

    <span class="c1"># Current group data</span>
    <span class="n">names</span> <span class="o">=</span> <span class="n">result</span><span class="p">[</span><span class="s1">&#39;names&#39;</span><span class="p">][</span><span class="n">group</span><span class="p">]</span>
    <span class="n">logfc</span> <span class="o">=</span> <span class="n">result</span><span class="p">[</span><span class="s1">&#39;logfoldchanges&#39;</span><span class="p">][</span><span class="n">group</span><span class="p">]</span>
    <span class="n">pvals</span> <span class="o">=</span> <span class="n">result</span><span class="p">[</span><span class="s1">&#39;pvals&#39;</span><span class="p">][</span><span class="n">group</span><span class="p">]</span>

    <span class="k">if</span> <span class="s1">&#39;gene_symbols&#39;</span> <span class="ow">in</span> <span class="n">adata_filtered</span><span class="o">.</span><span class="n">var</span><span class="o">.</span><span class="n">columns</span><span class="p">:</span>
        <span class="n">gene_symbols</span> <span class="o">=</span> <span class="n">adata_filtered</span><span class="o">.</span><span class="n">var</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">names</span><span class="p">,</span> <span class="s1">&#39;gene_symbols&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">gene_symbols</span> <span class="o">=</span> <span class="n">names</span>

    <span class="n">volcano_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span>
        <span class="s1">&#39;gene&#39;</span><span class="p">:</span> <span class="n">gene_symbols</span><span class="p">,</span>
        <span class="s1">&#39;logFC&#39;</span><span class="p">:</span> <span class="n">logfc</span><span class="p">,</span>
        <span class="s1">&#39;pval&#39;</span><span class="p">:</span> <span class="n">pvals</span>
    <span class="p">})</span>

    <span class="n">volcano_df</span><span class="p">[</span><span class="s1">&#39;neg_log10_pval&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">log10</span><span class="p">(</span><span class="n">volcano_df</span><span class="p">[</span><span class="s1">&#39;pval&#39;</span><span class="p">])</span>
    <span class="n">volcano_df</span><span class="p">[</span><span class="s1">&#39;significant&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">volcano_df</span><span class="p">[</span><span class="s1">&#39;pval&#39;</span><span class="p">]</span> <span class="o">&lt;</span> <span class="mf">0.05</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="nb">abs</span><span class="p">(</span><span class="n">volcano_df</span><span class="p">[</span><span class="s1">&#39;logFC&#39;</span><span class="p">])</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">)</span>

    <span class="n">ax</span> <span class="o">=</span> <span class="n">axs</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">volcano_df</span><span class="p">[</span><span class="s1">&#39;logFC&#39;</span><span class="p">],</span> <span class="n">volcano_df</span><span class="p">[</span><span class="s1">&#39;neg_log10_pval&#39;</span><span class="p">],</span>
               <span class="n">c</span><span class="o">=</span><span class="n">volcano_df</span><span class="p">[</span><span class="s1">&#39;significant&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">({</span><span class="kc">True</span><span class="p">:</span> <span class="s1">&#39;red&#39;</span><span class="p">,</span> <span class="kc">False</span><span class="p">:</span> <span class="s1">&#39;gray&#39;</span><span class="p">}),</span>
               <span class="n">alpha</span><span class="o">=</span><span class="mf">0.7</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Volcano Plot: Cluster </span><span class="si">{</span><span class="n">group</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;Log Fold Change&#39;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;-log10(p-value)&#39;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">axhline</span><span class="p">(</span><span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">log10</span><span class="p">(</span><span class="mf">0.05</span><span class="p">),</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;blue&#39;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">axvline</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;green&#39;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">axvline</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;green&#39;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>

<span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">axs</span><span class="p">)):</span>
    <span class="n">fig</span><span class="o">.</span><span class="n">delaxes</span><span class="p">(</span><span class="n">axs</span><span class="p">[</span><span class="n">j</span><span class="p">])</span>

<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/155e820268b9cc4f47e7e003c02c722d491dae4988af3eaad77ada4a5b430b07.png" src="_images/155e820268b9cc4f47e7e003c02c722d491dae4988af3eaad77ada4a5b430b07.png" />
</div>
</div>
</section>
</section>
<section id="vae-gat">
<h2>VAE + GAT<a class="headerlink" href="#vae-gat" title="Link to this heading">#</a></h2>
<p>We calculate the expression Graph</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X</span> <span class="o">=</span> <span class="n">adata_filtered</span><span class="o">.</span><span class="n">X</span>
<span class="n">X_array</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">toarray</span><span class="p">()</span> <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="s1">&#39;toarray&#39;</span><span class="p">)</span> <span class="k">else</span> <span class="n">X</span>  

<span class="c1"># CReate the graph using k-NN</span>
<span class="n">k</span> <span class="o">=</span> <span class="mi">10</span>
<span class="n">nbrs</span> <span class="o">=</span> <span class="n">NearestNeighbors</span><span class="p">(</span><span class="n">n_neighbors</span><span class="o">=</span><span class="n">k</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">algorithm</span><span class="o">=</span><span class="s1">&#39;ball_tree&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_array</span><span class="p">)</span>
<span class="n">distances</span><span class="p">,</span> <span class="n">indices</span> <span class="o">=</span> <span class="n">nbrs</span><span class="o">.</span><span class="n">kneighbors</span><span class="p">(</span><span class="n">X_array</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">edges</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">n_cells</span> <span class="o">=</span> <span class="n">X_array</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_cells</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="n">indices</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">1</span><span class="p">:]:</span>  <span class="c1">#not self loop</span>
        <span class="n">edges</span><span class="o">.</span><span class="n">append</span><span class="p">([</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">])</span>
        <span class="n">edges</span><span class="o">.</span><span class="n">append</span><span class="p">([</span><span class="n">j</span><span class="p">,</span> <span class="n">i</span><span class="p">])</span>  <span class="c1"># driven graph</span>

<span class="n">edge_index_cells</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">edges</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">)</span><span class="o">.</span><span class="n">T</span>  <span class="c1"># shape (2, num_edges)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot; Número de aristas: </span><span class="si">{</span><span class="n">edge_index_cells</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot; Número de células (nodos): </span><span class="si">{</span><span class="n">n_cells</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> Número de aristas: 36460
 Número de células (nodos): 1823
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">G</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">Graph</span><span class="p">()</span>
<span class="n">edges</span> <span class="o">=</span> <span class="n">edge_index_cells</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>
<span class="n">G</span><span class="o">.</span><span class="n">add_edges_from</span><span class="p">(</span><span class="n">edges</span><span class="p">)</span>

<span class="c1"># subgraph random sampling</span>
<span class="n">sample_nodes</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">G</span><span class="o">.</span><span class="n">nodes</span><span class="p">),</span> <span class="mi">150</span><span class="p">)</span>
<span class="n">subgraph</span> <span class="o">=</span> <span class="n">G</span><span class="o">.</span><span class="n">subgraph</span><span class="p">(</span><span class="n">sample_nodes</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">8</span><span class="p">))</span>
<span class="n">pos</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">spring_layout</span><span class="p">(</span><span class="n">subgraph</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="n">nx</span><span class="o">.</span><span class="n">draw_networkx_nodes</span><span class="p">(</span><span class="n">subgraph</span><span class="p">,</span> <span class="n">pos</span><span class="p">,</span> <span class="n">node_size</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">node_color</span><span class="o">=</span><span class="s1">&#39;deepskyblue&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.7</span><span class="p">)</span>
<span class="n">nx</span><span class="o">.</span><span class="n">draw_networkx_edges</span><span class="p">(</span><span class="n">subgraph</span><span class="p">,</span> <span class="n">pos</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Subgraph cell-cell (150 nodes)&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s1">&#39;off&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/7cc1cf5d6bf06ae3c9a4aae28c95e0d25aca48bb2cde871e37e17d2497cc591c.png" src="_images/7cc1cf5d6bf06ae3c9a4aae28c95e0d25aca48bb2cde871e37e17d2497cc591c.png" />
</div>
</div>
<section id="hyperparametrization-of-vae-gat">
<h3>Hyperparametrization of VAE + GAT<a class="headerlink" href="#hyperparametrization-of-vae-gat" title="Link to this heading">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span><span class="w"> </span><span class="nc">VAE_GAT_Cell</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_dim</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">,</span> <span class="n">latent_dim</span><span class="p">,</span> <span class="n">dropout_rate</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">num_heads</span><span class="o">=</span><span class="mi">2</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">VAE_GAT_Cell</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">gat1</span> <span class="o">=</span> <span class="n">GATConv</span><span class="p">(</span><span class="n">input_dim</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">,</span> <span class="n">heads</span><span class="o">=</span><span class="n">num_heads</span><span class="p">,</span> <span class="n">concat</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">gat2</span> <span class="o">=</span> <span class="n">GATConv</span><span class="p">(</span><span class="n">hidden_dim</span> <span class="o">*</span> <span class="n">num_heads</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">,</span> <span class="n">heads</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc_mu</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_dim</span><span class="p">,</span> <span class="n">latent_dim</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc_logvar</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_dim</span><span class="p">,</span> <span class="n">latent_dim</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc_p0</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_dim</span><span class="p">,</span> <span class="n">input_dim</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">latent_dim</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ELU</span><span class="p">(),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_dim</span><span class="p">,</span> <span class="n">input_dim</span><span class="p">)</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">dropout_rate</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">encode</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">edge_index</span><span class="p">):</span>
        <span class="n">h</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">elu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">gat1</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">edge_index</span><span class="p">))</span>
        <span class="n">h</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">h</span><span class="p">)</span>
        <span class="n">h</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">elu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">gat2</span><span class="p">(</span><span class="n">h</span><span class="p">,</span> <span class="n">edge_index</span><span class="p">))</span>
        <span class="n">h</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">h</span><span class="p">)</span>
        <span class="n">mu</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc_mu</span><span class="p">(</span><span class="n">h</span><span class="p">)</span>
        <span class="n">log_var</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc_logvar</span><span class="p">(</span><span class="n">h</span><span class="p">)</span>
        <span class="n">p0</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">fc_p0</span><span class="p">(</span><span class="n">h</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">mu</span><span class="p">,</span> <span class="n">log_var</span><span class="p">,</span> <span class="n">p0</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">reparameterize</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">mu</span><span class="p">,</span> <span class="n">log_var</span><span class="p">):</span>
        <span class="n">std</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="mf">0.5</span> <span class="o">*</span> <span class="n">log_var</span><span class="p">)</span>
        <span class="n">eps</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn_like</span><span class="p">(</span><span class="n">std</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">mu</span> <span class="o">+</span> <span class="n">eps</span> <span class="o">*</span> <span class="n">std</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">decode</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">z</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">edge_index</span><span class="p">):</span>
        <span class="n">mu</span><span class="p">,</span> <span class="n">log_var</span><span class="p">,</span> <span class="n">p0</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">edge_index</span><span class="p">)</span>
        <span class="n">z</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">reparameterize</span><span class="p">(</span><span class="n">mu</span><span class="p">,</span> <span class="n">log_var</span><span class="p">)</span>
        <span class="n">x_hat</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">x_hat</span><span class="p">,</span> <span class="n">mu</span><span class="p">,</span> <span class="n">log_var</span><span class="p">,</span> <span class="n">p0</span>
    
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">zinb_loss</span><span class="p">(</span><span class="n">recon_x</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">mu</span><span class="p">,</span> <span class="n">log_var</span><span class="p">,</span> <span class="n">p0</span><span class="p">,</span> <span class="n">beta</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">theta</span><span class="o">=</span><span class="mf">1.0</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">x</span><span class="o">.</span><span class="n">is_sparse</span><span class="p">:</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">to_dense</span><span class="p">()</span>
    <span class="k">if</span> <span class="n">recon_x</span><span class="o">.</span><span class="n">is_sparse</span><span class="p">:</span>
        <span class="n">recon_x</span> <span class="o">=</span> <span class="n">recon_x</span><span class="o">.</span><span class="n">to_dense</span><span class="p">()</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">recon_x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">recon_x</span><span class="p">)</span>
    <span class="n">theta_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">theta</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">x</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">x</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
    <span class="n">theta_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">clamp</span><span class="p">(</span><span class="n">theta_tensor</span><span class="p">,</span> <span class="nb">min</span><span class="o">=</span><span class="mf">1e-6</span><span class="p">,</span> <span class="nb">max</span><span class="o">=</span><span class="mf">1e3</span><span class="p">)</span>
    <span class="n">nb_loss</span> <span class="o">=</span> <span class="o">-</span><span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">lgamma</span><span class="p">(</span><span class="n">x</span> <span class="o">+</span> <span class="n">theta_tensor</span><span class="p">)</span> <span class="o">-</span> <span class="n">torch</span><span class="o">.</span><span class="n">lgamma</span><span class="p">(</span><span class="n">x</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">-</span> <span class="n">torch</span><span class="o">.</span><span class="n">lgamma</span><span class="p">(</span><span class="n">theta_tensor</span><span class="p">)</span> <span class="o">+</span>
                         <span class="n">x</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">recon_x</span> <span class="o">+</span> <span class="mf">1e-8</span><span class="p">)</span> <span class="o">+</span> <span class="n">theta_tensor</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">theta_tensor</span> <span class="o">/</span> <span class="p">(</span><span class="n">recon_x</span> <span class="o">+</span> <span class="mf">1e-8</span><span class="p">)))</span>
    <span class="n">p0</span> <span class="o">=</span> <span class="n">p0</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span>
    <span class="n">p0</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">clamp</span><span class="p">(</span><span class="n">p0</span><span class="p">,</span> <span class="nb">min</span><span class="o">=</span><span class="mf">1e-5</span><span class="p">,</span> <span class="nb">max</span><span class="o">=</span><span class="mi">1</span> <span class="o">-</span> <span class="mf">1e-5</span><span class="p">)</span>
    <span class="n">bernoulli_loss</span> <span class="o">=</span> <span class="o">-</span><span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">x</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">p0</span> <span class="o">+</span> <span class="mf">1e-8</span><span class="p">)</span> <span class="o">+</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">x</span><span class="p">)</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">p0</span> <span class="o">+</span> <span class="mf">1e-8</span><span class="p">))</span>
    <span class="n">mu</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">clamp</span><span class="p">(</span><span class="n">mu</span><span class="p">,</span> <span class="nb">min</span><span class="o">=-</span><span class="mi">10</span><span class="p">,</span> <span class="nb">max</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
    <span class="n">log_var</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">clamp</span><span class="p">(</span><span class="n">log_var</span><span class="p">,</span> <span class="nb">min</span><span class="o">=-</span><span class="mi">10</span><span class="p">,</span> <span class="nb">max</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
    <span class="n">kl_loss</span> <span class="o">=</span> <span class="o">-</span><span class="mf">0.5</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">log_var</span> <span class="o">-</span> <span class="n">mu</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span> <span class="o">-</span> <span class="n">log_var</span><span class="o">.</span><span class="n">exp</span><span class="p">())</span>
    <span class="n">total_loss</span> <span class="o">=</span> <span class="n">nb_loss</span> <span class="o">+</span> <span class="n">bernoulli_loss</span> <span class="o">+</span> <span class="n">beta</span> <span class="o">*</span> <span class="n">kl_loss</span>
    <span class="k">return</span> <span class="n">total_loss</span><span class="p">,</span> <span class="n">nb_loss</span><span class="p">,</span> <span class="n">bernoulli_loss</span><span class="p">,</span> <span class="n">kl_loss</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">set_seed</span><span class="p">(</span><span class="n">seed</span><span class="o">=</span><span class="mi">42</span><span class="p">):</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
    <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
    <span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">():</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">manual_seed_all</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">backends</span><span class="o">.</span><span class="n">cudnn</span><span class="o">.</span><span class="n">deterministic</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">backends</span><span class="o">.</span><span class="n">cudnn</span><span class="o">.</span><span class="n">benchmark</span> <span class="o">=</span> <span class="kc">False</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">latent_dims</span> <span class="o">=</span> <span class="p">[</span><span class="mi">32</span><span class="p">,</span> <span class="mi">64</span><span class="p">]</span>
<span class="n">hidden_dims</span> <span class="o">=</span> <span class="p">[</span><span class="mi">128</span><span class="p">,</span> <span class="mi">256</span><span class="p">]</span>
<span class="n">dropout_rates</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">]</span>
<span class="n">betas</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">]</span>
<span class="n">num_epochs</span> <span class="o">=</span> <span class="mi">200</span>

<span class="n">param_grid</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">product</span><span class="p">(</span><span class="n">latent_dims</span><span class="p">,</span> <span class="n">hidden_dims</span><span class="p">,</span> <span class="n">dropout_rates</span><span class="p">,</span> <span class="n">betas</span><span class="p">))</span>
<span class="n">results</span> <span class="o">=</span> <span class="p">[]</span>

<span class="c1"># Training for each combination</span>
<span class="k">for</span> <span class="n">latent_dim</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">,</span> <span class="n">dropout_rate</span><span class="p">,</span> <span class="n">beta</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span><span class="n">param_grid</span><span class="p">,</span> <span class="n">desc</span><span class="o">=</span><span class="s2">&quot;Grid Search&quot;</span><span class="p">):</span>
    <span class="n">set_seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>

    <span class="n">model</span> <span class="o">=</span> <span class="n">VAE_GAT_Cell</span><span class="p">(</span><span class="n">input_dim</span><span class="o">=</span><span class="n">X_tensor</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span>
                         <span class="n">hidden_dim</span><span class="o">=</span><span class="n">hidden_dim</span><span class="p">,</span>
                         <span class="n">latent_dim</span><span class="o">=</span><span class="n">latent_dim</span><span class="p">,</span>
                         <span class="n">dropout_rate</span><span class="o">=</span><span class="n">dropout_rate</span><span class="p">)</span>
    <span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">)</span>

    <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_epochs</span><span class="p">):</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
        <span class="n">recon_x</span><span class="p">,</span> <span class="n">mu</span><span class="p">,</span> <span class="n">log_var</span><span class="p">,</span> <span class="n">p0</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">X_tensor</span><span class="p">,</span> <span class="n">edge_index_cells</span><span class="p">)</span>
        <span class="n">loss</span><span class="p">,</span> <span class="n">nb_loss</span><span class="p">,</span> <span class="n">bernoulli_loss</span><span class="p">,</span> <span class="n">kl_loss</span> <span class="o">=</span> <span class="n">zinb_loss</span><span class="p">(</span><span class="n">recon_x</span><span class="p">,</span> <span class="n">X_tensor</span><span class="p">,</span> <span class="n">mu</span><span class="p">,</span> <span class="n">log_var</span><span class="p">,</span> <span class="n">p0</span><span class="p">,</span> <span class="n">beta</span><span class="o">=</span><span class="n">beta</span><span class="p">)</span>
        <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

    <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
        <span class="n">recon_x</span><span class="p">,</span> <span class="n">mu</span><span class="p">,</span> <span class="n">log_var</span><span class="p">,</span> <span class="n">p0</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">X_tensor</span><span class="p">,</span> <span class="n">edge_index_cells</span><span class="p">)</span>
        <span class="n">mu_np</span> <span class="o">=</span> <span class="n">mu</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
        <span class="n">pearson_corr</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">corrcoef</span><span class="p">(</span><span class="n">X_tensor</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span><span class="o">.</span><span class="n">flatten</span><span class="p">(),</span> <span class="n">recon_x</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span><span class="o">.</span><span class="n">flatten</span><span class="p">())[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>
        <span class="n">kl_div</span> <span class="o">=</span> <span class="n">kl_loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>

        <span class="n">umap_embeds</span> <span class="o">=</span> <span class="n">umap</span><span class="o">.</span><span class="n">UMAP</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">mu_np</span><span class="p">)</span>
        <span class="n">labels</span> <span class="o">=</span> <span class="n">DBSCAN</span><span class="p">(</span><span class="n">eps</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">min_samples</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span><span class="o">.</span><span class="n">fit_predict</span><span class="p">(</span><span class="n">umap_embeds</span><span class="p">)</span>

        <span class="n">n_clusters</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">labels</span><span class="p">))</span> <span class="o">-</span> <span class="p">(</span><span class="mi">1</span> <span class="k">if</span> <span class="o">-</span><span class="mi">1</span> <span class="ow">in</span> <span class="n">labels</span> <span class="k">else</span> <span class="mi">0</span><span class="p">)</span>
        <span class="n">silhouette</span> <span class="o">=</span> <span class="n">silhouette_score</span><span class="p">(</span><span class="n">umap_embeds</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span> <span class="k">if</span> <span class="n">n_clusters</span> <span class="o">&gt;</span> <span class="mi">1</span> <span class="k">else</span> <span class="o">-</span><span class="mi">1</span>
        <span class="n">calinski</span> <span class="o">=</span> <span class="n">calinski_harabasz_score</span><span class="p">(</span><span class="n">umap_embeds</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span> <span class="k">if</span> <span class="n">n_clusters</span> <span class="o">&gt;</span> <span class="mi">1</span> <span class="k">else</span> <span class="o">-</span><span class="mi">1</span>

    <span class="n">results</span><span class="o">.</span><span class="n">append</span><span class="p">({</span>
        <span class="s1">&#39;latent_dim&#39;</span><span class="p">:</span> <span class="n">latent_dim</span><span class="p">,</span>
        <span class="s1">&#39;hidden_dim&#39;</span><span class="p">:</span> <span class="n">hidden_dim</span><span class="p">,</span>
        <span class="s1">&#39;dropout_rate&#39;</span><span class="p">:</span> <span class="n">dropout_rate</span><span class="p">,</span>
        <span class="s1">&#39;beta&#39;</span><span class="p">:</span> <span class="n">beta</span><span class="p">,</span>
        <span class="s1">&#39;pearson_corr&#39;</span><span class="p">:</span> <span class="n">pearson_corr</span><span class="p">,</span>
        <span class="s1">&#39;silhouette&#39;</span><span class="p">:</span> <span class="n">silhouette</span><span class="p">,</span>
        <span class="s1">&#39;calinski&#39;</span><span class="p">:</span> <span class="n">calinski</span><span class="p">,</span>
        <span class="s1">&#39;kl_divergence&#39;</span><span class="p">:</span> <span class="n">kl_div</span>
    <span class="p">})</span>

<span class="n">results_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">results</span><span class="p">)</span>
<span class="n">results_df</span> <span class="o">=</span> <span class="n">results_df</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="n">by</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;silhouette&quot;</span><span class="p">,</span> <span class="s2">&quot;calinski&quot;</span><span class="p">,</span> <span class="s2">&quot;pearson_corr&quot;</span><span class="p">],</span> <span class="n">ascending</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">results_df</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">10</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Grid Search:   0%|          | 0/16 [00:00&lt;?, ?it/s]c:\Users\henry\miniconda3\envs\dl_venv\lib\site-packages\umap\umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.
  warn(
Grid Search:   6%|▋         | 1/16 [02:07&lt;31:56, 127.74s/it]c:\Users\henry\miniconda3\envs\dl_venv\lib\site-packages\umap\umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.
  warn(
Grid Search:  12%|█▎        | 2/16 [04:08&lt;28:54, 123.91s/it]c:\Users\henry\miniconda3\envs\dl_venv\lib\site-packages\umap\umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.
  warn(
Grid Search:  19%|█▉        | 3/16 [06:11&lt;26:40, 123.08s/it]c:\Users\henry\miniconda3\envs\dl_venv\lib\site-packages\umap\umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.
  warn(
Grid Search:  25%|██▌       | 4/16 [08:10&lt;24:20, 121.70s/it]c:\Users\henry\miniconda3\envs\dl_venv\lib\site-packages\umap\umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.
  warn(
Grid Search:  31%|███▏      | 5/16 [11:00&lt;25:30, 139.12s/it]c:\Users\henry\miniconda3\envs\dl_venv\lib\site-packages\umap\umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.
  warn(
Grid Search:  38%|███▊      | 6/16 [13:49&lt;24:53, 149.31s/it]c:\Users\henry\miniconda3\envs\dl_venv\lib\site-packages\umap\umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.
  warn(
Grid Search:  44%|████▍     | 7/16 [16:29&lt;22:54, 152.70s/it]c:\Users\henry\miniconda3\envs\dl_venv\lib\site-packages\umap\umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.
  warn(
Grid Search:  50%|█████     | 8/16 [19:11&lt;20:45, 155.67s/it]c:\Users\henry\miniconda3\envs\dl_venv\lib\site-packages\umap\umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.
  warn(
Grid Search:  56%|█████▋    | 9/16 [21:13&lt;16:55, 145.04s/it]c:\Users\henry\miniconda3\envs\dl_venv\lib\site-packages\umap\umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.
  warn(
Grid Search:  62%|██████▎   | 10/16 [23:12&lt;13:42, 137.01s/it]c:\Users\henry\miniconda3\envs\dl_venv\lib\site-packages\umap\umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.
  warn(
Grid Search:  69%|██████▉   | 11/16 [25:11&lt;10:57, 131.47s/it]c:\Users\henry\miniconda3\envs\dl_venv\lib\site-packages\umap\umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.
  warn(
Grid Search:  75%|███████▌  | 12/16 [27:10&lt;08:31, 127.82s/it]c:\Users\henry\miniconda3\envs\dl_venv\lib\site-packages\umap\umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.
  warn(
Grid Search:  81%|████████▏ | 13/16 [29:52&lt;06:54, 138.26s/it]c:\Users\henry\miniconda3\envs\dl_venv\lib\site-packages\umap\umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.
  warn(
Grid Search:  88%|████████▊ | 14/16 [32:35&lt;04:51, 145.62s/it]c:\Users\henry\miniconda3\envs\dl_venv\lib\site-packages\umap\umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.
  warn(
Grid Search:  94%|█████████▍| 15/16 [35:51&lt;02:40, 160.87s/it]c:\Users\henry\miniconda3\envs\dl_venv\lib\site-packages\umap\umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.
  warn(
Grid Search: 100%|██████████| 16/16 [39:07&lt;00:00, 146.74s/it]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>    latent_dim  hidden_dim  dropout_rate  beta  pearson_corr  silhouette  \
14          64         256           0.3   0.1      0.000148    0.962478   
15          64         256           0.3   1.0      0.000132    0.948041   
4           32         256           0.1   0.1     -0.000111    0.867644   
11          64         128           0.3   1.0     -0.000403    0.828804   
2           32         128           0.3   0.1      0.000049    0.752601   
5           32         256           0.1   1.0     -0.000075    0.547024   
12          64         256           0.1   0.1     -0.001432    0.385074   
1           32         128           0.1   1.0     -0.001508    0.363834   
7           32         256           0.3   1.0     -0.001574    0.198862   
13          64         256           0.1   1.0      0.000087    0.195343   

         calinski  kl_divergence  
14  417077.597154   1.591323e+07  
15  132579.796732   1.361510e+06  
4     4403.134182   2.890908e+06  
11   15216.441208   4.112711e+05  
2    17909.392912   6.680801e+05  
5    25669.620124   1.265968e+06  
12    1874.009473   1.823830e+06  
1      696.617386   6.159973e+04  
7      743.364529   2.634128e+05  
13     938.828025   1.018689e+06  
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">results_df</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>latent_dim</th>
      <th>hidden_dim</th>
      <th>dropout_rate</th>
      <th>beta</th>
      <th>pearson_corr</th>
      <th>silhouette</th>
      <th>calinski</th>
      <th>kl_divergence</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>14</th>
      <td>64</td>
      <td>256</td>
      <td>0.3</td>
      <td>0.1</td>
      <td>0.000148</td>
      <td>0.962478</td>
      <td>417077.597154</td>
      <td>1.591323e+07</td>
    </tr>
    <tr>
      <th>15</th>
      <td>64</td>
      <td>256</td>
      <td>0.3</td>
      <td>1.0</td>
      <td>0.000132</td>
      <td>0.948041</td>
      <td>132579.796732</td>
      <td>1.361510e+06</td>
    </tr>
    <tr>
      <th>4</th>
      <td>32</td>
      <td>256</td>
      <td>0.1</td>
      <td>0.1</td>
      <td>-0.000111</td>
      <td>0.867644</td>
      <td>4403.134182</td>
      <td>2.890908e+06</td>
    </tr>
    <tr>
      <th>11</th>
      <td>64</td>
      <td>128</td>
      <td>0.3</td>
      <td>1.0</td>
      <td>-0.000403</td>
      <td>0.828804</td>
      <td>15216.441208</td>
      <td>4.112711e+05</td>
    </tr>
    <tr>
      <th>2</th>
      <td>32</td>
      <td>128</td>
      <td>0.3</td>
      <td>0.1</td>
      <td>0.000049</td>
      <td>0.752601</td>
      <td>17909.392912</td>
      <td>6.680801e+05</td>
    </tr>
    <tr>
      <th>5</th>
      <td>32</td>
      <td>256</td>
      <td>0.1</td>
      <td>1.0</td>
      <td>-0.000075</td>
      <td>0.547024</td>
      <td>25669.620124</td>
      <td>1.265968e+06</td>
    </tr>
    <tr>
      <th>12</th>
      <td>64</td>
      <td>256</td>
      <td>0.1</td>
      <td>0.1</td>
      <td>-0.001432</td>
      <td>0.385074</td>
      <td>1874.009473</td>
      <td>1.823830e+06</td>
    </tr>
    <tr>
      <th>1</th>
      <td>32</td>
      <td>128</td>
      <td>0.1</td>
      <td>1.0</td>
      <td>-0.001508</td>
      <td>0.363834</td>
      <td>696.617386</td>
      <td>6.159973e+04</td>
    </tr>
    <tr>
      <th>7</th>
      <td>32</td>
      <td>256</td>
      <td>0.3</td>
      <td>1.0</td>
      <td>-0.001574</td>
      <td>0.198862</td>
      <td>743.364529</td>
      <td>2.634128e+05</td>
    </tr>
    <tr>
      <th>13</th>
      <td>64</td>
      <td>256</td>
      <td>0.1</td>
      <td>1.0</td>
      <td>0.000087</td>
      <td>0.195343</td>
      <td>938.828025</td>
      <td>1.018689e+06</td>
    </tr>
    <tr>
      <th>8</th>
      <td>64</td>
      <td>128</td>
      <td>0.1</td>
      <td>0.1</td>
      <td>0.001138</td>
      <td>0.088228</td>
      <td>636.894494</td>
      <td>3.178297e+05</td>
    </tr>
    <tr>
      <th>9</th>
      <td>64</td>
      <td>128</td>
      <td>0.1</td>
      <td>1.0</td>
      <td>-0.000162</td>
      <td>0.034470</td>
      <td>760.341408</td>
      <td>3.081613e+05</td>
    </tr>
    <tr>
      <th>3</th>
      <td>32</td>
      <td>128</td>
      <td>0.3</td>
      <td>1.0</td>
      <td>-0.000410</td>
      <td>0.015829</td>
      <td>960.967203</td>
      <td>1.860802e+05</td>
    </tr>
    <tr>
      <th>6</th>
      <td>32</td>
      <td>256</td>
      <td>0.3</td>
      <td>0.1</td>
      <td>0.000628</td>
      <td>0.006562</td>
      <td>500.019505</td>
      <td>2.328310e+06</td>
    </tr>
    <tr>
      <th>10</th>
      <td>64</td>
      <td>128</td>
      <td>0.3</td>
      <td>0.1</td>
      <td>-0.001180</td>
      <td>-0.006513</td>
      <td>296.436004</td>
      <td>1.937551e+05</td>
    </tr>
    <tr>
      <th>0</th>
      <td>32</td>
      <td>128</td>
      <td>0.1</td>
      <td>0.1</td>
      <td>0.003605</td>
      <td>-0.314394</td>
      <td>70.165057</td>
      <td>1.829032e+05</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<section id="model-defined-vae-gat">
<h4>Model Defined VAE + GAT<a class="headerlink" href="#model-defined-vae-gat" title="Link to this heading">#</a></h4>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">n_genes</span> <span class="o">=</span> <span class="n">adata_filtered</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>  <span class="c1"># columns</span>
<span class="n">input_dim</span> <span class="o">=</span> <span class="n">n_genes</span>
<span class="n">hidden_dim</span> <span class="o">=</span> <span class="mi">256</span>
<span class="n">latent_dim</span> <span class="o">=</span> <span class="mi">64</span> <span class="c1">#latent dimension</span>
<span class="n">learning_rate</span> <span class="o">=</span> <span class="mf">1e-3</span>
<span class="n">num_epochs</span> <span class="o">=</span> <span class="mi">200</span>
<span class="n">X_data</span> <span class="o">=</span> <span class="n">adata_filtered</span><span class="o">.</span><span class="n">X</span>  
<span class="n">X</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span><span class="p">(</span><span class="n">X_data</span><span class="p">)</span>
<span class="n">X_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span><span class="p">(</span><span class="n">adata_filtered</span><span class="o">.</span><span class="n">X</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span><span class="w"> </span><span class="nc">VAE_GAT_Cell</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_dim</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span> <span class="n">latent_dim</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span> <span class="n">dropout_rate</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">num_heads</span><span class="o">=</span><span class="mi">2</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">VAE_GAT_Cell</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">gat1</span> <span class="o">=</span> <span class="n">GATConv</span><span class="p">(</span><span class="n">input_dim</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">,</span> <span class="n">heads</span><span class="o">=</span><span class="n">num_heads</span><span class="p">,</span> <span class="n">concat</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">gat2</span> <span class="o">=</span> <span class="n">GATConv</span><span class="p">(</span><span class="n">hidden_dim</span> <span class="o">*</span> <span class="n">num_heads</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">,</span> <span class="n">heads</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc_mu</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_dim</span><span class="p">,</span> <span class="n">latent_dim</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc_logvar</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_dim</span><span class="p">,</span> <span class="n">latent_dim</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc_p0</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_dim</span><span class="p">,</span> <span class="n">input_dim</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">latent_dim</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ELU</span><span class="p">(),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_dim</span><span class="p">,</span> <span class="n">input_dim</span><span class="p">)</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">dropout_rate</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">encode</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">edge_index</span><span class="p">):</span>
        <span class="n">h</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">elu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">gat1</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">edge_index</span><span class="p">))</span>
        <span class="n">h</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">h</span><span class="p">)</span>
        <span class="n">h</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">elu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">gat2</span><span class="p">(</span><span class="n">h</span><span class="p">,</span> <span class="n">edge_index</span><span class="p">))</span>
        <span class="n">h</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">h</span><span class="p">)</span>
        <span class="n">mu</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc_mu</span><span class="p">(</span><span class="n">h</span><span class="p">)</span>
        <span class="n">log_var</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc_logvar</span><span class="p">(</span><span class="n">h</span><span class="p">)</span>
        <span class="n">p0</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">fc_p0</span><span class="p">(</span><span class="n">h</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">mu</span><span class="p">,</span> <span class="n">log_var</span><span class="p">,</span> <span class="n">p0</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">reparameterize</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">mu</span><span class="p">,</span> <span class="n">log_var</span><span class="p">):</span>
        <span class="n">std</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="mf">0.5</span> <span class="o">*</span> <span class="n">log_var</span><span class="p">)</span>
        <span class="n">eps</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn_like</span><span class="p">(</span><span class="n">std</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">mu</span> <span class="o">+</span> <span class="n">eps</span> <span class="o">*</span> <span class="n">std</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">decode</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">z</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">edge_index</span><span class="p">):</span>
        <span class="n">mu</span><span class="p">,</span> <span class="n">log_var</span><span class="p">,</span> <span class="n">p0</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">edge_index</span><span class="p">)</span>
        <span class="n">z</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">reparameterize</span><span class="p">(</span><span class="n">mu</span><span class="p">,</span> <span class="n">log_var</span><span class="p">)</span>
        <span class="n">x_hat</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">x_hat</span><span class="p">,</span> <span class="n">mu</span><span class="p">,</span> <span class="n">log_var</span><span class="p">,</span> <span class="n">p0</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">zinb_loss</span><span class="p">(</span><span class="n">recon_x</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">mu</span><span class="p">,</span> <span class="n">log_var</span><span class="p">,</span> <span class="n">p0</span><span class="p">,</span> <span class="n">beta</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">theta</span><span class="o">=</span><span class="mf">1.0</span><span class="p">):</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">to_dense</span><span class="p">()</span> <span class="k">if</span> <span class="n">x</span><span class="o">.</span><span class="n">is_sparse</span> <span class="k">else</span> <span class="n">x</span>
    <span class="n">recon_x</span> <span class="o">=</span> <span class="n">recon_x</span><span class="o">.</span><span class="n">to_dense</span><span class="p">()</span> <span class="k">if</span> <span class="n">recon_x</span><span class="o">.</span><span class="n">is_sparse</span> <span class="k">else</span> <span class="n">recon_x</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">recon_x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">recon_x</span><span class="p">)</span>
    <span class="n">theta_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">theta</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">x</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">x</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
    <span class="n">theta_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">clamp</span><span class="p">(</span><span class="n">theta_tensor</span><span class="p">,</span> <span class="nb">min</span><span class="o">=</span><span class="mf">1e-6</span><span class="p">,</span> <span class="nb">max</span><span class="o">=</span><span class="mf">1e3</span><span class="p">)</span>

    <span class="n">nb_loss</span> <span class="o">=</span> <span class="o">-</span><span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">lgamma</span><span class="p">(</span><span class="n">x</span> <span class="o">+</span> <span class="n">theta_tensor</span><span class="p">)</span> <span class="o">-</span> <span class="n">torch</span><span class="o">.</span><span class="n">lgamma</span><span class="p">(</span><span class="n">x</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">-</span> <span class="n">torch</span><span class="o">.</span><span class="n">lgamma</span><span class="p">(</span><span class="n">theta_tensor</span><span class="p">)</span> <span class="o">+</span>
                         <span class="n">x</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">recon_x</span> <span class="o">+</span> <span class="mf">1e-8</span><span class="p">)</span> <span class="o">+</span> <span class="n">theta_tensor</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">theta_tensor</span> <span class="o">/</span> <span class="p">(</span><span class="n">recon_x</span> <span class="o">+</span> <span class="mf">1e-8</span><span class="p">)))</span>
    <span class="n">p0</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">clamp</span><span class="p">(</span><span class="n">p0</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">1</span><span class="p">)),</span> <span class="nb">min</span><span class="o">=</span><span class="mf">1e-5</span><span class="p">,</span> <span class="nb">max</span><span class="o">=</span><span class="mi">1</span> <span class="o">-</span> <span class="mf">1e-5</span><span class="p">)</span>
    <span class="n">bernoulli_loss</span> <span class="o">=</span> <span class="o">-</span><span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">x</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">p0</span> <span class="o">+</span> <span class="mf">1e-8</span><span class="p">)</span> <span class="o">+</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">x</span><span class="p">)</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">p0</span> <span class="o">+</span> <span class="mf">1e-8</span><span class="p">))</span>
    <span class="n">mu</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">clamp</span><span class="p">(</span><span class="n">mu</span><span class="p">,</span> <span class="nb">min</span><span class="o">=-</span><span class="mi">10</span><span class="p">,</span> <span class="nb">max</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
    <span class="n">log_var</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">clamp</span><span class="p">(</span><span class="n">log_var</span><span class="p">,</span> <span class="nb">min</span><span class="o">=-</span><span class="mi">10</span><span class="p">,</span> <span class="nb">max</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
    <span class="n">kl_loss</span> <span class="o">=</span> <span class="o">-</span><span class="mf">0.5</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">log_var</span> <span class="o">-</span> <span class="n">mu</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span> <span class="o">-</span> <span class="n">log_var</span><span class="o">.</span><span class="n">exp</span><span class="p">())</span>
    <span class="n">total_loss</span> <span class="o">=</span> <span class="n">nb_loss</span> <span class="o">+</span> <span class="n">bernoulli_loss</span> <span class="o">+</span> <span class="n">beta</span> <span class="o">*</span> <span class="n">kl_loss</span>
    <span class="k">return</span> <span class="n">total_loss</span><span class="p">,</span> <span class="n">nb_loss</span><span class="p">,</span> <span class="n">bernoulli_loss</span><span class="p">,</span> <span class="n">kl_loss</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">VAE_GAT_Cell</span><span class="p">(</span><span class="n">input_dim</span><span class="o">=</span><span class="n">X_tensor</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">)</span>

<span class="n">losses</span><span class="p">,</span> <span class="n">nb_losses</span><span class="p">,</span> <span class="n">bernoulli_losses</span><span class="p">,</span> <span class="n">kl_losses</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[],</span> <span class="p">[],</span> <span class="p">[]</span>

<span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">200</span><span class="p">):</span>
    <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
    <span class="n">recon_x</span><span class="p">,</span> <span class="n">mu</span><span class="p">,</span> <span class="n">log_var</span><span class="p">,</span> <span class="n">p0</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">X_tensor</span><span class="p">,</span> <span class="n">edge_index_cells</span><span class="p">)</span>
    <span class="n">loss</span><span class="p">,</span> <span class="n">nb_loss</span><span class="p">,</span> <span class="n">bernoulli_loss</span><span class="p">,</span> <span class="n">kl_loss</span> <span class="o">=</span> <span class="n">zinb_loss</span><span class="p">(</span><span class="n">recon_x</span><span class="p">,</span> <span class="n">X_tensor</span><span class="p">,</span> <span class="n">mu</span><span class="p">,</span> <span class="n">log_var</span><span class="p">,</span> <span class="n">p0</span><span class="p">,</span> <span class="n">beta</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
    <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
    <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

    <span class="n">losses</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>
    <span class="n">nb_losses</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nb_loss</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>
    <span class="n">bernoulli_losses</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">bernoulli_loss</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>
    <span class="n">kl_losses</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">kl_loss</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Total Loss</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">losses</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Total Loss&#39;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;blue&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Total Loss - VAE + GAT&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Épocas&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Pérdida&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="c1"># NB Loss</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">nb_losses</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;NB Loss&#39;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;green&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;NB Loss - VAE + GAT&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Épocas&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Pérdida&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="c1"># Bernoulli Loss</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">bernoulli_losses</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Bernoulli Loss&#39;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;orange&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Bernoulli Loss - VAE + GAT&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Épocas&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Pérdida&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="c1"># KL Loss</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">kl_losses</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;KL Loss&#39;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;red&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;KL Divergence - VAE + GAT&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Épocas&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Pérdida&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/023ed8446e81b92b4871f029577949e3a4cb7504745d4631f82126dffab76268.png" src="_images/023ed8446e81b92b4871f029577949e3a4cb7504745d4631f82126dffab76268.png" />
<img alt="_images/562148d10fccf3ea60eb9b4ddf8c31193c27566d03d92955adb98765d2bba862.png" src="_images/562148d10fccf3ea60eb9b4ddf8c31193c27566d03d92955adb98765d2bba862.png" />
<img alt="_images/6d93c99174b5b9b848963bc47ba0352801e4f0e1902f94407d70e93c6a9f93ad.png" src="_images/6d93c99174b5b9b848963bc47ba0352801e4f0e1902f94407d70e93c6a9f93ad.png" />
<img alt="_images/f8b4ff86c70db6931ebee8fbf2cf22b9886cda465e13e4f45bd9f04795b2a618.png" src="_images/f8b4ff86c70db6931ebee8fbf2cf22b9886cda465e13e4f45bd9f04795b2a618.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">adata_latent</span> <span class="o">=</span> <span class="n">sc</span><span class="o">.</span><span class="n">AnnData</span><span class="p">(</span><span class="n">X</span><span class="o">=</span><span class="n">mu</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>
<span class="n">sc</span><span class="o">.</span><span class="n">pp</span><span class="o">.</span><span class="n">neighbors</span><span class="p">(</span><span class="n">adata_latent</span><span class="p">,</span> <span class="n">n_neighbors</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">use_rep</span><span class="o">=</span><span class="s1">&#39;X&#39;</span><span class="p">)</span>
<span class="n">sc</span><span class="o">.</span><span class="n">tl</span><span class="o">.</span><span class="n">umap</span><span class="p">(</span><span class="n">adata_latent</span><span class="p">)</span>
<span class="n">umap_coords</span> <span class="o">=</span> <span class="n">adata_latent</span><span class="o">.</span><span class="n">obsm</span><span class="p">[</span><span class="s1">&#39;X_umap&#39;</span><span class="p">]</span>

<span class="n">resolutions</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.4</span><span class="p">,</span> <span class="mf">0.6</span><span class="p">,</span> <span class="mf">0.8</span><span class="p">]</span>
<span class="n">methods</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;leiden&#39;</span><span class="p">,</span> <span class="s1">&#39;louvain&#39;</span><span class="p">]</span>
<span class="n">clustering_results</span> <span class="o">=</span> <span class="p">[]</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">axs</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">18</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>
<span class="n">axs</span> <span class="o">=</span> <span class="n">axs</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>
<span class="n">i</span> <span class="o">=</span> <span class="mi">0</span>

<span class="k">for</span> <span class="n">method</span> <span class="ow">in</span> <span class="n">methods</span><span class="p">:</span>
    <span class="k">for</span> <span class="n">res</span> <span class="ow">in</span> <span class="n">resolutions</span><span class="p">:</span>
        <span class="n">key</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">method</span><span class="si">}</span><span class="s2">_r&quot;</span>
        <span class="k">if</span> <span class="n">method</span> <span class="o">==</span> <span class="s1">&#39;leiden&#39;</span><span class="p">:</span>
            <span class="n">sc</span><span class="o">.</span><span class="n">tl</span><span class="o">.</span><span class="n">leiden</span><span class="p">(</span><span class="n">adata_latent</span><span class="p">,</span> <span class="n">resolution</span><span class="o">=</span><span class="n">res</span><span class="p">,</span> <span class="n">key_added</span><span class="o">=</span><span class="n">key</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">sc</span><span class="o">.</span><span class="n">tl</span><span class="o">.</span><span class="n">louvain</span><span class="p">(</span><span class="n">adata_latent</span><span class="p">,</span> <span class="n">resolution</span><span class="o">=</span><span class="n">res</span><span class="p">,</span> <span class="n">key_added</span><span class="o">=</span><span class="n">key</span><span class="p">)</span>

        <span class="n">labels</span> <span class="o">=</span> <span class="n">adata_latent</span><span class="o">.</span><span class="n">obs</span><span class="p">[</span><span class="n">key</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span><span class="o">.</span><span class="n">values</span>
        <span class="n">n_clusters</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">labels</span><span class="p">))</span>
        <span class="n">silh</span> <span class="o">=</span> <span class="n">silhouette_score</span><span class="p">(</span><span class="n">umap_coords</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span> <span class="k">if</span> <span class="n">n_clusters</span> <span class="o">&gt;</span> <span class="mi">1</span> <span class="k">else</span> <span class="o">-</span><span class="mi">1</span>
        <span class="n">ch</span> <span class="o">=</span> <span class="n">calinski_harabasz_score</span><span class="p">(</span><span class="n">umap_coords</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span> <span class="k">if</span> <span class="n">n_clusters</span> <span class="o">&gt;</span> <span class="mi">1</span> <span class="k">else</span> <span class="o">-</span><span class="mi">1</span>

        <span class="n">clustering_results</span><span class="o">.</span><span class="n">append</span><span class="p">({</span>
            <span class="s1">&#39;method&#39;</span><span class="p">:</span> <span class="n">method</span><span class="p">,</span>
            <span class="s1">&#39;resolution&#39;</span><span class="p">:</span> <span class="n">res</span><span class="p">,</span>
            <span class="s1">&#39;n_clusters&#39;</span><span class="p">:</span> <span class="n">n_clusters</span><span class="p">,</span>
            <span class="s1">&#39;silhouette&#39;</span><span class="p">:</span> <span class="n">silh</span><span class="p">,</span>
            <span class="s1">&#39;calinski_harabasz&#39;</span><span class="p">:</span> <span class="n">ch</span>
        <span class="p">})</span>

        <span class="n">axs</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">umap_coords</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">umap_coords</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="n">labels</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;tab20&#39;</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.7</span><span class="p">)</span>
        <span class="n">axs</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">method</span><span class="o">.</span><span class="n">title</span><span class="p">()</span><span class="si">}</span><span class="s2"> (res=</span><span class="si">{</span><span class="n">res</span><span class="si">}</span><span class="s2">)</span><span class="se">\n</span><span class="s2">Silh=</span><span class="si">{</span><span class="n">silh</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">  CH=</span><span class="si">{</span><span class="n">ch</span><span class="si">:</span><span class="s2">.1f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="n">axs</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">&quot;UMAP1&quot;</span><span class="p">)</span>
        <span class="n">axs</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">&quot;UMAP2&quot;</span><span class="p">)</span>
        <span class="n">i</span> <span class="o">+=</span> <span class="mi">1</span>

<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/1264956e81f707a9178dbf1daa16b03a87e3d43ef339a21794dbeb86b3d949bf.png" src="_images/1264956e81f707a9178dbf1daa16b03a87e3d43ef339a21794dbeb86b3d949bf.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># recon_np = recon_x.detach().numpy()</span>
<span class="c1"># pearson_corr = np.corrcoef(X_tensor.numpy().flatten(), recon_np.flatten())[0, 1]</span>
<span class="c1"># kl_div = kl_loss.item()</span>

<span class="c1"># metrics_df = pd.DataFrame({</span>
<span class="c1">#     &#39;Metric&#39;: [&#39;Pearson Corr&#39;, &#39;Silhouette Score&#39;, &#39;Calinski-Harabasz&#39;, &#39;KL Divergence&#39;],</span>
<span class="c1">#     &#39;VAE + GAT&#39;: [pearson_corr, silh, ch, kl_div]</span>
<span class="c1"># })</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># pd.set_option(&#39;display.float_format&#39;, &#39;{:.6f}&#39;.format)</span>
<span class="c1"># metrics_df</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">evaluate_model_vae_gat</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">X_data</span><span class="p">,</span> <span class="n">edge_index</span><span class="p">):</span>
    <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
        <span class="n">recon</span><span class="p">,</span> <span class="n">mu</span><span class="p">,</span> <span class="n">log_var</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">X_data</span><span class="p">,</span> <span class="n">edge_index</span><span class="p">)</span>
    <span class="n">mu_np</span> <span class="o">=</span> <span class="n">mu</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
    <span class="n">X_np</span> <span class="o">=</span> <span class="n">X_data</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
    <span class="n">recon_np</span> <span class="o">=</span> <span class="n">recon</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>

    <span class="n">mse</span> <span class="o">=</span> <span class="n">mean_squared_error</span><span class="p">(</span><span class="n">X_np</span><span class="o">.</span><span class="n">flatten</span><span class="p">(),</span> <span class="n">recon_np</span><span class="o">.</span><span class="n">flatten</span><span class="p">())</span>
    <span class="n">pearson_corr</span> <span class="o">=</span> <span class="n">pearsonr</span><span class="p">(</span><span class="n">X_np</span><span class="o">.</span><span class="n">flatten</span><span class="p">(),</span> <span class="n">recon_np</span><span class="o">.</span><span class="n">flatten</span><span class="p">())[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">latent_normality_pval</span> <span class="o">=</span> <span class="n">normaltest</span><span class="p">(</span><span class="n">mu_np</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">pvalue</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>

    <span class="n">adata_latent</span> <span class="o">=</span> <span class="n">sc</span><span class="o">.</span><span class="n">AnnData</span><span class="p">(</span><span class="n">X</span><span class="o">=</span><span class="n">mu_np</span><span class="p">)</span>
    <span class="n">sc</span><span class="o">.</span><span class="n">pp</span><span class="o">.</span><span class="n">neighbors</span><span class="p">(</span><span class="n">adata_latent</span><span class="p">,</span> <span class="n">n_neighbors</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">use_rep</span><span class="o">=</span><span class="s2">&quot;X&quot;</span><span class="p">)</span>
    <span class="n">sc</span><span class="o">.</span><span class="n">tl</span><span class="o">.</span><span class="n">umap</span><span class="p">(</span><span class="n">adata_latent</span><span class="p">)</span>

    <span class="n">metrics</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">methods</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;leiden&#39;</span><span class="p">,</span> <span class="s1">&#39;louvain&#39;</span><span class="p">]</span>
    <span class="n">resolutions</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.4</span><span class="p">,</span> <span class="mf">0.6</span><span class="p">,</span> <span class="mf">0.8</span><span class="p">]</span>

    <span class="k">for</span> <span class="n">method</span> <span class="ow">in</span> <span class="n">methods</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">res</span> <span class="ow">in</span> <span class="n">resolutions</span><span class="p">:</span>
            <span class="n">key</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">method</span><span class="si">}</span><span class="s2">_r</span><span class="si">{</span><span class="n">res</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="k">if</span> <span class="n">method</span> <span class="o">==</span> <span class="s1">&#39;leiden&#39;</span><span class="p">:</span>
                <span class="n">sc</span><span class="o">.</span><span class="n">tl</span><span class="o">.</span><span class="n">leiden</span><span class="p">(</span><span class="n">adata_latent</span><span class="p">,</span> <span class="n">resolution</span><span class="o">=</span><span class="n">res</span><span class="p">,</span> <span class="n">key_added</span><span class="o">=</span><span class="n">key</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">sc</span><span class="o">.</span><span class="n">tl</span><span class="o">.</span><span class="n">louvain</span><span class="p">(</span><span class="n">adata_latent</span><span class="p">,</span> <span class="n">resolution</span><span class="o">=</span><span class="n">res</span><span class="p">,</span> <span class="n">key_added</span><span class="o">=</span><span class="n">key</span><span class="p">)</span>

            <span class="n">labels</span> <span class="o">=</span> <span class="n">adata_latent</span><span class="o">.</span><span class="n">obs</span><span class="p">[</span><span class="n">key</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span><span class="o">.</span><span class="n">values</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">labels</span><span class="p">))</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
                <span class="n">silh</span> <span class="o">=</span> <span class="n">silhouette_score</span><span class="p">(</span><span class="n">adata_latent</span><span class="o">.</span><span class="n">obsm</span><span class="p">[</span><span class="s1">&#39;X_umap&#39;</span><span class="p">],</span> <span class="n">labels</span><span class="p">)</span>
                <span class="n">ch</span> <span class="o">=</span> <span class="n">calinski_harabasz_score</span><span class="p">(</span><span class="n">adata_latent</span><span class="o">.</span><span class="n">obsm</span><span class="p">[</span><span class="s1">&#39;X_umap&#39;</span><span class="p">],</span> <span class="n">labels</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">silh</span><span class="p">,</span> <span class="n">ch</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span>

            <span class="n">metrics</span><span class="o">.</span><span class="n">append</span><span class="p">({</span><span class="s1">&#39;Metric&#39;</span><span class="p">:</span> <span class="s1">&#39;Silhouette Score&#39;</span><span class="p">,</span> <span class="s1">&#39;Value&#39;</span><span class="p">:</span> <span class="n">silh</span><span class="p">,</span> <span class="s1">&#39;Method&#39;</span><span class="p">:</span> <span class="n">method</span><span class="p">,</span> <span class="s1">&#39;Resolution&#39;</span><span class="p">:</span> <span class="n">res</span><span class="p">})</span>
            <span class="n">metrics</span><span class="o">.</span><span class="n">append</span><span class="p">({</span><span class="s1">&#39;Metric&#39;</span><span class="p">:</span> <span class="s1">&#39;Calinski-Harabasz Index&#39;</span><span class="p">,</span> <span class="s1">&#39;Value&#39;</span><span class="p">:</span> <span class="n">ch</span><span class="p">,</span> <span class="s1">&#39;Method&#39;</span><span class="p">:</span> <span class="n">method</span><span class="p">,</span> <span class="s1">&#39;Resolution&#39;</span><span class="p">:</span> <span class="n">res</span><span class="p">})</span>

    <span class="n">metrics</span><span class="o">.</span><span class="n">extend</span><span class="p">([</span>
        <span class="p">{</span><span class="s1">&#39;Metric&#39;</span><span class="p">:</span> <span class="s1">&#39;MSE&#39;</span><span class="p">,</span> <span class="s1">&#39;Value&#39;</span><span class="p">:</span> <span class="n">mse</span><span class="p">,</span> <span class="s1">&#39;Method&#39;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">,</span> <span class="s1">&#39;Resolution&#39;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">},</span>
        <span class="p">{</span><span class="s1">&#39;Metric&#39;</span><span class="p">:</span> <span class="s1">&#39;Pearson Correlation&#39;</span><span class="p">,</span> <span class="s1">&#39;Value&#39;</span><span class="p">:</span> <span class="n">pearson_corr</span><span class="p">,</span> <span class="s1">&#39;Method&#39;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">,</span> <span class="s1">&#39;Resolution&#39;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">},</span>
        <span class="p">{</span><span class="s1">&#39;Metric&#39;</span><span class="p">:</span> <span class="s1">&#39;Latent Space Normality (p-value)&#39;</span><span class="p">,</span> <span class="s1">&#39;Value&#39;</span><span class="p">:</span> <span class="n">latent_normality_pval</span><span class="p">,</span> <span class="s1">&#39;Method&#39;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">,</span> <span class="s1">&#39;Resolution&#39;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">}</span>
    <span class="p">])</span>

    <span class="n">df_metrics</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">metrics</span><span class="p">)</span>

    <span class="n">metric_order</span> <span class="o">=</span> <span class="p">[</span>
        <span class="p">(</span><span class="s1">&#39;Silhouette Score&#39;</span><span class="p">,</span> <span class="s1">&#39;leiden&#39;</span><span class="p">,</span> <span class="mf">0.4</span><span class="p">),</span>
        <span class="p">(</span><span class="s1">&#39;Calinski-Harabasz Index&#39;</span><span class="p">,</span> <span class="s1">&#39;leiden&#39;</span><span class="p">,</span> <span class="mf">0.4</span><span class="p">),</span>
        <span class="p">(</span><span class="s1">&#39;Silhouette Score&#39;</span><span class="p">,</span> <span class="s1">&#39;leiden&#39;</span><span class="p">,</span> <span class="mf">0.6</span><span class="p">),</span>
        <span class="p">(</span><span class="s1">&#39;Calinski-Harabasz Index&#39;</span><span class="p">,</span> <span class="s1">&#39;leiden&#39;</span><span class="p">,</span> <span class="mf">0.6</span><span class="p">),</span>
        <span class="p">(</span><span class="s1">&#39;Silhouette Score&#39;</span><span class="p">,</span> <span class="s1">&#39;leiden&#39;</span><span class="p">,</span> <span class="mf">0.8</span><span class="p">),</span>
        <span class="p">(</span><span class="s1">&#39;Calinski-Harabasz Index&#39;</span><span class="p">,</span> <span class="s1">&#39;leiden&#39;</span><span class="p">,</span> <span class="mf">0.8</span><span class="p">),</span>
        <span class="p">(</span><span class="s1">&#39;Silhouette Score&#39;</span><span class="p">,</span> <span class="s1">&#39;louvain&#39;</span><span class="p">,</span> <span class="mf">0.4</span><span class="p">),</span>
        <span class="p">(</span><span class="s1">&#39;Calinski-Harabasz Index&#39;</span><span class="p">,</span> <span class="s1">&#39;louvain&#39;</span><span class="p">,</span> <span class="mf">0.4</span><span class="p">),</span>
        <span class="p">(</span><span class="s1">&#39;Silhouette Score&#39;</span><span class="p">,</span> <span class="s1">&#39;louvain&#39;</span><span class="p">,</span> <span class="mf">0.6</span><span class="p">),</span>
        <span class="p">(</span><span class="s1">&#39;Calinski-Harabasz Index&#39;</span><span class="p">,</span> <span class="s1">&#39;louvain&#39;</span><span class="p">,</span> <span class="mf">0.6</span><span class="p">),</span>
        <span class="p">(</span><span class="s1">&#39;Silhouette Score&#39;</span><span class="p">,</span> <span class="s1">&#39;louvain&#39;</span><span class="p">,</span> <span class="mf">0.8</span><span class="p">),</span>
        <span class="p">(</span><span class="s1">&#39;Calinski-Harabasz Index&#39;</span><span class="p">,</span> <span class="s1">&#39;louvain&#39;</span><span class="p">,</span> <span class="mf">0.8</span><span class="p">),</span>
        <span class="p">(</span><span class="s1">&#39;MSE&#39;</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">),</span>
        <span class="p">(</span><span class="s1">&#39;Pearson Correlation&#39;</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">),</span>
        <span class="p">(</span><span class="s1">&#39;Latent Space Normality (p-value)&#39;</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">)</span>
    <span class="p">]</span>

    <span class="n">ordered_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">metric</span><span class="p">,</span> <span class="n">method</span><span class="p">,</span> <span class="n">res</span> <span class="ow">in</span> <span class="n">metric_order</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">pd</span><span class="o">.</span><span class="n">isna</span><span class="p">(</span><span class="n">method</span><span class="p">)</span> <span class="ow">and</span> <span class="n">pd</span><span class="o">.</span><span class="n">isna</span><span class="p">(</span><span class="n">res</span><span class="p">):</span>
            <span class="n">row</span> <span class="o">=</span> <span class="n">df_metrics</span><span class="p">[(</span><span class="n">df_metrics</span><span class="p">[</span><span class="s1">&#39;Metric&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="n">metric</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">df_metrics</span><span class="p">[</span><span class="s1">&#39;Method&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">isna</span><span class="p">())</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">df_metrics</span><span class="p">[</span><span class="s1">&#39;Resolution&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">isna</span><span class="p">())]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">row</span> <span class="o">=</span> <span class="n">df_metrics</span><span class="p">[(</span><span class="n">df_metrics</span><span class="p">[</span><span class="s1">&#39;Metric&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="n">metric</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">df_metrics</span><span class="p">[</span><span class="s1">&#39;Method&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="n">method</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">df_metrics</span><span class="p">[</span><span class="s1">&#39;Resolution&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="n">res</span><span class="p">)]</span>
        <span class="n">ordered_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">ordered_df</span><span class="p">,</span> <span class="n">row</span><span class="p">],</span> <span class="n">ignore_index</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">ordered_df</span><span class="o">.</span><span class="n">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">metrics_gat_df</span> <span class="o">=</span> <span class="n">evaluate_model_vae_gat</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">X_tensor</span><span class="p">,</span> <span class="n">edge_index_cells</span><span class="p">)</span>
<span class="n">final_df</span> <span class="o">=</span> <span class="n">merged_df</span><span class="o">.</span><span class="n">merge</span><span class="p">(</span><span class="n">metrics_gat_df</span><span class="p">,</span> <span class="n">on</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;Metric&quot;</span><span class="p">,</span> <span class="s2">&quot;Method&quot;</span><span class="p">,</span> <span class="s2">&quot;Resolution&quot;</span><span class="p">],</span> <span class="n">how</span><span class="o">=</span><span class="s2">&quot;outer&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>c:\Users\henry\miniconda3\envs\dl_venv\lib\site-packages\scipy\sparse\_index.py:151: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.
  self._set_arrayXarray(i, j, x)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">final_df</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Metric</th>
      <th>Method</th>
      <th>Resolution</th>
      <th>VAE</th>
      <th>VAE+Attention</th>
      <th>VAE+GAT</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Silhouette Score</td>
      <td>leiden</td>
      <td>0.4</td>
      <td>0.195177</td>
      <td>0.462208</td>
      <td>0.459771</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Calinski-Harabasz Index</td>
      <td>leiden</td>
      <td>0.4</td>
      <td>510.820769</td>
      <td>3348.233447</td>
      <td>2430.691527</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Silhouette Score</td>
      <td>leiden</td>
      <td>0.6</td>
      <td>0.171419</td>
      <td>0.435036</td>
      <td>0.394551</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Calinski-Harabasz Index</td>
      <td>leiden</td>
      <td>0.6</td>
      <td>443.458888</td>
      <td>3652.384527</td>
      <td>2464.879944</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Silhouette Score</td>
      <td>leiden</td>
      <td>0.8</td>
      <td>0.076785</td>
      <td>0.411317</td>
      <td>0.471954</td>
    </tr>
    <tr>
      <th>5</th>
      <td>Calinski-Harabasz Index</td>
      <td>leiden</td>
      <td>0.8</td>
      <td>229.003893</td>
      <td>3600.145376</td>
      <td>2774.322012</td>
    </tr>
    <tr>
      <th>6</th>
      <td>Silhouette Score</td>
      <td>louvain</td>
      <td>0.4</td>
      <td>-1.000000</td>
      <td>0.408141</td>
      <td>0.477607</td>
    </tr>
    <tr>
      <th>7</th>
      <td>Calinski-Harabasz Index</td>
      <td>louvain</td>
      <td>0.4</td>
      <td>-1.000000</td>
      <td>2133.816489</td>
      <td>2332.017864</td>
    </tr>
    <tr>
      <th>8</th>
      <td>Silhouette Score</td>
      <td>louvain</td>
      <td>0.6</td>
      <td>0.106973</td>
      <td>0.390661</td>
      <td>0.470149</td>
    </tr>
    <tr>
      <th>9</th>
      <td>Calinski-Harabasz Index</td>
      <td>louvain</td>
      <td>0.6</td>
      <td>206.088366</td>
      <td>1920.285863</td>
      <td>2482.156713</td>
    </tr>
    <tr>
      <th>10</th>
      <td>Silhouette Score</td>
      <td>louvain</td>
      <td>0.8</td>
      <td>0.061618</td>
      <td>0.394807</td>
      <td>0.405119</td>
    </tr>
    <tr>
      <th>11</th>
      <td>Calinski-Harabasz Index</td>
      <td>louvain</td>
      <td>0.8</td>
      <td>230.627533</td>
      <td>1912.544419</td>
      <td>2433.678608</td>
    </tr>
    <tr>
      <th>12</th>
      <td>MSE</td>
      <td>None</td>
      <td>NaN</td>
      <td>0.794525</td>
      <td>4.551389</td>
      <td>2.381168</td>
    </tr>
    <tr>
      <th>13</th>
      <td>Pearson Correlation</td>
      <td>None</td>
      <td>NaN</td>
      <td>0.000289</td>
      <td>-0.003726</td>
      <td>0.090071</td>
    </tr>
    <tr>
      <th>14</th>
      <td>Latent Space Normality (p-value)</td>
      <td>None</td>
      <td>NaN</td>
      <td>0.425853</td>
      <td>0.029407</td>
      <td>0.000477</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
</section>
</section>
<section id="differential-expression-for-vae-gat">
<h3>Differential Expression for VAE + GAT<a class="headerlink" href="#differential-expression-for-vae-gat" title="Link to this heading">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">mu_np</span> <span class="o">=</span> <span class="n">mu</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
<span class="n">adata_latent</span> <span class="o">=</span> <span class="n">sc</span><span class="o">.</span><span class="n">AnnData</span><span class="p">(</span><span class="n">X</span><span class="o">=</span><span class="n">mu_np</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">sc</span><span class="o">.</span><span class="n">pp</span><span class="o">.</span><span class="n">neighbors</span><span class="p">(</span><span class="n">adata_latent</span><span class="p">,</span> <span class="n">n_neighbors</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">use_rep</span><span class="o">=</span><span class="s1">&#39;X&#39;</span><span class="p">)</span>
<span class="n">sc</span><span class="o">.</span><span class="n">tl</span><span class="o">.</span><span class="n">umap</span><span class="p">(</span><span class="n">adata_latent</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">sc</span><span class="o">.</span><span class="n">tl</span><span class="o">.</span><span class="n">leiden</span><span class="p">(</span><span class="n">adata_latent</span><span class="p">,</span> <span class="n">resolution</span><span class="o">=</span><span class="mf">0.6</span><span class="p">,</span> <span class="n">key_added</span><span class="o">=</span><span class="s1">&#39;leiden_gat_0.6&#39;</span><span class="p">)</span>
<span class="c1">#Assign Labels</span>
<span class="n">adata_filtered</span><span class="o">.</span><span class="n">obs</span><span class="p">[</span><span class="s1">&#39;leiden_gat_0.6&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">adata_latent</span><span class="o">.</span><span class="n">obs</span><span class="p">[</span><span class="s1">&#39;leiden_gat_0.6&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">sc</span><span class="o">.</span><span class="n">tl</span><span class="o">.</span><span class="n">rank_genes_groups</span><span class="p">(</span> <span class="c1">#apply DE</span>
    <span class="n">adata_filtered</span><span class="p">,</span>
    <span class="n">groupby</span><span class="o">=</span><span class="s1">&#39;leiden_gat_0.6&#39;</span><span class="p">,</span>
    <span class="n">method</span><span class="o">=</span><span class="s1">&#39;wilcoxon&#39;</span><span class="p">,</span>
    <span class="n">use_raw</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">key_added</span><span class="o">=</span><span class="s1">&#39;rank_genes_gat&#39;</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">sc</span><span class="o">.</span><span class="n">pl</span><span class="o">.</span><span class="n">rank_genes_groups</span><span class="p">(</span>
    <span class="n">adata_filtered</span><span class="p">,</span>
    <span class="n">n_genes</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span>
    <span class="n">sharey</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">gene_symbols</span><span class="o">=</span><span class="s1">&#39;gene_symbols&#39;</span><span class="p">,</span>
    <span class="n">key</span><span class="o">=</span><span class="s1">&#39;rank_genes_gat&#39;</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/be4706fce89c8a49de232a8967a4ce9501ee51eec2f91105fbffc9a4e882c7d3.png" src="_images/be4706fce89c8a49de232a8967a4ce9501ee51eec2f91105fbffc9a4e882c7d3.png" />
</div>
</div>
<p>volvano plot</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">key_added</span><span class="o">=</span><span class="s1">&#39;rank_genes_gat&#39;</span>
</pre></div>
</div>
</div>
</div>
<section id="cluster-summary-with-biological-interpretation">
<h4>Cluster Summary with Biological Interpretation<a class="headerlink" href="#cluster-summary-with-biological-interpretation" title="Link to this heading">#</a></h4>
<div class="pst-scrollable-table-container"><table class="table">
<thead>
<tr class="row-odd"><th class="head"><p>Cluster</p></th>
<th class="head"><p>Top Marker Genes</p></th>
<th class="head"><p>Probable Cell Type</p></th>
<th class="head"><p>Description</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>0</p></td>
<td><p>TRBC2, TRAC, CD3D, CD3E</p></td>
<td><p>T cells (naive/early activated)</p></td>
<td><p>Classic TCR and CD3 markers suggest infiltrating T lymphocytes, possibly CD4+ T cells, involved in immune surveillance or early anti-tumor responses.</p></td>
</tr>
<tr class="row-odd"><td><p>1</p></td>
<td><p>LTB, GIMAP7, CD7, IL32</p></td>
<td><p>Activated T cells / T memory</p></td>
<td><p>These markers point to a more activated or memory-like T cell state, indicating tumor-infiltrating lymphocytes (TILs) with potential immune memory against glioblastoma antigens.</p></td>
</tr>
<tr class="row-even"><td><p>2</p></td>
<td><p>CD8A, GZMA, PRF1, NKG7</p></td>
<td><p>Cytotoxic T lymphocytes (CTLs)</p></td>
<td><p>Express cytolytic granules; likely active CD8+ T cells, attempting to eliminate tumor cells. May also reflect exhaustion phenotype in late-stage tumors.</p></td>
</tr>
<tr class="row-odd"><td><p>3</p></td>
<td><p>CCL3, CCL4, GZMB, IFNG</p></td>
<td><p>Highly activated CTLs / NK-like T cells</p></td>
<td><p>Pro-inflammatory chemokines and cytotoxic genes suggest strong anti-tumor effector activity. Could be hybrid T/NK cells in the glioblastoma TME.</p></td>
</tr>
<tr class="row-even"><td><p>4</p></td>
<td><p>HLA-DRA, CD74, H2-Aa, CCL17</p></td>
<td><p>Antigen-presenting cells (microglia/macrophages)</p></td>
<td><p>MHC-II molecules and CD74 are markers of microglia or infiltrating macrophages in an antigen-presenting state, likely modulating immune responses in the tumor.</p></td>
</tr>
<tr class="row-odd"><td><p>5</p></td>
<td><p>CD79A, MZB1, IGHM, JCHAIN</p></td>
<td><p>B cells / plasmablasts</p></td>
<td><p>Rare in CNS but present in some glioblastoma settings; may reflect tertiary lymphoid structure formation or humoral responses.</p></td>
</tr>
<tr class="row-even"><td><p>6</p></td>
<td><p>HBB, HBA2, AHSP</p></td>
<td><p>Erythroid lineage / contamination</p></td>
<td><p>Hemoglobin genes suggest presence of red blood cells or early erythroid precursors—possibly blood contamination or angiogenic niches.</p></td>
</tr>
<tr class="row-odd"><td><p>7</p></td>
<td><p>FCER1A, CLEC10A, CD1C</p></td>
<td><p>Dendritic cells (cDCs)</p></td>
<td><p>These are professional antigen-presenting cells, potentially involved in cross-presentation to CD8+ T cells. May have limited access to brain parenchyma.</p></td>
</tr>
<tr class="row-even"><td><p>8</p></td>
<td><p>PPBP, PF4, ITGA2B</p></td>
<td><p>Platelets / megakaryocytes</p></td>
<td><p>Platelet signature genes; possibly small platelet fragments or megakaryocytes trapped in capillaries during sampling. Rare in brain.</p></td>
</tr>
<tr class="row-odd"><td><p>9</p></td>
<td><p>S100A8, S100A9, LYZ</p></td>
<td><p>Monocytes / myeloid-derived suppressor cells (MDSCs)</p></td>
<td><p>Strong inflammatory and immunosuppressive signatures, associated with tumor-promoting immune suppression in glioblastoma.</p></td>
</tr>
<tr class="row-even"><td><p>10</p></td>
<td><p>GNLY, GZMB, NKG7, KLRD1</p></td>
<td><p>Natural Killer (NK) cells</p></td>
<td><p>Cytotoxic innate lymphoid cells involved in anti-tumor immunity. Their infiltration into the glioblastoma TME is rare but significant.</p></td>
</tr>
<tr class="row-odd"><td><p>11</p></td>
<td><p>CD14, FCN1, LYZ</p></td>
<td><p>Classical monocytes / infiltrating macrophages</p></td>
<td><p>Possibly blood-derived monocytes transitioning to tumor-associated macrophages (TAMs), crucial in shaping the glioma microenvironment.</p></td>
</tr>
<tr class="row-even"><td><p>12</p></td>
<td><p>MKI67, TOP2A, HIST1H4C</p></td>
<td><p>Proliferating cells (tumor or progenitors)</p></td>
<td><p>High proliferation markers suggest glioblastoma stem-like cells (GSCs) or actively cycling tumor cells. Strongly indicative of neoplastic origin.</p></td>
</tr>
<tr class="row-odd"><td><p>13</p></td>
<td><p>GZMH, PRF1, KLRK1</p></td>
<td><p>Effector NK / CTLs</p></td>
<td><p>Highly cytotoxic phenotype; possibly a mix of T and NK cells targeting glioma cells.</p></td>
</tr>
<tr class="row-even"><td><p>14</p></td>
<td><p>FCGR3A (CD16), MS4A7, CD68</p></td>
<td><p>Non-classical monocytes / TAMs</p></td>
<td><p>Immunosuppressive monocytes involved in glioma progression and immune evasion.</p></td>
</tr>
<tr class="row-odd"><td><p>15</p></td>
<td><p>IGLC2, IGHG1, MZB1</p></td>
<td><p>Plasma cells / antibody-secreting B cells</p></td>
<td><p>Rare in brain but can emerge in response to chronic inflammation or antigen stimulation in tumors.</p></td>
</tr>
</tbody>
</table>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="n">axs</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">20</span><span class="p">))</span>
<span class="n">axs</span> <span class="o">=</span> <span class="n">axs</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>

<span class="n">groups</span> <span class="o">=</span> <span class="n">adata_filtered</span><span class="o">.</span><span class="n">obs</span><span class="p">[</span><span class="s1">&#39;leiden_gat_0.6&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">cat</span><span class="o">.</span><span class="n">categories</span>

<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">group</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">groups</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">i</span> <span class="o">&gt;=</span> <span class="nb">len</span><span class="p">(</span><span class="n">axs</span><span class="p">):</span>
        <span class="k">break</span>

    <span class="n">names</span> <span class="o">=</span> <span class="n">adata_filtered</span><span class="o">.</span><span class="n">uns</span><span class="p">[</span><span class="s1">&#39;rank_genes_gat&#39;</span><span class="p">][</span><span class="s1">&#39;names&#39;</span><span class="p">][</span><span class="n">group</span><span class="p">]</span>
    <span class="n">logfc</span> <span class="o">=</span> <span class="n">adata_filtered</span><span class="o">.</span><span class="n">uns</span><span class="p">[</span><span class="s1">&#39;rank_genes_gat&#39;</span><span class="p">][</span><span class="s1">&#39;logfoldchanges&#39;</span><span class="p">][</span><span class="n">group</span><span class="p">]</span>
    <span class="n">pvals</span> <span class="o">=</span> <span class="n">adata_filtered</span><span class="o">.</span><span class="n">uns</span><span class="p">[</span><span class="s1">&#39;rank_genes_gat&#39;</span><span class="p">][</span><span class="s1">&#39;pvals&#39;</span><span class="p">][</span><span class="n">group</span><span class="p">]</span>

    <span class="n">volcano_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span>
        <span class="s1">&#39;gene&#39;</span><span class="p">:</span> <span class="n">names</span><span class="p">,</span>
        <span class="s1">&#39;logFC&#39;</span><span class="p">:</span> <span class="n">logfc</span><span class="p">,</span>
        <span class="s1">&#39;pval&#39;</span><span class="p">:</span> <span class="n">pvals</span>
    <span class="p">})</span>

    <span class="n">volcano_df</span><span class="p">[</span><span class="s1">&#39;neg_log10_pval&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">log10</span><span class="p">(</span><span class="n">volcano_df</span><span class="p">[</span><span class="s1">&#39;pval&#39;</span><span class="p">])</span>

    <span class="n">volcano_df</span><span class="p">[</span><span class="s1">&#39;significant&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">volcano_df</span><span class="p">[</span><span class="s1">&#39;pval&#39;</span><span class="p">]</span> <span class="o">&lt;</span> <span class="mf">0.05</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="nb">abs</span><span class="p">(</span><span class="n">volcano_df</span><span class="p">[</span><span class="s1">&#39;logFC&#39;</span><span class="p">])</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">)</span>

    <span class="n">ax</span> <span class="o">=</span> <span class="n">axs</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">volcano_df</span><span class="p">[</span><span class="s1">&#39;logFC&#39;</span><span class="p">],</span> <span class="n">volcano_df</span><span class="p">[</span><span class="s1">&#39;neg_log10_pval&#39;</span><span class="p">],</span>
               <span class="n">c</span><span class="o">=</span><span class="n">volcano_df</span><span class="p">[</span><span class="s1">&#39;significant&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">({</span><span class="kc">True</span><span class="p">:</span> <span class="s1">&#39;red&#39;</span><span class="p">,</span> <span class="kc">False</span><span class="p">:</span> <span class="s1">&#39;gray&#39;</span><span class="p">}),</span>
               <span class="n">alpha</span><span class="o">=</span><span class="mf">0.7</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Volcano Plot: Cluster </span><span class="si">{</span><span class="n">group</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;Log Fold Change&#39;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;-log10(p-value)&#39;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">axhline</span><span class="p">(</span><span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">log10</span><span class="p">(</span><span class="mf">0.05</span><span class="p">),</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;blue&#39;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">axvline</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;green&#39;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">axvline</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;green&#39;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>

<span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">axs</span><span class="p">)):</span>
    <span class="n">fig</span><span class="o">.</span><span class="n">delaxes</span><span class="p">(</span><span class="n">axs</span><span class="p">[</span><span class="n">j</span><span class="p">])</span>

<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/7e9ea9706b40a773f334d8cfa102f9a0e2c397728d6a9f370ce9c854677cead5.png" src="_images/7e9ea9706b40a773f334d8cfa102f9a0e2c397728d6a9f370ce9c854677cead5.png" />
</div>
</div>
</section>
</section>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="PCA.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Principal Component Analysis - Dimensionality reduction</p>
      </div>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#model-vae">Model VAE</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#decoder-gene-expression-reconstruction">3. Decoder – Gene Expression Reconstruction</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#loss-functions">Loss Functions</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#clusterization-for-vae">Clusterization for VAE</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#hyperparametrization-of-vae">Hyperparametrization of VAE</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#performance-loss-functions">Performance loss functions</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#clusters-of-vae">Clusters of VAE</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#evaluation-metrics">Evaluation Metrics</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#differential-expression-for-vae">Differential Expression for VAE</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#volcano-plot-for-differential-expression">Volcano PLot for Differential Expression</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#vae-attention">VAE + Attention</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#hyperparametrization-of-the-model-vae-attention">Hyperparametrization of the model VAE + Attention</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#cluster-for-vae-attention">Cluster for VAE + Attention</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#differential-expression-for-vae-attention">Differential Expression for VAE + Attention</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#cluster-interpretation-based-on-marker-ranking-plots">Cluster Interpretation Based on Marker Ranking Plots</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#vae-gat">VAE + GAT</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#hyperparametrization-of-vae-gat">Hyperparametrization of VAE + GAT</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#model-defined-vae-gat">Model Defined VAE + GAT</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#differential-expression-for-vae-gat">Differential Expression for VAE + GAT</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#cluster-summary-with-biological-interpretation">Cluster Summary with Biological Interpretation</a></li>
</ul>
</li>
</ul>
</li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By The Jupyter Book Community
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2023.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>